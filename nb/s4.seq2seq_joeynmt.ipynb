{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘./nb/.ipynb_checkpoints’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!find . -name .ipynb* -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "name: \"my_experiment\"\n",
    "\n",
    "# This configuration serves the purpose of documenting and explaining the settings, *NOT* as an example for good hyperparamter settings.\n",
    "\n",
    "data: # specify your data here\n",
    "    src: {lang_src}                       # src language: expected suffix of train files, e.g. \"train.de\"\n",
    "    trg: {lang_tgt}                       # trg language\n",
    "    train: {train_path}     # training data\n",
    "    dev: {dev_path}         # development data for validation\n",
    "    test: {test_path}       # test data for testing final model; optional\n",
    "    level: {level}                  # segmentation level: either \"word\", \"bpe\" or \"char\"\n",
    "    lowercase: True                 # lowercase the data, also for validation\n",
    "    max_sent_length: 150             # filter out longer sentences from training (src+trg)\n",
    "    src_voc_min_freq: 1             # src minimum frequency for a token to become part of the vocabulary\n",
    "    trg_voc_min_freq: 1             # trg minimum frequency for a token to become part of the vocabulary\n",
    "    #src_vocab: \"my_model/src_vocab.txt\"  # if specified, load a vocabulary from this file\n",
    "    #trg_vocab: \"my_model/trg_vocab.txt\"  # one token per line, line number is index\n",
    "\n",
    "testing:                            # specify which inference algorithm to use for testing (for validation it's always greedy decoding)\n",
    "    beam_size: 5                    # size of the beam for beam search\n",
    "    alpha: 1.0                      # length penalty for beam search\n",
    "\n",
    "training:                           # specify training details here\n",
    "    reset_best_ckpt: False          # if True, reset the tracking of the best checkpoint and scores. Use for domain adaptation or fine-tuning with new metrics or dev data.\n",
    "    reset_scheduler: False          # if True, overwrite scheduler in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    reset_optimizer: False          # if True, overwrite optimizer in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    random_seed: 42                 # set this seed to make training deterministic\n",
    "    optimizer: \"adam\"               # choices: \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", default is SGD\n",
    "    learning_rate: 0.0005           # initial learning rate, default: 3.0e-4 / 0.005\n",
    "    learning_rate_min: 0.0001       # stop learning when learning rate is reduced below this threshold, default: 1.0e-8\n",
    "    #learning_rate_factor: 1        # factor for Noam scheduler (used with Transformer)\n",
    "    #learning_rate_warmup: 4000     # warmup steps for Noam scheduler (used with Transformer)\n",
    "    clip_grad_val: 1.0              # clip the gradients to this value when they exceed it, optional\n",
    "    #clip_grad_norm: 1.0            # norm clipping instead of value clipping\n",
    "    weight_decay: 0.                # l2 regularization, default: 0\n",
    "    batch_size: 48                  # mini-batch size as number of sentences (when batch_type is \"sentence\"; default) or total number of tokens (when batch_type is \"token\")\n",
    "    batch_type: \"sentence\"          # create batches with sentences (\"sentence\", default) or tokens (\"token\")\n",
    "    eval_batch_size: 10            # mini-batch size for evaluation (see batch_size above)\n",
    "    eval_batch_type: \"sentence\"     # evaluation batch type (\"sentence\", default) or tokens (\"token\")\n",
    "    batch_multiplier: 1             # increase the effective batch size with values >1 to batch_multiplier*batch_size without increasing memory consumption by making updates only every batch_multiplier batches\n",
    "    scheduling: \"plateau\"           # learning rate scheduling, optional, if not specified stays constant, options: \"plateau\", \"exponential\", \"decaying\", \"noam\" (for Transformer), \"warmupexponentialdecay\"\n",
    "    patience: 600                     # specific to plateau scheduler: wait for this many validations without improvement before decreasing the learning rate\n",
    "    decrease_factor: 0.5            # specific to plateau & exponential scheduler: decrease the learning rate by this factor\n",
    "    epochs: 30                      # train for this many epochs\n",
    "    validation_freq: {val_freq}            # validate after this many updates (number of mini-batches), default: 1000\n",
    "    logging_freq: 1000               # log the training progress after this many updates, default: 100\n",
    "    eval_metric: \"bleu\"             # validation metric, default: \"bleu\", other options: \"chrf\", \"token_accuracy\", \"sequence_accuracy\"\n",
    "    early_stopping_metric: \"eval_metric\"   # when a new high score on this metric is achieved, a checkpoint is written, when \"eval_metric\" (default) is maximized, when \"loss\" or \"ppl\" is minimized\n",
    "    model_dir: {model_dir} # directory where models and validation results are stored, required\n",
    "    overwrite: True                 # overwrite existing model directory, default: False. Do not set to True unless for debugging!\n",
    "    shuffle: True                   # shuffle the training data, default: True\n",
    "    use_cuda: True                  # use CUDA for acceleration on GPU, required. Set to False when working on CPU.\n",
    "    max_output_length: 60           # maximum output length for decoding, default: None. If set to None, allow sentences of max 1.5*src length\n",
    "    print_valid_sents: []    # print this many validation sentences during each validation run, default: [0, 1, 2]\n",
    "    keep_last_ckpts: 3              # keep this many of the latest checkpoints, if -1: all of them, default: 5\n",
    "    label_smoothing: 0.0            # label smoothing: reference tokens will have 1-label_smoothing probability instead of 1, rest of probability mass is uniformly distributed over the rest of the vocabulary, default: 0.0 (off)\n",
    "\n",
    "model:                              # specify your model architecture here\n",
    "    initializer: \"xavier\"           # initializer for all trainable weights (xavier, zeros, normal, uniform)\n",
    "    init_weight: 0.01               # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    init_gain: 1.0                  # gain for Xavier initializer (default: 1.0)\n",
    "    bias_initializer: \"zeros\"       # initializer for bias terms (xavier, zeros, normal, uniform)\n",
    "    embed_initializer: \"normal\"     # initializer for embeddings (xavier, zeros, normal, uniform)\n",
    "    embed_init_weight: 0.1          # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    embed_init_gain: 1.0            # gain for Xavier initializer for embeddings (default: 1.0)\n",
    "    init_rnn_orthogonal: False      # use orthogonal initialization for recurrent weights (default: False)\n",
    "    lstm_forget_gate: 1.            # initialize LSTM forget gate with this value (default: 1.)\n",
    "    tied_embeddings: False           # tie src and trg embeddings, only applicable if vocabularies are the same, default: False\n",
    "    tied_softmax: False             # tie trg embeddings and softmax (for Transformer; can be used together with tied_embeddings), default: False\n",
    "    encoder:\n",
    "        type: \"recurrent\"           # encoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"             # type of recurrent unit to use, either \"gru\" or \"lstm\", default: \"lstm\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}      # size of embeddings\n",
    "            scale: False            # scale the embeddings by sqrt of their size, default: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}            # size of RNN\n",
    "        bidirectional: True         # use a bi-directional encoder, default: True\n",
    "        dropout: 0.3                # apply dropout to the inputs to the RNN, default: 0.0\n",
    "        num_layers: 2               # stack this many layers of equal size, default: 1\n",
    "        freeze: False               # if True, encoder parameters are not updated during training (does not include embedding parameters)\n",
    "    decoder:\n",
    "        type: \"recurrent\"           # decoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}\n",
    "            scale: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}\n",
    "        dropout: 0.3\n",
    "        hidden_dropout: 0.2         # apply dropout to the attention vector, default: 0.0\n",
    "        num_layers: 2\n",
    "        input_feeding: True         # combine hidden state and attention vector before feeding to rnn, default: True\n",
    "        init_hidden: \"last\"         # initialized the decoder hidden state: use linear projection of last encoder state (\"bridge\") or simply the last state (\"last\") or zeros (\"zero\"), default: \"bridge\"\n",
    "        attention: \"bahdanau\"       # attention mechanism, choices: \"bahdanau\" (MLP attention), \"luong\" (bilinear attention), default: \"bahdanau\"\n",
    "        freeze: False               # if True, decoder parameters are not updated during training (does not include embedding parameters, but attention)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/translate/Religioso/char\n",
      "2020-02-19 22:05:27,883 Hello! This is Joey-NMT.\n",
      "2020-02-19 22:05:28.457139: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 22:05:28.457194: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 22:05:28.457203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-02-19 22:05:29,055 Total params: 12451936\n",
      "2020-02-19 22:05:29,056 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-02-19 22:05:30,943 cfg.name                           : my_experiment\n",
      "2020-02-19 22:05:30,943 cfg.data.src                       : es\n",
      "2020-02-19 22:05:30,943 cfg.data.trg                       : shp\n",
      "2020-02-19 22:05:30,943 cfg.data.train                     : data/translate/preprocessed/Religioso/char/train\n",
      "2020-02-19 22:05:30,943 cfg.data.dev                       : data/translate/preprocessed/Religioso/char/valid\n",
      "2020-02-19 22:05:30,943 cfg.data.test                      : data/translate/preprocessed/Religioso/char/test\n",
      "2020-02-19 22:05:30,943 cfg.data.level                     : char\n",
      "2020-02-19 22:05:30,943 cfg.data.lowercase                 : True\n",
      "2020-02-19 22:05:30,943 cfg.data.max_sent_length           : 150\n",
      "2020-02-19 22:05:30,943 cfg.data.src_voc_min_freq          : 1\n",
      "2020-02-19 22:05:30,943 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-02-19 22:05:30,943 cfg.testing.beam_size              : 5\n",
      "2020-02-19 22:05:30,943 cfg.testing.alpha                  : 1.0\n",
      "2020-02-19 22:05:30,943 cfg.training.reset_best_ckpt       : False\n",
      "2020-02-19 22:05:30,943 cfg.training.reset_scheduler       : False\n",
      "2020-02-19 22:05:30,943 cfg.training.reset_optimizer       : False\n",
      "2020-02-19 22:05:30,943 cfg.training.random_seed           : 42\n",
      "2020-02-19 22:05:30,944 cfg.training.optimizer             : adam\n",
      "2020-02-19 22:05:30,944 cfg.training.learning_rate         : 0.0005\n",
      "2020-02-19 22:05:30,944 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-02-19 22:05:30,944 cfg.training.clip_grad_val         : 1.0\n",
      "2020-02-19 22:05:30,944 cfg.training.weight_decay          : 0.0\n",
      "2020-02-19 22:05:30,944 cfg.training.batch_size            : 48\n",
      "2020-02-19 22:05:30,944 cfg.training.batch_type            : sentence\n",
      "2020-02-19 22:05:30,944 cfg.training.eval_batch_size       : 10\n",
      "2020-02-19 22:05:30,944 cfg.training.eval_batch_type       : sentence\n",
      "2020-02-19 22:05:30,944 cfg.training.batch_multiplier      : 1\n",
      "2020-02-19 22:05:30,944 cfg.training.scheduling            : plateau\n",
      "2020-02-19 22:05:30,944 cfg.training.patience              : 600\n",
      "2020-02-19 22:05:30,944 cfg.training.decrease_factor       : 0.5\n",
      "2020-02-19 22:05:30,944 cfg.training.epochs                : 30\n",
      "2020-02-19 22:05:30,944 cfg.training.validation_freq       : 10\n",
      "2020-02-19 22:05:30,944 cfg.training.logging_freq          : 1000\n",
      "2020-02-19 22:05:30,944 cfg.training.eval_metric           : bleu\n",
      "2020-02-19 22:05:30,944 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-02-19 22:05:30,944 cfg.training.model_dir             : results/translate/es-shp_Religioso_300_512/char\n",
      "2020-02-19 22:05:30,944 cfg.training.overwrite             : True\n",
      "2020-02-19 22:05:30,944 cfg.training.shuffle               : True\n",
      "2020-02-19 22:05:30,944 cfg.training.use_cuda              : True\n",
      "2020-02-19 22:05:30,944 cfg.training.max_output_length     : 60\n",
      "2020-02-19 22:05:30,944 cfg.training.print_valid_sents     : []\n",
      "2020-02-19 22:05:30,944 cfg.training.keep_last_ckpts       : 3\n",
      "2020-02-19 22:05:30,944 cfg.training.label_smoothing       : 0.0\n",
      "2020-02-19 22:05:30,944 cfg.model.initializer              : xavier\n",
      "2020-02-19 22:05:30,944 cfg.model.init_weight              : 0.01\n",
      "2020-02-19 22:05:30,944 cfg.model.init_gain                : 1.0\n",
      "2020-02-19 22:05:30,945 cfg.model.bias_initializer         : zeros\n",
      "2020-02-19 22:05:30,945 cfg.model.embed_initializer        : normal\n",
      "2020-02-19 22:05:30,945 cfg.model.embed_init_weight        : 0.1\n",
      "2020-02-19 22:05:30,945 cfg.model.embed_init_gain          : 1.0\n",
      "2020-02-19 22:05:30,945 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-02-19 22:05:30,945 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-02-19 22:05:30,945 cfg.model.tied_embeddings          : False\n",
      "2020-02-19 22:05:30,945 cfg.model.tied_softmax             : False\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.type             : recurrent\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.rnn_type         : gru\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.embeddings.scale : False\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.hidden_size      : 512\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.bidirectional    : True\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.dropout          : 0.3\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.num_layers       : 2\n",
      "2020-02-19 22:05:30,945 cfg.model.encoder.freeze           : False\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.type             : recurrent\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.rnn_type         : gru\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.embeddings.scale : False\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.hidden_size      : 512\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.dropout          : 0.3\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.num_layers       : 2\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.input_feeding    : True\n",
      "2020-02-19 22:05:30,945 cfg.model.decoder.init_hidden      : last\n",
      "2020-02-19 22:05:30,946 cfg.model.decoder.attention        : bahdanau\n",
      "2020-02-19 22:05:30,946 cfg.model.decoder.freeze           : False\n",
      "2020-02-19 22:05:30,946 Data set sizes: \n",
      "\ttrain 4975,\n",
      "\tvalid 749,\n",
      "\ttest 749\n",
      "2020-02-19 22:05:30,946 First training example:\n",
      "\t[SRC] @@ i k a x b i @@ j a @@ n o n @@ i b o n @@ j o i r a @@ j a w e t i a n b i @@ k e y ó y a m a i @@ i k i\n",
      "\t[TRG] @@ p e r o @@ l a @@ p a l a b r a @@ d e l @@ s e ñ o r @@ p e r m a n e c e @@ e t e r n a m e n t e @@ e s t a @@ p a l a b r a @@ e s @@ e l @@ e v a n g e l i o @@ q u e @@ s e @@ l e s @@ h a @@ a n u n c i a d o @@ a @@ u s t e d e s\n",
      "2020-02-19 22:05:30,946 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) @@ (6) i (7) n (8) o (9) k\n",
      "2020-02-19 22:05:30,946 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) a (7) o (8) s (9) n\n",
      "2020-02-19 22:05:30,946 Number of Src words (types): 36\n",
      "2020-02-19 22:05:30,946 Number of Trg words (types): 36\n",
      "2020-02-19 22:05:30,946 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=36),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=36))\n",
      "2020-02-19 22:05:30,946 EPOCH 1\n",
      "2020-02-19 22:05:49,482 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:05:49,482 Saving new checkpoint.\n",
      "2020-02-19 22:05:49,630 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 166065.1406, ppl:  17.8629, duration: 14.0591s\n",
      "2020-02-19 22:06:07,609 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 162445.1094, ppl:  16.7749, duration: 14.0255s\n",
      "2020-02-19 22:06:25,565 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 158454.1250, ppl:  15.6521, duration: 14.0711s\n",
      "2020-02-19 22:06:43,211 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 149395.0312, ppl:  13.3745, duration: 13.9827s\n",
      "2020-02-19 22:07:01,034 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 140036.1406, ppl:  11.3690, duration: 14.0635s\n",
      "2020-02-19 22:07:18,671 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 133485.9219, ppl:  10.1470, duration: 13.9370s\n",
      "2020-02-19 22:07:36,721 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 129336.0703, ppl:   9.4418, duration: 14.1064s\n",
      "2020-02-19 22:07:54,775 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 126376.5469, ppl:   8.9690, duration: 14.0115s\n",
      "2020-02-19 22:08:12,543 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 123890.5078, ppl:   8.5901, duration: 14.0185s\n",
      "2020-02-19 22:08:30,812 Validation result (greedy) at epoch   1, step      100: bleu:   0.00, loss: 123114.1250, ppl:   8.4752, duration: 14.2022s\n",
      "2020-02-19 22:08:32,431 Epoch   1: total training loss 17488.72\n",
      "2020-02-19 22:08:32,432 EPOCH 2\n",
      "2020-02-19 22:08:49,319 Validation result (greedy) at epoch   2, step      110: bleu:   0.00, loss: 118772.8516, ppl:   7.8599, duration: 14.1184s\n",
      "2020-02-19 22:09:07,943 Validation result (greedy) at epoch   2, step      120: bleu:   0.00, loss: 117022.2969, ppl:   7.6247, duration: 14.1608s\n",
      "2020-02-19 22:09:26,127 Validation result (greedy) at epoch   2, step      130: bleu:   0.00, loss: 116021.3281, ppl:   7.4933, duration: 14.1654s\n",
      "2020-02-19 22:09:44,318 Validation result (greedy) at epoch   2, step      140: bleu:   0.00, loss: 114102.5703, ppl:   7.2479, duration: 14.1248s\n",
      "2020-02-19 22:10:02,285 Validation result (greedy) at epoch   2, step      150: bleu:   0.00, loss: 112727.0234, ppl:   7.0768, duration: 14.1278s\n",
      "2020-02-19 22:10:20,162 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 112095.8125, ppl:   6.9997, duration: 14.1770s\n",
      "2020-02-19 22:10:38,292 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 111017.1719, ppl:   6.8699, duration: 14.1876s\n",
      "2020-02-19 22:10:56,539 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 109474.5938, ppl:   6.6884, duration: 14.1280s\n",
      "2020-02-19 22:11:14,965 Validation result (greedy) at epoch   2, step      190: bleu:   0.00, loss: 108567.4375, ppl:   6.5839, duration: 14.0787s\n",
      "2020-02-19 22:11:33,566 Validation result (greedy) at epoch   2, step      200: bleu:   0.00, loss: 107446.0938, ppl:   6.4569, duration: 14.1599s\n",
      "2020-02-19 22:11:37,316 Epoch   2: total training loss 13913.01\n",
      "2020-02-19 22:11:37,316 EPOCH 3\n",
      "2020-02-19 22:11:52,435 Validation result (greedy) at epoch   3, step      210: bleu:   0.00, loss: 106289.6406, ppl:   6.3286, duration: 14.1845s\n",
      "2020-02-19 22:12:10,784 Validation result (greedy) at epoch   3, step      220: bleu:   0.00, loss: 105321.5312, ppl:   6.2232, duration: 14.2840s\n",
      "2020-02-19 22:12:28,894 Validation result (greedy) at epoch   3, step      230: bleu:   0.00, loss: 105009.4453, ppl:   6.1895, duration: 14.2610s\n",
      "2020-02-19 22:12:47,361 Validation result (greedy) at epoch   3, step      240: bleu:   0.00, loss: 103716.2578, ppl:   6.0521, duration: 14.1486s\n",
      "2020-02-19 22:13:05,729 Validation result (greedy) at epoch   3, step      250: bleu:   0.00, loss: 102453.3672, ppl:   5.9209, duration: 14.2079s\n",
      "2020-02-19 22:13:24,381 Validation result (greedy) at epoch   3, step      260: bleu:   0.00, loss: 101923.3594, ppl:   5.8667, duration: 14.1640s\n",
      "2020-02-19 22:13:42,679 Validation result (greedy) at epoch   3, step      270: bleu:   0.00, loss: 101115.6484, ppl:   5.7850, duration: 14.1482s\n",
      "2020-02-19 22:14:01,162 Validation result (greedy) at epoch   3, step      280: bleu:   0.00, loss: 100311.1250, ppl:   5.7048, duration: 14.1776s\n",
      "2020-02-19 22:14:19,761 Validation result (greedy) at epoch   3, step      290: bleu:   0.00, loss: 99172.9062, ppl:   5.5931, duration: 14.1656s\n",
      "2020-02-19 22:14:38,203 Validation result (greedy) at epoch   3, step      300: bleu:   0.00, loss: 98653.4062, ppl:   5.5429, duration: 14.1767s\n",
      "2020-02-19 22:14:56,656 Validation result (greedy) at epoch   3, step      310: bleu:   0.00, loss: 97013.7969, ppl:   5.3874, duration: 14.2031s\n",
      "2020-02-19 22:14:57,558 Epoch   3: total training loss 12716.61\n",
      "2020-02-19 22:14:57,559 EPOCH 4\n",
      "2020-02-19 22:15:15,174 Validation result (greedy) at epoch   4, step      320: bleu:   0.00, loss: 98761.4219, ppl:   5.5533, duration: 14.2163s\n",
      "2020-02-19 22:15:33,783 Validation result (greedy) at epoch   4, step      330: bleu:   0.00, loss: 96432.4062, ppl:   5.3333, duration: 14.2020s\n",
      "2020-02-19 22:15:52,093 Validation result (greedy) at epoch   4, step      340: bleu:   0.00, loss: 95489.1719, ppl:   5.2467, duration: 14.1668s\n",
      "2020-02-19 22:16:10,648 Validation result (greedy) at epoch   4, step      350: bleu:   0.00, loss: 94628.5469, ppl:   5.1689, duration: 14.2077s\n",
      "2020-02-19 22:16:29,326 Validation result (greedy) at epoch   4, step      360: bleu:   0.00, loss: 93780.4453, ppl:   5.0933, duration: 14.1831s\n",
      "2020-02-19 22:16:47,947 Validation result (greedy) at epoch   4, step      370: bleu:   0.00, loss: 93775.1094, ppl:   5.0929, duration: 14.1902s\n",
      "2020-02-19 22:17:06,248 Validation result (greedy) at epoch   4, step      380: bleu:   0.00, loss: 92720.1641, ppl:   5.0005, duration: 14.1509s\n",
      "2020-02-19 22:17:24,362 Validation result (greedy) at epoch   4, step      390: bleu:   0.00, loss: 92116.7578, ppl:   4.9484, duration: 14.1584s\n",
      "2020-02-19 22:17:43,041 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:17:43,041 Saving new checkpoint.\n",
      "2020-02-19 22:17:43,206 Validation result (greedy) at epoch   4, step      400: bleu:   0.38, loss: 91179.6094, ppl:   4.8685, duration: 14.3311s\n",
      "2020-02-19 22:18:01,529 Validation result (greedy) at epoch   4, step      410: bleu:   0.00, loss: 90457.4844, ppl:   4.8079, duration: 14.1046s\n",
      "2020-02-19 22:18:04,112 Epoch   4: total training loss 11774.74\n",
      "2020-02-19 22:18:04,113 EPOCH 5\n",
      "2020-02-19 22:18:19,890 Validation result (greedy) at epoch   5, step      420: bleu:   0.00, loss: 90065.9062, ppl:   4.7753, duration: 14.0738s\n",
      "2020-02-19 22:18:37,915 Validation result (greedy) at epoch   5, step      430: bleu:   0.29, loss: 89592.8672, ppl:   4.7362, duration: 13.9512s\n",
      "2020-02-19 22:18:54,933 Validation result (greedy) at epoch   5, step      440: bleu:   0.29, loss: 89010.5156, ppl:   4.6886, duration: 13.9771s\n",
      "2020-02-19 22:19:12,283 Validation result (greedy) at epoch   5, step      450: bleu:   0.00, loss: 88529.8359, ppl:   4.6496, duration: 13.9741s\n",
      "2020-02-19 22:19:28,534 Validation result (greedy) at epoch   5, step      460: bleu:   0.37, loss: 87640.2188, ppl:   4.5784, duration: 13.9718s\n",
      "2020-02-19 22:19:45,470 Validation result (greedy) at epoch   5, step      470: bleu:   0.00, loss: 87830.1641, ppl:   4.5935, duration: 13.9809s\n",
      "2020-02-19 22:20:02,768 Validation result (greedy) at epoch   5, step      480: bleu:   0.00, loss: 86993.4766, ppl:   4.5273, duration: 13.9957s\n",
      "2020-02-19 22:20:19,863 Validation result (greedy) at epoch   5, step      490: bleu:   0.00, loss: 86675.2344, ppl:   4.5023, duration: 13.9759s\n",
      "2020-02-19 22:20:37,250 Validation result (greedy) at epoch   5, step      500: bleu:   0.30, loss: 85730.3672, ppl:   4.4291, duration: 13.9803s\n",
      "2020-02-19 22:20:55,129 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:20:55,129 Saving new checkpoint.\n",
      "2020-02-19 22:20:55,298 Validation result (greedy) at epoch   5, step      510: bleu:   0.49, loss: 84982.5156, ppl:   4.3720, duration: 14.4156s\n",
      "2020-02-19 22:21:13,048 Validation result (greedy) at epoch   5, step      520: bleu:   0.00, loss: 84655.9219, ppl:   4.3472, duration: 14.0491s\n",
      "2020-02-19 22:21:13,048 Epoch   5: total training loss 11004.19\n",
      "2020-02-19 22:21:13,048 EPOCH 6\n",
      "2020-02-19 22:21:31,269 Validation result (greedy) at epoch   6, step      530: bleu:   0.00, loss: 84781.9375, ppl:   4.3568, duration: 14.1728s\n",
      "2020-02-19 22:21:49,605 Validation result (greedy) at epoch   6, step      540: bleu:   0.38, loss: 83788.6875, ppl:   4.2823, duration: 14.2958s\n",
      "2020-02-19 22:22:07,630 Validation result (greedy) at epoch   6, step      550: bleu:   0.00, loss: 84334.8047, ppl:   4.3231, duration: 14.2450s\n",
      "2020-02-19 22:22:26,137 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:22:26,137 Saving new checkpoint.\n",
      "2020-02-19 22:22:26,333 Validation result (greedy) at epoch   6, step      560: bleu:   0.66, loss: 83092.3672, ppl:   4.2308, duration: 14.3451s\n",
      "2020-02-19 22:22:45,008 Validation result (greedy) at epoch   6, step      570: bleu:   0.47, loss: 83026.3594, ppl:   4.2260, duration: 14.2624s\n",
      "2020-02-19 22:23:03,298 Validation result (greedy) at epoch   6, step      580: bleu:   0.56, loss: 82623.8281, ppl:   4.1966, duration: 14.2208s\n",
      "2020-02-19 22:23:21,072 Validation result (greedy) at epoch   6, step      590: bleu:   0.00, loss: 83201.7578, ppl:   4.2389, duration: 14.2379s\n",
      "2020-02-19 22:23:39,485 Validation result (greedy) at epoch   6, step      600: bleu:   0.55, loss: 82189.1406, ppl:   4.1650, duration: 14.1665s\n",
      "2020-02-19 22:23:57,500 Validation result (greedy) at epoch   6, step      610: bleu:   0.00, loss: 81759.0312, ppl:   4.1340, duration: 14.1210s\n",
      "2020-02-19 22:24:16,002 Validation result (greedy) at epoch   6, step      620: bleu:   0.39, loss: 81246.7891, ppl:   4.0974, duration: 14.0421s\n",
      "2020-02-19 22:24:17,641 Epoch   6: total training loss 10408.39\n",
      "2020-02-19 22:24:17,641 EPOCH 7\n",
      "2020-02-19 22:24:34,553 Validation result (greedy) at epoch   7, step      630: bleu:   0.46, loss: 80736.1875, ppl:   4.0613, duration: 14.1502s\n",
      "2020-02-19 22:24:52,554 Validation result (greedy) at epoch   7, step      640: bleu:   0.00, loss: 80844.6484, ppl:   4.0689, duration: 14.2463s\n",
      "2020-02-19 22:25:10,712 Validation result (greedy) at epoch   7, step      650: bleu:   0.45, loss: 81005.4297, ppl:   4.0803, duration: 14.2182s\n",
      "2020-02-19 22:25:29,162 Validation result (greedy) at epoch   7, step      660: bleu:   0.00, loss: 79898.3516, ppl:   4.0026, duration: 14.2539s\n",
      "2020-02-19 22:25:47,689 Validation result (greedy) at epoch   7, step      670: bleu:   0.00, loss: 79496.3594, ppl:   3.9748, duration: 14.2104s\n",
      "2020-02-19 22:26:05,857 Validation result (greedy) at epoch   7, step      680: bleu:   0.00, loss: 78998.1328, ppl:   3.9406, duration: 14.2507s\n",
      "2020-02-19 22:26:23,877 Validation result (greedy) at epoch   7, step      690: bleu:   0.00, loss: 78749.2344, ppl:   3.9236, duration: 14.0952s\n",
      "2020-02-19 22:26:41,992 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:26:41,993 Saving new checkpoint.\n",
      "2020-02-19 22:26:42,191 Validation result (greedy) at epoch   7, step      700: bleu:   0.66, loss: 78371.3047, ppl:   3.8979, duration: 14.3751s\n",
      "2020-02-19 22:27:00,362 Validation result (greedy) at epoch   7, step      710: bleu:   0.00, loss: 78626.6797, ppl:   3.9153, duration: 14.1305s\n",
      "2020-02-19 22:27:18,584 Validation result (greedy) at epoch   7, step      720: bleu:   0.35, loss: 78223.0234, ppl:   3.8879, duration: 14.1610s\n",
      "2020-02-19 22:27:22,099 Epoch   7: total training loss 9918.93\n",
      "2020-02-19 22:27:22,100 EPOCH 8\n",
      "2020-02-19 22:27:37,271 Validation result (greedy) at epoch   8, step      730: bleu:   0.42, loss: 77540.1172, ppl:   3.8421, duration: 14.1348s\n",
      "2020-02-19 22:27:55,845 Validation result (greedy) at epoch   8, step      740: bleu:   0.00, loss: 77400.5781, ppl:   3.8328, duration: 14.1518s\n",
      "2020-02-19 22:28:13,854 Validation result (greedy) at epoch   8, step      750: bleu:   0.00, loss: 77577.2188, ppl:   3.8446, duration: 14.1285s\n",
      "2020-02-19 22:28:31,742 Validation result (greedy) at epoch   8, step      760: bleu:   0.00, loss: 77833.6172, ppl:   3.8617, duration: 14.1050s\n",
      "2020-02-19 22:28:50,276 Validation result (greedy) at epoch   8, step      770: bleu:   0.42, loss: 76579.4609, ppl:   3.7786, duration: 14.1344s\n",
      "2020-02-19 22:29:08,509 Validation result (greedy) at epoch   8, step      780: bleu:   0.39, loss: 76791.2578, ppl:   3.7925, duration: 14.0786s\n",
      "2020-02-19 22:29:26,799 Validation result (greedy) at epoch   8, step      790: bleu:   0.00, loss: 76520.5625, ppl:   3.7747, duration: 14.1157s\n",
      "2020-02-19 22:29:45,003 Validation result (greedy) at epoch   8, step      800: bleu:   0.49, loss: 77320.2891, ppl:   3.8275, duration: 14.1332s\n",
      "2020-02-19 22:30:03,343 Validation result (greedy) at epoch   8, step      810: bleu:   0.38, loss: 75911.4922, ppl:   3.7350, duration: 14.1450s\n",
      "2020-02-19 22:30:21,476 Validation result (greedy) at epoch   8, step      820: bleu:   0.00, loss: 75659.1562, ppl:   3.7187, duration: 14.1481s\n",
      "2020-02-19 22:30:39,871 Validation result (greedy) at epoch   8, step      830: bleu:   0.00, loss: 75474.9062, ppl:   3.7068, duration: 14.1092s\n",
      "2020-02-19 22:30:40,625 Epoch   8: total training loss 9528.31\n",
      "2020-02-19 22:30:40,626 EPOCH 9\n",
      "2020-02-19 22:30:58,588 Validation result (greedy) at epoch   9, step      840: bleu:   0.54, loss: 75175.4375, ppl:   3.6876, duration: 14.2197s\n",
      "2020-02-19 22:31:17,230 Validation result (greedy) at epoch   9, step      850: bleu:   0.00, loss: 74820.8594, ppl:   3.6650, duration: 14.2276s\n",
      "2020-02-19 22:31:35,485 Validation result (greedy) at epoch   9, step      860: bleu:   0.40, loss: 75199.6719, ppl:   3.6891, duration: 14.0752s\n",
      "2020-02-19 22:31:53,851 Validation result (greedy) at epoch   9, step      870: bleu:   0.00, loss: 74652.6016, ppl:   3.6543, duration: 14.1685s\n",
      "2020-02-19 22:32:12,102 Validation result (greedy) at epoch   9, step      880: bleu:   0.00, loss: 74459.3750, ppl:   3.6420, duration: 14.0977s\n",
      "2020-02-19 22:32:30,080 Validation result (greedy) at epoch   9, step      890: bleu:   0.00, loss: 74740.6641, ppl:   3.6599, duration: 14.1975s\n",
      "2020-02-19 22:32:48,345 Validation result (greedy) at epoch   9, step      900: bleu:   0.46, loss: 74226.5078, ppl:   3.6273, duration: 14.1175s\n",
      "2020-02-19 22:33:06,793 Validation result (greedy) at epoch   9, step      910: bleu:   0.00, loss: 74189.3125, ppl:   3.6250, duration: 14.2754s\n",
      "2020-02-19 22:33:24,935 Validation result (greedy) at epoch   9, step      920: bleu:   0.00, loss: 73717.8750, ppl:   3.5954, duration: 14.1678s\n",
      "2020-02-19 22:33:43,142 Validation result (greedy) at epoch   9, step      930: bleu:   0.00, loss: 73611.0625, ppl:   3.5888, duration: 14.1704s\n",
      "2020-02-19 22:33:45,690 Epoch   9: total training loss 9155.31\n",
      "2020-02-19 22:33:45,691 EPOCH 10\n",
      "2020-02-19 22:34:01,489 Validation result (greedy) at epoch  10, step      940: bleu:   0.00, loss: 73939.3359, ppl:   3.6093, duration: 14.1604s\n",
      "2020-02-19 22:34:20,037 Validation result (greedy) at epoch  10, step      950: bleu:   0.00, loss: 73560.3438, ppl:   3.5856, duration: 14.1698s\n",
      "2020-02-19 22:34:38,313 Validation result (greedy) at epoch  10, step      960: bleu:   0.00, loss: 73739.0156, ppl:   3.5968, duration: 14.1844s\n",
      "2020-02-19 22:34:56,835 Validation result (greedy) at epoch  10, step      970: bleu:   0.53, loss: 73065.0469, ppl:   3.5549, duration: 14.1551s\n",
      "2020-02-19 22:35:15,184 Validation result (greedy) at epoch  10, step      980: bleu:   0.46, loss: 73127.5000, ppl:   3.5588, duration: 14.2659s\n",
      "2020-02-19 22:35:33,913 Validation result (greedy) at epoch  10, step      990: bleu:   0.50, loss: 72792.1719, ppl:   3.5381, duration: 14.2438s\n",
      "2020-02-19 22:35:37,961 Epoch  10 Step:     1000 Batch Loss:    42.586044 Tokens per Sec:     7603, Lr: 0.000500\n",
      "2020-02-19 22:35:52,173 Validation result (greedy) at epoch  10, step     1000: bleu:   0.43, loss: 72415.0078, ppl:   3.5150, duration: 14.2111s\n",
      "2020-02-19 22:36:10,505 Validation result (greedy) at epoch  10, step     1010: bleu:   0.48, loss: 72358.2500, ppl:   3.5116, duration: 14.2691s\n",
      "2020-02-19 22:36:27,823 Validation result (greedy) at epoch  10, step     1020: bleu:   0.37, loss: 72789.5391, ppl:   3.5380, duration: 14.0684s\n",
      "2020-02-19 22:36:46,187 Validation result (greedy) at epoch  10, step     1030: bleu:   0.47, loss: 72412.3125, ppl:   3.5149, duration: 14.1768s\n",
      "2020-02-19 22:37:05,093 Validation result (greedy) at epoch  10, step     1040: bleu:   0.47, loss: 72335.5625, ppl:   3.5102, duration: 14.0774s\n",
      "2020-02-19 22:37:05,094 Epoch  10: total training loss 8837.22\n",
      "2020-02-19 22:37:05,094 EPOCH 11\n",
      "2020-02-19 22:37:23,310 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:37:23,310 Saving new checkpoint.\n",
      "2020-02-19 22:37:23,519 Validation result (greedy) at epoch  11, step     1050: bleu:   0.67, loss: 72147.5391, ppl:   3.4988, duration: 14.3848s\n",
      "2020-02-19 22:37:41,072 Validation result (greedy) at epoch  11, step     1060: bleu:   0.62, loss: 71980.4219, ppl:   3.4886, duration: 13.9812s\n",
      "2020-02-19 22:37:58,013 Validation result (greedy) at epoch  11, step     1070: bleu:   0.46, loss: 72015.2812, ppl:   3.4907, duration: 13.9893s\n",
      "2020-02-19 22:38:14,840 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:38:14,840 Saving new checkpoint.\n",
      "2020-02-19 22:38:14,958 Validation result (greedy) at epoch  11, step     1080: bleu:   0.71, loss: 71880.4609, ppl:   3.4826, duration: 14.0626s\n",
      "2020-02-19 22:38:32,029 Validation result (greedy) at epoch  11, step     1090: bleu:   0.63, loss: 71658.4453, ppl:   3.4692, duration: 13.9634s\n",
      "2020-02-19 22:38:48,868 Validation result (greedy) at epoch  11, step     1100: bleu:   0.56, loss: 71896.3828, ppl:   3.4835, duration: 13.9661s\n",
      "2020-02-19 22:39:06,459 Validation result (greedy) at epoch  11, step     1110: bleu:   0.62, loss: 71146.0547, ppl:   3.4385, duration: 13.9743s\n",
      "2020-02-19 22:39:23,400 Validation result (greedy) at epoch  11, step     1120: bleu:   0.63, loss: 71191.9453, ppl:   3.4412, duration: 13.9904s\n",
      "2020-02-19 22:39:41,097 Validation result (greedy) at epoch  11, step     1130: bleu:   0.66, loss: 70947.8594, ppl:   3.4267, duration: 14.0254s\n",
      "2020-02-19 22:39:58,439 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:39:58,440 Saving new checkpoint.\n",
      "2020-02-19 22:39:58,615 Validation result (greedy) at epoch  11, step     1140: bleu:   0.80, loss: 71067.6094, ppl:   3.4338, duration: 14.3564s\n",
      "2020-02-19 22:40:00,396 Epoch  11: total training loss 8584.09\n",
      "2020-02-19 22:40:00,397 EPOCH 12\n",
      "2020-02-19 22:40:17,068 Validation result (greedy) at epoch  12, step     1150: bleu:   0.66, loss: 70967.9453, ppl:   3.4278, duration: 14.0742s\n",
      "2020-02-19 22:40:35,473 Validation result (greedy) at epoch  12, step     1160: bleu:   0.00, loss: 70555.0078, ppl:   3.4034, duration: 14.1673s\n",
      "2020-02-19 22:40:53,477 Validation result (greedy) at epoch  12, step     1170: bleu:   0.73, loss: 70930.2734, ppl:   3.4256, duration: 14.0842s\n",
      "2020-02-19 22:41:11,618 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:41:11,618 Saving new checkpoint.\n",
      "2020-02-19 22:41:11,812 Validation result (greedy) at epoch  12, step     1180: bleu:   0.84, loss: 70410.6875, ppl:   3.3948, duration: 14.3490s\n",
      "2020-02-19 22:41:29,736 Validation result (greedy) at epoch  12, step     1190: bleu:   0.65, loss: 70534.3906, ppl:   3.4021, duration: 14.2739s\n",
      "2020-02-19 22:41:48,362 Validation result (greedy) at epoch  12, step     1200: bleu:   0.68, loss: 70377.8906, ppl:   3.3929, duration: 14.2463s\n",
      "2020-02-19 22:42:07,209 Validation result (greedy) at epoch  12, step     1210: bleu:   0.60, loss: 70111.8672, ppl:   3.3773, duration: 14.2975s\n",
      "2020-02-19 22:42:25,299 Validation result (greedy) at epoch  12, step     1220: bleu:   0.00, loss: 69869.0703, ppl:   3.3631, duration: 14.1527s\n",
      "2020-02-19 22:42:42,400 Validation result (greedy) at epoch  12, step     1230: bleu:   0.69, loss: 70207.8828, ppl:   3.3829, duration: 13.9817s\n",
      "2020-02-19 22:42:59,697 Validation result (greedy) at epoch  12, step     1240: bleu:   0.55, loss: 69799.2969, ppl:   3.3590, duration: 13.9666s\n",
      "2020-02-19 22:43:02,202 Epoch  12: total training loss 8309.20\n",
      "2020-02-19 22:43:02,202 EPOCH 13\n",
      "2020-02-19 22:43:16,745 Validation result (greedy) at epoch  13, step     1250: bleu:   0.69, loss: 69611.1719, ppl:   3.3481, duration: 13.9988s\n",
      "2020-02-19 22:43:33,576 Validation result (greedy) at epoch  13, step     1260: bleu:   0.76, loss: 69897.3516, ppl:   3.3647, duration: 14.0157s\n",
      "2020-02-19 22:43:51,337 Validation result (greedy) at epoch  13, step     1270: bleu:   0.55, loss: 69540.5391, ppl:   3.3440, duration: 14.0024s\n",
      "2020-02-19 22:44:08,248 Validation result (greedy) at epoch  13, step     1280: bleu:   0.64, loss: 70247.0234, ppl:   3.3852, duration: 13.9919s\n",
      "2020-02-19 22:44:26,224 Validation result (greedy) at epoch  13, step     1290: bleu:   0.50, loss: 70324.2812, ppl:   3.3898, duration: 14.1612s\n",
      "2020-02-19 22:44:45,214 Validation result (greedy) at epoch  13, step     1300: bleu:   0.71, loss: 70294.2734, ppl:   3.3880, duration: 14.1935s\n",
      "2020-02-19 22:45:03,219 Validation result (greedy) at epoch  13, step     1310: bleu:   0.74, loss: 69337.1875, ppl:   3.3322, duration: 14.0295s\n",
      "2020-02-19 22:45:21,529 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:45:21,530 Saving new checkpoint.\n",
      "2020-02-19 22:45:21,738 Validation result (greedy) at epoch  13, step     1320: bleu:   0.86, loss: 69136.3906, ppl:   3.3206, duration: 14.3304s\n",
      "2020-02-19 22:45:39,946 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:45:39,947 Saving new checkpoint.\n",
      "2020-02-19 22:45:40,071 Validation result (greedy) at epoch  13, step     1330: bleu:   0.93, loss: 69062.7031, ppl:   3.3163, duration: 14.2299s\n",
      "2020-02-19 22:45:57,990 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:45:57,991 Saving new checkpoint.\n",
      "2020-02-19 22:45:58,119 Validation result (greedy) at epoch  13, step     1340: bleu:   0.96, loss: 69244.1406, ppl:   3.3268, duration: 14.2458s\n",
      "2020-02-19 22:46:15,765 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:46:15,766 Saving new checkpoint.\n",
      "2020-02-19 22:46:15,955 Validation result (greedy) at epoch  13, step     1350: bleu:   1.01, loss: 69085.8125, ppl:   3.3177, duration: 14.3903s\n",
      "2020-02-19 22:46:16,860 Epoch  13: total training loss 8077.90\n",
      "2020-02-19 22:46:16,860 EPOCH 14\n",
      "2020-02-19 22:46:34,331 Validation result (greedy) at epoch  14, step     1360: bleu:   0.77, loss: 69300.5625, ppl:   3.3301, duration: 14.1579s\n",
      "2020-02-19 22:46:52,595 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:46:52,595 Saving new checkpoint.\n",
      "2020-02-19 22:46:52,716 Validation result (greedy) at epoch  14, step     1370: bleu:   1.04, loss: 69266.3828, ppl:   3.3281, duration: 14.3260s\n",
      "2020-02-19 22:47:10,644 Validation result (greedy) at epoch  14, step     1380: bleu:   1.00, loss: 68962.8359, ppl:   3.3106, duration: 14.2011s\n",
      "2020-02-19 22:47:29,255 Validation result (greedy) at epoch  14, step     1390: bleu:   0.94, loss: 69009.1797, ppl:   3.3133, duration: 14.2083s\n",
      "2020-02-19 22:47:47,842 Validation result (greedy) at epoch  14, step     1400: bleu:   0.99, loss: 68687.3828, ppl:   3.2948, duration: 14.1972s\n",
      "2020-02-19 22:48:06,246 Validation result (greedy) at epoch  14, step     1410: bleu:   0.99, loss: 69153.3359, ppl:   3.3216, duration: 14.2022s\n",
      "2020-02-19 22:48:24,749 Validation result (greedy) at epoch  14, step     1420: bleu:   0.75, loss: 68344.7109, ppl:   3.2753, duration: 14.2711s\n",
      "2020-02-19 22:48:42,896 Validation result (greedy) at epoch  14, step     1430: bleu:   0.94, loss: 68532.6875, ppl:   3.2860, duration: 14.2297s\n",
      "2020-02-19 22:49:00,900 Validation result (greedy) at epoch  14, step     1440: bleu:   0.84, loss: 69580.0938, ppl:   3.3463, duration: 14.1701s\n",
      "2020-02-19 22:49:19,375 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:49:19,375 Saving new checkpoint.\n",
      "2020-02-19 22:49:19,572 Validation result (greedy) at epoch  14, step     1450: bleu:   1.09, loss: 68496.6953, ppl:   3.2839, duration: 14.4071s\n",
      "2020-02-19 22:49:21,884 Epoch  14: total training loss 7818.78\n",
      "2020-02-19 22:49:21,884 EPOCH 15\n",
      "2020-02-19 22:49:37,527 Validation result (greedy) at epoch  15, step     1460: bleu:   0.76, loss: 68229.6328, ppl:   3.2687, duration: 14.0184s\n",
      "2020-02-19 22:49:54,524 Validation result (greedy) at epoch  15, step     1470: bleu:   0.90, loss: 68423.7188, ppl:   3.2798, duration: 13.9732s\n",
      "2020-02-19 22:50:11,929 Validation result (greedy) at epoch  15, step     1480: bleu:   1.01, loss: 68459.5234, ppl:   3.2818, duration: 14.0128s\n",
      "2020-02-19 22:50:28,706 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:50:28,706 Saving new checkpoint.\n",
      "2020-02-19 22:50:28,872 Validation result (greedy) at epoch  15, step     1490: bleu:   1.11, loss: 68376.3125, ppl:   3.2771, duration: 14.1497s\n",
      "2020-02-19 22:50:47,209 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:50:47,210 Saving new checkpoint.\n",
      "2020-02-19 22:50:47,382 Validation result (greedy) at epoch  15, step     1500: bleu:   1.13, loss: 68398.8047, ppl:   3.2783, duration: 14.4100s\n",
      "2020-02-19 22:51:04,400 Validation result (greedy) at epoch  15, step     1510: bleu:   0.67, loss: 68513.7891, ppl:   3.2849, duration: 13.9925s\n",
      "2020-02-19 22:51:21,084 Validation result (greedy) at epoch  15, step     1520: bleu:   0.90, loss: 68672.2812, ppl:   3.2939, duration: 13.9547s\n",
      "2020-02-19 22:51:38,579 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:51:38,580 Saving new checkpoint.\n",
      "2020-02-19 22:51:38,713 Validation result (greedy) at epoch  15, step     1530: bleu:   1.17, loss: 68063.9297, ppl:   3.2593, duration: 14.0997s\n",
      "2020-02-19 22:51:55,687 Validation result (greedy) at epoch  15, step     1540: bleu:   0.99, loss: 68046.8828, ppl:   3.2584, duration: 13.9707s\n",
      "2020-02-19 22:52:13,298 Validation result (greedy) at epoch  15, step     1550: bleu:   1.01, loss: 67992.5156, ppl:   3.2553, duration: 14.1385s\n",
      "2020-02-19 22:52:30,308 Validation result (greedy) at epoch  15, step     1560: bleu:   0.79, loss: 68053.4219, ppl:   3.2587, duration: 13.9944s\n",
      "2020-02-19 22:52:30,309 Epoch  15: total training loss 7565.89\n",
      "2020-02-19 22:52:30,309 EPOCH 16\n",
      "2020-02-19 22:52:47,712 Validation result (greedy) at epoch  16, step     1570: bleu:   1.07, loss: 68411.3359, ppl:   3.2790, duration: 14.0291s\n",
      "2020-02-19 22:53:04,767 Validation result (greedy) at epoch  16, step     1580: bleu:   0.91, loss: 68562.9453, ppl:   3.2877, duration: 13.9654s\n",
      "2020-02-19 22:53:21,961 Validation result (greedy) at epoch  16, step     1590: bleu:   1.08, loss: 67966.9922, ppl:   3.2539, duration: 14.0736s\n",
      "2020-02-19 22:53:40,459 Validation result (greedy) at epoch  16, step     1600: bleu:   1.13, loss: 68175.7266, ppl:   3.2657, duration: 14.1549s\n",
      "2020-02-19 22:53:58,536 Validation result (greedy) at epoch  16, step     1610: bleu:   1.07, loss: 68489.1562, ppl:   3.2835, duration: 14.1572s\n",
      "2020-02-19 22:54:17,277 Validation result (greedy) at epoch  16, step     1620: bleu:   1.06, loss: 67859.6797, ppl:   3.2478, duration: 14.1446s\n",
      "2020-02-19 22:54:35,424 Validation result (greedy) at epoch  16, step     1630: bleu:   1.15, loss: 68384.8516, ppl:   3.2775, duration: 14.1110s\n",
      "2020-02-19 22:54:53,748 Validation result (greedy) at epoch  16, step     1640: bleu:   1.09, loss: 67892.7656, ppl:   3.2497, duration: 14.1787s\n",
      "2020-02-19 22:55:12,057 Validation result (greedy) at epoch  16, step     1650: bleu:   0.94, loss: 67563.9062, ppl:   3.2312, duration: 14.1854s\n",
      "2020-02-19 22:55:30,475 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:55:30,476 Saving new checkpoint.\n",
      "2020-02-19 22:55:30,668 Validation result (greedy) at epoch  16, step     1660: bleu:   1.20, loss: 67953.5625, ppl:   3.2531, duration: 14.3627s\n",
      "2020-02-19 22:55:32,603 Epoch  16: total training loss 7326.13\n",
      "2020-02-19 22:55:32,604 EPOCH 17\n",
      "2020-02-19 22:55:48,959 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:55:48,959 Saving new checkpoint.\n",
      "2020-02-19 22:55:49,084 Validation result (greedy) at epoch  17, step     1670: bleu:   1.24, loss: 67595.4531, ppl:   3.2329, duration: 14.1232s\n",
      "2020-02-19 22:56:07,307 Validation result (greedy) at epoch  17, step     1680: bleu:   0.95, loss: 67974.7656, ppl:   3.2543, duration: 14.1441s\n",
      "2020-02-19 22:56:24,786 Validation result (greedy) at epoch  17, step     1690: bleu:   1.05, loss: 68064.2422, ppl:   3.2593, duration: 13.9278s\n",
      "2020-02-19 22:56:42,489 Validation result (greedy) at epoch  17, step     1700: bleu:   1.10, loss: 67871.0859, ppl:   3.2484, duration: 13.9730s\n",
      "2020-02-19 22:57:00,923 Validation result (greedy) at epoch  17, step     1710: bleu:   1.23, loss: 68072.0703, ppl:   3.2598, duration: 14.1072s\n",
      "2020-02-19 22:57:19,209 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 22:57:19,209 Saving new checkpoint.\n",
      "2020-02-19 22:57:19,343 Validation result (greedy) at epoch  17, step     1720: bleu:   1.37, loss: 68083.4531, ppl:   3.2604, duration: 14.1808s\n",
      "2020-02-19 22:57:37,272 Validation result (greedy) at epoch  17, step     1730: bleu:   1.09, loss: 67804.8828, ppl:   3.2447, duration: 14.1794s\n",
      "2020-02-19 22:57:55,174 Validation result (greedy) at epoch  17, step     1740: bleu:   1.14, loss: 68204.7891, ppl:   3.2673, duration: 14.2213s\n",
      "2020-02-19 22:58:13,684 Validation result (greedy) at epoch  17, step     1750: bleu:   1.27, loss: 67562.8281, ppl:   3.2311, duration: 14.2680s\n",
      "2020-02-19 22:58:32,005 Validation result (greedy) at epoch  17, step     1760: bleu:   1.17, loss: 67639.5000, ppl:   3.2354, duration: 14.1859s\n",
      "2020-02-19 22:58:35,188 Epoch  17: total training loss 7074.21\n",
      "2020-02-19 22:58:35,189 EPOCH 18\n",
      "2020-02-19 22:58:49,945 Validation result (greedy) at epoch  18, step     1770: bleu:   1.32, loss: 67760.8203, ppl:   3.2422, duration: 14.0051s\n",
      "2020-02-19 22:59:08,014 Validation result (greedy) at epoch  18, step     1780: bleu:   1.32, loss: 69316.4844, ppl:   3.3310, duration: 14.0064s\n",
      "2020-02-19 22:59:26,244 Validation result (greedy) at epoch  18, step     1790: bleu:   0.61, loss: 67936.8125, ppl:   3.2521, duration: 13.9948s\n",
      "2020-02-19 22:59:44,670 Validation result (greedy) at epoch  18, step     1800: bleu:   1.26, loss: 67878.3672, ppl:   3.2488, duration: 14.1400s\n",
      "2020-02-19 23:00:02,432 Validation result (greedy) at epoch  18, step     1810: bleu:   1.19, loss: 68385.6406, ppl:   3.2776, duration: 14.0927s\n",
      "2020-02-19 23:00:20,930 Validation result (greedy) at epoch  18, step     1820: bleu:   1.29, loss: 68240.4766, ppl:   3.2693, duration: 14.1343s\n",
      "2020-02-19 23:00:38,816 Validation result (greedy) at epoch  18, step     1830: bleu:   1.04, loss: 68518.0781, ppl:   3.2851, duration: 14.2847s\n",
      "2020-02-19 23:00:56,550 Validation result (greedy) at epoch  18, step     1840: bleu:   1.28, loss: 68924.2812, ppl:   3.3084, duration: 14.0026s\n",
      "2020-02-19 23:01:14,429 Validation result (greedy) at epoch  18, step     1850: bleu:   1.26, loss: 67904.8984, ppl:   3.2503, duration: 14.0822s\n",
      "2020-02-19 23:01:32,496 Validation result (greedy) at epoch  18, step     1860: bleu:   1.22, loss: 67789.3438, ppl:   3.2438, duration: 14.1047s\n",
      "2020-02-19 23:01:49,372 Validation result (greedy) at epoch  18, step     1870: bleu:   1.34, loss: 67688.9688, ppl:   3.2382, duration: 14.0176s\n",
      "2020-02-19 23:01:49,974 Epoch  18: total training loss 6835.57\n",
      "2020-02-19 23:01:49,974 EPOCH 19\n",
      "2020-02-19 23:02:06,409 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:02:06,409 Saving new checkpoint.\n",
      "2020-02-19 23:02:06,536 Validation result (greedy) at epoch  19, step     1880: bleu:   1.39, loss: 68301.6016, ppl:   3.2728, duration: 14.0806s\n",
      "2020-02-19 23:02:23,708 Validation result (greedy) at epoch  19, step     1890: bleu:   1.33, loss: 68570.0625, ppl:   3.2881, duration: 14.0332s\n",
      "2020-02-19 23:02:40,629 Validation result (greedy) at epoch  19, step     1900: bleu:   1.07, loss: 69025.2812, ppl:   3.3142, duration: 14.1713s\n",
      "2020-02-19 23:02:59,199 Validation result (greedy) at epoch  19, step     1910: bleu:   1.11, loss: 68731.9688, ppl:   3.2973, duration: 14.1825s\n",
      "2020-02-19 23:03:18,227 Validation result (greedy) at epoch  19, step     1920: bleu:   1.35, loss: 68204.4531, ppl:   3.2673, duration: 14.4295s\n",
      "2020-02-19 23:03:36,454 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:03:36,455 Saving new checkpoint.\n",
      "2020-02-19 23:03:36,635 Validation result (greedy) at epoch  19, step     1930: bleu:   1.45, loss: 68551.5469, ppl:   3.2870, duration: 14.4807s\n",
      "2020-02-19 23:03:55,171 Validation result (greedy) at epoch  19, step     1940: bleu:   1.29, loss: 68830.3281, ppl:   3.3030, duration: 14.1925s\n",
      "2020-02-19 23:04:13,622 Validation result (greedy) at epoch  19, step     1950: bleu:   1.29, loss: 68419.4453, ppl:   3.2795, duration: 14.2031s\n",
      "2020-02-19 23:04:32,094 Validation result (greedy) at epoch  19, step     1960: bleu:   1.22, loss: 68526.8906, ppl:   3.2856, duration: 14.2253s\n",
      "2020-02-19 23:04:50,621 Validation result (greedy) at epoch  19, step     1970: bleu:   1.26, loss: 68053.3359, ppl:   3.2587, duration: 14.1733s\n",
      "2020-02-19 23:04:52,798 Epoch  19: total training loss 6615.93\n",
      "2020-02-19 23:04:52,799 EPOCH 20\n",
      "2020-02-19 23:05:08,618 Validation result (greedy) at epoch  20, step     1980: bleu:   1.40, loss: 68113.5703, ppl:   3.2621, duration: 14.1990s\n",
      "2020-02-19 23:05:27,136 Validation result (greedy) at epoch  20, step     1990: bleu:   1.39, loss: 68531.8203, ppl:   3.2859, duration: 14.1992s\n",
      "2020-02-19 23:05:31,500 Epoch  20 Step:     2000 Batch Loss:    24.921848 Tokens per Sec:     7133, Lr: 0.000500\n",
      "2020-02-19 23:05:45,737 Validation result (greedy) at epoch  20, step     2000: bleu:   1.39, loss: 68550.0156, ppl:   3.2869, duration: 14.2359s\n",
      "2020-02-19 23:06:04,437 Validation result (greedy) at epoch  20, step     2010: bleu:   1.42, loss: 68819.9688, ppl:   3.3024, duration: 14.2228s\n",
      "2020-02-19 23:06:22,887 Validation result (greedy) at epoch  20, step     2020: bleu:   1.36, loss: 68829.2812, ppl:   3.3029, duration: 14.1277s\n",
      "2020-02-19 23:06:41,385 Validation result (greedy) at epoch  20, step     2030: bleu:   1.23, loss: 69242.8438, ppl:   3.3267, duration: 14.1848s\n",
      "2020-02-19 23:06:59,597 Validation result (greedy) at epoch  20, step     2040: bleu:   1.11, loss: 68821.9766, ppl:   3.3025, duration: 14.1797s\n",
      "2020-02-19 23:07:17,874 Validation result (greedy) at epoch  20, step     2050: bleu:   1.15, loss: 70395.5625, ppl:   3.3940, duration: 14.2341s\n",
      "2020-02-19 23:07:36,638 Validation result (greedy) at epoch  20, step     2060: bleu:   1.39, loss: 69218.4219, ppl:   3.3253, duration: 14.2215s\n",
      "2020-02-19 23:07:55,083 Validation result (greedy) at epoch  20, step     2070: bleu:   1.35, loss: 68981.6953, ppl:   3.3117, duration: 14.1857s\n",
      "2020-02-19 23:08:13,229 Validation result (greedy) at epoch  20, step     2080: bleu:   1.26, loss: 68250.0547, ppl:   3.2699, duration: 13.7405s\n",
      "2020-02-19 23:08:13,230 Epoch  20: total training loss 6398.61\n",
      "2020-02-19 23:08:13,230 EPOCH 21\n",
      "2020-02-19 23:08:31,165 Validation result (greedy) at epoch  21, step     2090: bleu:   1.29, loss: 69049.4297, ppl:   3.3156, duration: 13.7870s\n",
      "2020-02-19 23:08:49,339 Validation result (greedy) at epoch  21, step     2100: bleu:   1.15, loss: 69178.7578, ppl:   3.3230, duration: 13.8937s\n",
      "2020-02-19 23:09:07,868 Validation result (greedy) at epoch  21, step     2110: bleu:   1.07, loss: 68851.2734, ppl:   3.3042, duration: 13.8291s\n",
      "2020-02-19 23:09:26,177 Validation result (greedy) at epoch  21, step     2120: bleu:   1.36, loss: 68876.9766, ppl:   3.3057, duration: 13.8183s\n",
      "2020-02-19 23:09:44,425 Validation result (greedy) at epoch  21, step     2130: bleu:   1.21, loss: 69075.9844, ppl:   3.3171, duration: 14.2052s\n",
      "2020-02-19 23:10:02,093 Validation result (greedy) at epoch  21, step     2140: bleu:   1.42, loss: 69303.1016, ppl:   3.3302, duration: 14.0123s\n",
      "2020-02-19 23:10:19,861 Validation result (greedy) at epoch  21, step     2150: bleu:   1.36, loss: 69789.6641, ppl:   3.3584, duration: 13.9572s\n",
      "2020-02-19 23:10:37,944 Validation result (greedy) at epoch  21, step     2160: bleu:   1.30, loss: 71676.9062, ppl:   3.4703, duration: 14.0450s\n",
      "2020-02-19 23:10:56,117 Validation result (greedy) at epoch  21, step     2170: bleu:   1.39, loss: 69688.2266, ppl:   3.3525, duration: 14.1903s\n",
      "2020-02-19 23:11:13,705 Validation result (greedy) at epoch  21, step     2180: bleu:   1.17, loss: 69378.1875, ppl:   3.3345, duration: 14.0042s\n",
      "2020-02-19 23:11:15,421 Epoch  21: total training loss 6073.37\n",
      "2020-02-19 23:11:15,421 EPOCH 22\n",
      "2020-02-19 23:11:32,125 Validation result (greedy) at epoch  22, step     2190: bleu:   1.28, loss: 69439.7344, ppl:   3.3381, duration: 14.2103s\n",
      "2020-02-19 23:11:50,439 Validation result (greedy) at epoch  22, step     2200: bleu:   1.12, loss: 69789.1484, ppl:   3.3584, duration: 14.1783s\n",
      "2020-02-19 23:12:08,131 Validation result (greedy) at epoch  22, step     2210: bleu:   1.37, loss: 70241.1328, ppl:   3.3849, duration: 14.1023s\n",
      "2020-02-19 23:12:25,977 Validation result (greedy) at epoch  22, step     2220: bleu:   1.12, loss: 70330.9219, ppl:   3.3902, duration: 14.1176s\n",
      "2020-02-19 23:12:44,686 Validation result (greedy) at epoch  22, step     2230: bleu:   1.40, loss: 70060.3438, ppl:   3.3743, duration: 14.1958s\n",
      "2020-02-19 23:13:02,806 Validation result (greedy) at epoch  22, step     2240: bleu:   1.34, loss: 70531.1094, ppl:   3.4020, duration: 14.1294s\n",
      "2020-02-19 23:13:21,985 Validation result (greedy) at epoch  22, step     2250: bleu:   1.21, loss: 70208.1328, ppl:   3.3829, duration: 14.4318s\n",
      "2020-02-19 23:13:41,101 Validation result (greedy) at epoch  22, step     2260: bleu:   1.36, loss: 70237.3047, ppl:   3.3846, duration: 14.6503s\n",
      "2020-02-19 23:13:59,443 Validation result (greedy) at epoch  22, step     2270: bleu:   1.37, loss: 69916.9766, ppl:   3.3659, duration: 14.2241s\n",
      "2020-02-19 23:14:17,754 Validation result (greedy) at epoch  22, step     2280: bleu:   1.31, loss: 69656.1797, ppl:   3.3507, duration: 14.2379s\n",
      "2020-02-19 23:14:21,336 Epoch  22: total training loss 5807.45\n",
      "2020-02-19 23:14:21,337 EPOCH 23\n",
      "2020-02-19 23:14:36,270 Validation result (greedy) at epoch  23, step     2290: bleu:   1.41, loss: 70182.8359, ppl:   3.3814, duration: 14.0117s\n",
      "2020-02-19 23:14:54,384 Validation result (greedy) at epoch  23, step     2300: bleu:   1.38, loss: 71016.3906, ppl:   3.4307, duration: 14.1599s\n",
      "2020-02-19 23:15:12,614 Validation result (greedy) at epoch  23, step     2310: bleu:   1.21, loss: 70897.9688, ppl:   3.4237, duration: 14.1720s\n",
      "2020-02-19 23:15:31,122 Validation result (greedy) at epoch  23, step     2320: bleu:   1.36, loss: 71073.9688, ppl:   3.4342, duration: 14.2012s\n",
      "2020-02-19 23:15:49,599 Validation result (greedy) at epoch  23, step     2330: bleu:   1.04, loss: 71946.4453, ppl:   3.4866, duration: 14.1680s\n",
      "2020-02-19 23:16:08,290 Validation result (greedy) at epoch  23, step     2340: bleu:   1.06, loss: 72499.7188, ppl:   3.5202, duration: 14.2292s\n",
      "2020-02-19 23:16:26,231 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:16:26,231 Saving new checkpoint.\n",
      "2020-02-19 23:16:26,355 Validation result (greedy) at epoch  23, step     2350: bleu:   1.51, loss: 71119.0703, ppl:   3.4369, duration: 14.2211s\n",
      "2020-02-19 23:16:44,980 Validation result (greedy) at epoch  23, step     2360: bleu:   1.35, loss: 71364.1094, ppl:   3.4515, duration: 14.1808s\n",
      "2020-02-19 23:17:03,430 Validation result (greedy) at epoch  23, step     2370: bleu:   1.13, loss: 70733.0625, ppl:   3.4139, duration: 14.2739s\n",
      "2020-02-19 23:17:21,136 Validation result (greedy) at epoch  23, step     2380: bleu:   0.98, loss: 71016.6406, ppl:   3.4307, duration: 14.1590s\n",
      "2020-02-19 23:17:39,727 Validation result (greedy) at epoch  23, step     2390: bleu:   1.21, loss: 70775.3359, ppl:   3.4164, duration: 14.2436s\n",
      "2020-02-19 23:17:40,592 Epoch  23: total training loss 5604.36\n",
      "2020-02-19 23:17:40,592 EPOCH 24\n",
      "2020-02-19 23:17:57,980 Validation result (greedy) at epoch  24, step     2400: bleu:   1.12, loss: 73339.4375, ppl:   3.5719, duration: 14.1749s\n",
      "2020-02-19 23:18:16,545 Validation result (greedy) at epoch  24, step     2410: bleu:   1.50, loss: 70934.9453, ppl:   3.4259, duration: 14.4442s\n",
      "2020-02-19 23:18:35,046 Validation result (greedy) at epoch  24, step     2420: bleu:   1.42, loss: 71269.0312, ppl:   3.4458, duration: 14.2609s\n",
      "2020-02-19 23:18:53,393 Validation result (greedy) at epoch  24, step     2430: bleu:   1.08, loss: 71693.6719, ppl:   3.4713, duration: 14.2459s\n",
      "2020-02-19 23:19:12,074 Validation result (greedy) at epoch  24, step     2440: bleu:   1.23, loss: 72563.9297, ppl:   3.5241, duration: 14.3638s\n",
      "2020-02-19 23:19:30,892 Validation result (greedy) at epoch  24, step     2450: bleu:   1.15, loss: 72563.9219, ppl:   3.5241, duration: 14.1616s\n",
      "2020-02-19 23:19:49,312 Validation result (greedy) at epoch  24, step     2460: bleu:   1.42, loss: 72333.7031, ppl:   3.5101, duration: 14.1118s\n",
      "2020-02-19 23:20:07,834 Validation result (greedy) at epoch  24, step     2470: bleu:   1.13, loss: 72603.8594, ppl:   3.5266, duration: 14.2681s\n",
      "2020-02-19 23:20:26,331 Validation result (greedy) at epoch  24, step     2480: bleu:   1.31, loss: 72459.1797, ppl:   3.5177, duration: 14.3109s\n",
      "2020-02-19 23:20:44,905 Validation result (greedy) at epoch  24, step     2490: bleu:   1.22, loss: 72184.7812, ppl:   3.5010, duration: 14.4029s\n",
      "2020-02-19 23:20:47,432 Epoch  24: total training loss 5338.58\n",
      "2020-02-19 23:20:47,432 EPOCH 25\n",
      "2020-02-19 23:21:03,072 Validation result (greedy) at epoch  25, step     2500: bleu:   1.34, loss: 72945.5234, ppl:   3.5476, duration: 14.0930s\n",
      "2020-02-19 23:21:21,023 Validation result (greedy) at epoch  25, step     2510: bleu:   1.47, loss: 73259.8594, ppl:   3.5670, duration: 14.1564s\n",
      "2020-02-19 23:21:40,277 Validation result (greedy) at epoch  25, step     2520: bleu:   1.31, loss: 72540.2266, ppl:   3.5227, duration: 14.7475s\n",
      "2020-02-19 23:21:57,638 Validation result (greedy) at epoch  25, step     2530: bleu:   1.17, loss: 73460.4766, ppl:   3.5794, duration: 14.2336s\n",
      "2020-02-19 23:22:15,643 Validation result (greedy) at epoch  25, step     2540: bleu:   0.87, loss: 73295.9062, ppl:   3.5692, duration: 14.3137s\n",
      "2020-02-19 23:22:33,401 Validation result (greedy) at epoch  25, step     2550: bleu:   1.14, loss: 73467.7656, ppl:   3.5799, duration: 14.3949s\n",
      "2020-02-19 23:22:51,397 Validation result (greedy) at epoch  25, step     2560: bleu:   1.28, loss: 73655.6562, ppl:   3.5916, duration: 14.4424s\n",
      "2020-02-19 23:23:08,609 Validation result (greedy) at epoch  25, step     2570: bleu:   1.15, loss: 72862.7031, ppl:   3.5425, duration: 14.4030s\n",
      "2020-02-19 23:23:26,439 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:23:26,439 Saving new checkpoint.\n",
      "2020-02-19 23:23:26,602 Validation result (greedy) at epoch  25, step     2580: bleu:   1.56, loss: 73665.2422, ppl:   3.5922, duration: 14.7609s\n",
      "2020-02-19 23:23:44,419 Validation result (greedy) at epoch  25, step     2590: bleu:   1.24, loss: 73011.0312, ppl:   3.5516, duration: 14.4983s\n",
      "2020-02-19 23:24:02,475 Validation result (greedy) at epoch  25, step     2600: bleu:   1.36, loss: 73238.8672, ppl:   3.5657, duration: 14.3400s\n",
      "2020-02-19 23:24:02,476 Epoch  25: total training loss 5098.71\n",
      "2020-02-19 23:24:02,476 EPOCH 26\n",
      "2020-02-19 23:24:20,317 Validation result (greedy) at epoch  26, step     2610: bleu:   0.96, loss: 73863.4922, ppl:   3.6045, duration: 14.5412s\n",
      "2020-02-19 23:24:37,990 Validation result (greedy) at epoch  26, step     2620: bleu:   1.13, loss: 74376.0859, ppl:   3.6368, duration: 14.2018s\n",
      "2020-02-19 23:24:54,968 Validation result (greedy) at epoch  26, step     2630: bleu:   1.48, loss: 74843.4375, ppl:   3.6664, duration: 14.0217s\n",
      "2020-02-19 23:25:11,482 Validation result (greedy) at epoch  26, step     2640: bleu:   1.31, loss: 75409.2266, ppl:   3.7026, duration: 13.9994s\n",
      "2020-02-19 23:25:30,043 Validation result (greedy) at epoch  26, step     2650: bleu:   1.14, loss: 74310.5938, ppl:   3.6326, duration: 14.0715s\n",
      "2020-02-19 23:25:48,353 Validation result (greedy) at epoch  26, step     2660: bleu:   1.22, loss: 75144.0625, ppl:   3.6856, duration: 13.9955s\n",
      "2020-02-19 23:26:06,682 Validation result (greedy) at epoch  26, step     2670: bleu:   1.39, loss: 74900.3359, ppl:   3.6700, duration: 14.1553s\n",
      "2020-02-19 23:26:25,120 Validation result (greedy) at epoch  26, step     2680: bleu:   1.31, loss: 75347.1172, ppl:   3.6986, duration: 14.1356s\n",
      "2020-02-19 23:26:43,413 Validation result (greedy) at epoch  26, step     2690: bleu:   1.39, loss: 74991.8047, ppl:   3.6758, duration: 14.1418s\n",
      "2020-02-19 23:27:01,717 Validation result (greedy) at epoch  26, step     2700: bleu:   1.22, loss: 74166.8047, ppl:   3.6236, duration: 14.1954s\n",
      "2020-02-19 23:27:03,317 Epoch  26: total training loss 4879.24\n",
      "2020-02-19 23:27:03,317 EPOCH 27\n",
      "2020-02-19 23:27:19,793 Validation result (greedy) at epoch  27, step     2710: bleu:   1.17, loss: 75427.6797, ppl:   3.7038, duration: 14.0034s\n",
      "2020-02-19 23:27:37,495 Validation result (greedy) at epoch  27, step     2720: bleu:   1.16, loss: 76687.4922, ppl:   3.7857, duration: 14.1501s\n",
      "2020-02-19 23:27:55,051 Validation result (greedy) at epoch  27, step     2730: bleu:   1.37, loss: 76395.9531, ppl:   3.7665, duration: 14.1677s\n",
      "2020-02-19 23:28:13,400 Validation result (greedy) at epoch  27, step     2740: bleu:   1.23, loss: 75916.3516, ppl:   3.7353, duration: 14.0726s\n",
      "2020-02-19 23:28:31,931 Validation result (greedy) at epoch  27, step     2750: bleu:   1.54, loss: 76276.1953, ppl:   3.7587, duration: 14.1595s\n",
      "2020-02-19 23:28:50,153 Validation result (greedy) at epoch  27, step     2760: bleu:   1.16, loss: 77040.0234, ppl:   3.8089, duration: 14.2006s\n",
      "2020-02-19 23:29:08,797 Validation result (greedy) at epoch  27, step     2770: bleu:   1.44, loss: 76220.6484, ppl:   3.7551, duration: 14.3888s\n",
      "2020-02-19 23:29:27,220 Validation result (greedy) at epoch  27, step     2780: bleu:   1.12, loss: 76468.9531, ppl:   3.7713, duration: 14.1713s\n",
      "2020-02-19 23:29:45,754 Validation result (greedy) at epoch  27, step     2790: bleu:   1.18, loss: 76542.6797, ppl:   3.7761, duration: 14.1762s\n",
      "2020-02-19 23:30:04,514 Validation result (greedy) at epoch  27, step     2800: bleu:   1.15, loss: 75885.1719, ppl:   3.7333, duration: 14.1209s\n",
      "2020-02-19 23:30:08,008 Epoch  27: total training loss 4665.08\n",
      "2020-02-19 23:30:08,008 EPOCH 28\n",
      "2020-02-19 23:30:22,917 Validation result (greedy) at epoch  28, step     2810: bleu:   1.25, loss: 76051.8594, ppl:   3.7441, duration: 14.1665s\n",
      "2020-02-19 23:30:41,074 Validation result (greedy) at epoch  28, step     2820: bleu:   1.27, loss: 76846.3984, ppl:   3.7961, duration: 14.1869s\n",
      "2020-02-19 23:30:58,884 Validation result (greedy) at epoch  28, step     2830: bleu:   1.04, loss: 78038.8750, ppl:   3.8755, duration: 14.1818s\n",
      "2020-02-19 23:31:17,479 Validation result (greedy) at epoch  28, step     2840: bleu:   1.11, loss: 77261.7031, ppl:   3.8236, duration: 14.1788s\n",
      "2020-02-19 23:31:36,072 Validation result (greedy) at epoch  28, step     2850: bleu:   1.26, loss: 77522.0312, ppl:   3.8409, duration: 14.1718s\n",
      "2020-02-19 23:31:54,819 Validation result (greedy) at epoch  28, step     2860: bleu:   1.17, loss: 76913.7891, ppl:   3.8006, duration: 14.2396s\n",
      "2020-02-19 23:32:13,430 Validation result (greedy) at epoch  28, step     2870: bleu:   1.24, loss: 77750.2891, ppl:   3.8561, duration: 14.1644s\n",
      "2020-02-19 23:32:31,727 Validation result (greedy) at epoch  28, step     2880: bleu:   0.95, loss: 78112.1953, ppl:   3.8804, duration: 14.2112s\n",
      "2020-02-19 23:32:50,156 Validation result (greedy) at epoch  28, step     2890: bleu:   1.17, loss: 77218.2266, ppl:   3.8207, duration: 14.1927s\n",
      "2020-02-19 23:33:08,295 Validation result (greedy) at epoch  28, step     2900: bleu:   0.99, loss: 77617.2656, ppl:   3.8472, duration: 14.1583s\n",
      "2020-02-19 23:33:26,940 Validation result (greedy) at epoch  28, step     2910: bleu:   1.02, loss: 76907.6250, ppl:   3.8001, duration: 14.1931s\n",
      "2020-02-19 23:33:27,733 Epoch  28: total training loss 4466.80\n",
      "2020-02-19 23:33:27,734 EPOCH 29\n",
      "2020-02-19 23:33:45,184 Validation result (greedy) at epoch  29, step     2920: bleu:   1.24, loss: 77866.9609, ppl:   3.8640, duration: 14.1562s\n",
      "2020-02-19 23:34:02,999 Validation result (greedy) at epoch  29, step     2930: bleu:   1.17, loss: 79763.8828, ppl:   3.9933, duration: 14.1092s\n",
      "2020-02-19 23:34:21,225 Validation result (greedy) at epoch  29, step     2940: bleu:   1.24, loss: 79401.7500, ppl:   3.9683, duration: 14.1661s\n",
      "2020-02-19 23:34:40,112 Validation result (greedy) at epoch  29, step     2950: bleu:   0.92, loss: 79981.6953, ppl:   4.0084, duration: 14.1665s\n",
      "2020-02-19 23:34:58,428 Validation result (greedy) at epoch  29, step     2960: bleu:   1.43, loss: 79095.5156, ppl:   3.9473, duration: 14.1567s\n",
      "2020-02-19 23:35:17,058 Validation result (greedy) at epoch  29, step     2970: bleu:   1.43, loss: 79275.7266, ppl:   3.9596, duration: 14.0940s\n",
      "2020-02-19 23:35:35,418 Validation result (greedy) at epoch  29, step     2980: bleu:   1.30, loss: 79816.0312, ppl:   3.9969, duration: 14.1587s\n",
      "2020-02-19 23:35:53,684 Validation result (greedy) at epoch  29, step     2990: bleu:   1.08, loss: 79392.5469, ppl:   3.9677, duration: 14.1243s\n",
      "2020-02-19 23:35:57,698 Epoch  29 Step:     3000 Batch Loss:    67.414734 Tokens per Sec:     7591, Lr: 0.000500\n",
      "2020-02-19 23:36:11,851 Validation result (greedy) at epoch  29, step     3000: bleu:   1.38, loss: 80717.3516, ppl:   4.0600, duration: 14.1514s\n",
      "2020-02-19 23:36:30,111 Validation result (greedy) at epoch  29, step     3010: bleu:   1.11, loss: 81237.1641, ppl:   4.0968, duration: 14.1662s\n",
      "2020-02-19 23:36:32,702 Epoch  29: total training loss 4243.64\n",
      "2020-02-19 23:36:32,703 EPOCH 30\n",
      "2020-02-19 23:36:48,472 Validation result (greedy) at epoch  30, step     3020: bleu:   1.22, loss: 81823.3281, ppl:   4.1387, duration: 14.1447s\n",
      "2020-02-19 23:37:06,607 Validation result (greedy) at epoch  30, step     3030: bleu:   1.19, loss: 79766.2656, ppl:   3.9935, duration: 14.0904s\n",
      "2020-02-19 23:37:24,678 Validation result (greedy) at epoch  30, step     3040: bleu:   1.16, loss: 80133.2578, ppl:   4.0190, duration: 14.1618s\n",
      "2020-02-19 23:37:43,012 Validation result (greedy) at epoch  30, step     3050: bleu:   1.05, loss: 79906.0469, ppl:   4.0032, duration: 14.1539s\n",
      "2020-02-19 23:38:01,127 Validation result (greedy) at epoch  30, step     3060: bleu:   1.11, loss: 80790.6953, ppl:   4.0651, duration: 14.1307s\n",
      "2020-02-19 23:38:19,545 Validation result (greedy) at epoch  30, step     3070: bleu:   1.16, loss: 81658.8438, ppl:   4.1269, duration: 14.1051s\n",
      "2020-02-19 23:38:38,065 Validation result (greedy) at epoch  30, step     3080: bleu:   1.23, loss: 83707.0781, ppl:   4.2762, duration: 14.1694s\n",
      "2020-02-19 23:38:56,448 Validation result (greedy) at epoch  30, step     3090: bleu:   1.50, loss: 80152.9375, ppl:   4.0204, duration: 14.1160s\n",
      "2020-02-19 23:39:14,218 Validation result (greedy) at epoch  30, step     3100: bleu:   1.22, loss: 79847.9844, ppl:   3.9991, duration: 14.1120s\n",
      "2020-02-19 23:39:32,419 Validation result (greedy) at epoch  30, step     3110: bleu:   1.37, loss: 79938.3906, ppl:   4.0054, duration: 14.1108s\n",
      "2020-02-19 23:39:50,702 Validation result (greedy) at epoch  30, step     3120: bleu:   1.30, loss: 79969.7266, ppl:   4.0076, duration: 14.1492s\n",
      "2020-02-19 23:39:50,703 Epoch  30: total training loss 4164.41\n",
      "2020-02-19 23:39:50,703 Training ended after  30 epochs.\n",
      "2020-02-19 23:39:50,703 Best validation result (greedy) at step     2580:   1.56 eval_metric.\n",
      "2020-02-19 23:40:02,041  dev bleu:   1.59 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-02-19 23:40:02,042 Translations saved to: results/translate/es-shp_Religioso_300_512/char/00002580.hyps.dev\n",
      "2020-02-19 23:40:12,799 test bleu:   1.65 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-02-19 23:40:12,799 Translations saved to: results/translate/es-shp_Religioso_300_512/char/00002580.hyps.test\n",
      "results/translate/Religioso/bpe_drop_10000\n",
      "2020-02-19 23:40:15,460 Hello! This is Joey-NMT.\n",
      "2020-02-19 23:40:16.010079: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 23:40:16.010139: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-02-19 23:40:16.010149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-02-19 23:40:16,507 Total params: 18241256\n",
      "2020-02-19 23:40:16,507 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-02-19 23:40:18,247 cfg.name                           : my_experiment\n",
      "2020-02-19 23:40:18,247 cfg.data.src                       : es\n",
      "2020-02-19 23:40:18,247 cfg.data.trg                       : shp\n",
      "2020-02-19 23:40:18,247 cfg.data.train                     : data/translate/preprocessed/Religioso/bpe_drop_10000/train\n",
      "2020-02-19 23:40:18,247 cfg.data.dev                       : data/translate/preprocessed/Religioso/bpe_drop_10000/valid\n",
      "2020-02-19 23:40:18,247 cfg.data.test                      : data/translate/preprocessed/Religioso/bpe_drop_10000/test\n",
      "2020-02-19 23:40:18,247 cfg.data.level                     : bpe\n",
      "2020-02-19 23:40:18,247 cfg.data.lowercase                 : True\n",
      "2020-02-19 23:40:18,247 cfg.data.max_sent_length           : 150\n",
      "2020-02-19 23:40:18,247 cfg.data.src_voc_min_freq          : 1\n",
      "2020-02-19 23:40:18,248 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-02-19 23:40:18,248 cfg.testing.beam_size              : 5\n",
      "2020-02-19 23:40:18,248 cfg.testing.alpha                  : 1.0\n",
      "2020-02-19 23:40:18,248 cfg.training.reset_best_ckpt       : False\n",
      "2020-02-19 23:40:18,248 cfg.training.reset_scheduler       : False\n",
      "2020-02-19 23:40:18,248 cfg.training.reset_optimizer       : False\n",
      "2020-02-19 23:40:18,248 cfg.training.random_seed           : 42\n",
      "2020-02-19 23:40:18,248 cfg.training.optimizer             : adam\n",
      "2020-02-19 23:40:18,248 cfg.training.learning_rate         : 0.0005\n",
      "2020-02-19 23:40:18,248 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-02-19 23:40:18,248 cfg.training.clip_grad_val         : 1.0\n",
      "2020-02-19 23:40:18,248 cfg.training.weight_decay          : 0.0\n",
      "2020-02-19 23:40:18,248 cfg.training.batch_size            : 48\n",
      "2020-02-19 23:40:18,248 cfg.training.batch_type            : sentence\n",
      "2020-02-19 23:40:18,248 cfg.training.eval_batch_size       : 10\n",
      "2020-02-19 23:40:18,248 cfg.training.eval_batch_type       : sentence\n",
      "2020-02-19 23:40:18,248 cfg.training.batch_multiplier      : 1\n",
      "2020-02-19 23:40:18,248 cfg.training.scheduling            : plateau\n",
      "2020-02-19 23:40:18,248 cfg.training.patience              : 600\n",
      "2020-02-19 23:40:18,248 cfg.training.decrease_factor       : 0.5\n",
      "2020-02-19 23:40:18,248 cfg.training.epochs                : 30\n",
      "2020-02-19 23:40:18,248 cfg.training.validation_freq       : 10\n",
      "2020-02-19 23:40:18,248 cfg.training.logging_freq          : 1000\n",
      "2020-02-19 23:40:18,248 cfg.training.eval_metric           : bleu\n",
      "2020-02-19 23:40:18,248 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-02-19 23:40:18,248 cfg.training.model_dir             : results/translate/es-shp_Religioso_300_512/bpe_drop_10000\n",
      "2020-02-19 23:40:18,248 cfg.training.overwrite             : True\n",
      "2020-02-19 23:40:18,249 cfg.training.shuffle               : True\n",
      "2020-02-19 23:40:18,249 cfg.training.use_cuda              : True\n",
      "2020-02-19 23:40:18,249 cfg.training.max_output_length     : 60\n",
      "2020-02-19 23:40:18,249 cfg.training.print_valid_sents     : []\n",
      "2020-02-19 23:40:18,249 cfg.training.keep_last_ckpts       : 3\n",
      "2020-02-19 23:40:18,249 cfg.training.label_smoothing       : 0.0\n",
      "2020-02-19 23:40:18,249 cfg.model.initializer              : xavier\n",
      "2020-02-19 23:40:18,249 cfg.model.init_weight              : 0.01\n",
      "2020-02-19 23:40:18,249 cfg.model.init_gain                : 1.0\n",
      "2020-02-19 23:40:18,249 cfg.model.bias_initializer         : zeros\n",
      "2020-02-19 23:40:18,249 cfg.model.embed_initializer        : normal\n",
      "2020-02-19 23:40:18,249 cfg.model.embed_init_weight        : 0.1\n",
      "2020-02-19 23:40:18,249 cfg.model.embed_init_gain          : 1.0\n",
      "2020-02-19 23:40:18,249 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-02-19 23:40:18,249 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-02-19 23:40:18,249 cfg.model.tied_embeddings          : False\n",
      "2020-02-19 23:40:18,249 cfg.model.tied_softmax             : False\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.type             : recurrent\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.rnn_type         : gru\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.embeddings.scale : False\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.hidden_size      : 512\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.bidirectional    : True\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.dropout          : 0.3\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.num_layers       : 2\n",
      "2020-02-19 23:40:18,249 cfg.model.encoder.freeze           : False\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.type             : recurrent\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.rnn_type         : gru\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.embeddings.scale : False\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.hidden_size      : 512\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.dropout          : 0.3\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.num_layers       : 2\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.input_feeding    : True\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.init_hidden      : last\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.attention        : bahdanau\n",
      "2020-02-19 23:40:18,250 cfg.model.decoder.freeze           : False\n",
      "2020-02-19 23:40:18,250 Data set sizes: \n",
      "\ttrain 5996,\n",
      "\tvalid 749,\n",
      "\ttest 749\n",
      "2020-02-19 23:40:18,250 First training example:\n",
      "\t[SRC] ikaxbi ja non ibon jo@@ ira jawetianbi keyó@@ yamai iki\n",
      "\t[TRG] pero la palabra de@@ l señor permanece et@@ er@@ n@@ amente esta palabra e@@ s el evangelio que se l@@ es ha anunciado a ustedes\n",
      "2020-02-19 23:40:18,250 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) iki (5) ja (6) i@@ (7) a (8) i (9) jato\n",
      "2020-02-19 23:40:18,250 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) y (5) a (6) de (7) que (8) la (9) el\n",
      "2020-02-19 23:40:18,250 Number of Src words (types): 5232\n",
      "2020-02-19 23:40:18,250 Number of Trg words (types): 5246\n",
      "2020-02-19 23:40:18,250 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=5232),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=5246))\n",
      "2020-02-19 23:40:18,255 EPOCH 1\n",
      "2020-02-19 23:40:22,898 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:40:22,899 Saving new checkpoint.\n",
      "2020-02-19 23:40:23,150 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 110775.3828, ppl: 1055.0187, duration: 3.0242s\n",
      "2020-02-19 23:40:27,712 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 105996.7031, ppl: 781.3425, duration: 2.7623s\n",
      "2020-02-19 23:40:32,294 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 106406.6250, ppl: 801.7315, duration: 2.8091s\n",
      "2020-02-19 23:40:36,887 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 106007.7812, ppl: 781.8867, duration: 2.7882s\n",
      "2020-02-19 23:40:42,562 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 105689.3906, ppl: 766.3977, duration: 3.5509s\n",
      "2020-02-19 23:40:47,064 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 105465.6016, ppl: 755.6950, duration: 2.7565s\n",
      "2020-02-19 23:40:52,697 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 105222.1172, ppl: 744.2203, duration: 3.5970s\n",
      "2020-02-19 23:40:56,716 Hooray! New best validation result [eval_metric]!\n",
      "2020-02-19 23:40:56,717 Saving new checkpoint.\n",
      "2020-02-19 23:40:56,889 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 105203.3828, ppl: 743.3447, duration: 2.8978s\n",
      "2020-02-19 23:41:01,964 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 105126.0625, ppl: 739.7415, duration: 3.5410s\n",
      "2020-02-19 23:41:06,882 Validation result (greedy) at epoch   1, step      100: bleu:   0.00, loss: 104894.5312, ppl: 729.0565, duration: 3.6677s\n",
      "2020-02-19 23:41:12,487 Validation result (greedy) at epoch   1, step      110: bleu:   0.00, loss: 104751.8672, ppl: 722.5493, duration: 3.8254s\n",
      "2020-02-19 23:41:17,439 Validation result (greedy) at epoch   1, step      120: bleu:   0.00, loss: 104661.3203, ppl: 718.4496, duration: 3.5930s\n",
      "2020-02-19 23:41:18,241 Epoch   1: total training loss 18257.52\n",
      "2020-02-19 23:41:18,241 EPOCH 2\n",
      "2020-02-19 23:41:22,424 Validation result (greedy) at epoch   2, step      130: bleu:   0.00, loss: 105048.7812, ppl: 736.1577, duration: 3.2498s\n",
      "2020-02-19 23:41:27,767 Validation result (greedy) at epoch   2, step      140: bleu:   0.00, loss: 104912.5859, ppl: 729.8840, duration: 3.5259s\n",
      "2020-02-19 23:41:34,740 Validation result (greedy) at epoch   2, step      150: bleu:   0.00, loss: 104714.2266, ppl: 720.8423, duration: 5.1154s\n",
      "2020-02-19 23:41:41,700 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 104805.4141, ppl: 724.9847, duration: 5.2684s\n",
      "2020-02-19 23:41:48,166 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 104575.6406, ppl: 714.5919, duration: 4.7003s\n",
      "2020-02-19 23:41:54,250 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 104511.0859, ppl: 711.6987, duration: 4.4173s\n",
      "2020-02-19 23:41:59,513 Validation result (greedy) at epoch   2, step      190: bleu:   0.00, loss: 104543.6641, ppl: 713.1574, duration: 3.6666s\n",
      "2020-02-19 23:42:05,313 Validation result (greedy) at epoch   2, step      200: bleu:   0.00, loss: 104653.9688, ppl: 718.1180, duration: 4.2099s\n",
      "2020-02-19 23:42:10,636 Validation result (greedy) at epoch   2, step      210: bleu:   0.00, loss: 104651.2188, ppl: 717.9938, duration: 3.4873s\n",
      "2020-02-19 23:42:16,809 Validation result (greedy) at epoch   2, step      220: bleu:   0.00, loss: 104542.4844, ppl: 713.1044, duration: 4.5971s\n",
      "2020-02-19 23:42:24,034 Validation result (greedy) at epoch   2, step      230: bleu:   0.00, loss: 104702.7031, ppl: 720.3205, duration: 5.5262s\n",
      "2020-02-19 23:42:31,389 Validation result (greedy) at epoch   2, step      240: bleu:   0.00, loss: 104470.4922, ppl: 709.8854, duration: 5.4502s\n",
      "2020-02-19 23:42:36,430 Validation result (greedy) at epoch   2, step      250: bleu:   0.00, loss: 104592.7344, ppl: 715.3599, duration: 3.5045s\n",
      "2020-02-19 23:42:36,430 Epoch   2: total training loss 17767.24\n",
      "2020-02-19 23:42:36,430 EPOCH 3\n",
      "2020-02-19 23:42:41,854 Validation result (greedy) at epoch   3, step      260: bleu:   0.00, loss: 104550.8984, ppl: 713.4815, duration: 3.7676s\n",
      "2020-02-19 23:42:48,438 Validation result (greedy) at epoch   3, step      270: bleu:   0.00, loss: 104378.0312, ppl: 705.7727, duration: 4.4112s\n",
      "2020-02-19 23:42:56,380 Validation result (greedy) at epoch   3, step      280: bleu:   0.00, loss: 104537.0156, ppl: 712.8592, duration: 5.8863s\n",
      "2020-02-19 23:43:01,945 Validation result (greedy) at epoch   3, step      290: bleu:   0.00, loss: 104431.6328, ppl: 708.1541, duration: 3.8865s\n",
      "2020-02-19 23:43:08,080 Validation result (greedy) at epoch   3, step      300: bleu:   0.00, loss: 104190.6016, ppl: 697.5086, duration: 4.1924s\n",
      "2020-02-19 23:43:14,852 Validation result (greedy) at epoch   3, step      310: bleu:   0.00, loss: 104223.6328, ppl: 698.9580, duration: 4.8024s\n",
      "2020-02-19 23:43:22,154 Validation result (greedy) at epoch   3, step      320: bleu:   0.00, loss: 104089.2578, ppl: 693.0806, duration: 5.1754s\n",
      "2020-02-19 23:43:30,135 Validation result (greedy) at epoch   3, step      330: bleu:   0.00, loss: 104280.3516, ppl: 701.4537, duration: 5.9817s\n",
      "2020-02-19 23:43:37,352 Validation result (greedy) at epoch   3, step      340: bleu:   0.00, loss: 104126.8516, ppl: 694.7197, duration: 5.5404s\n",
      "2020-02-19 23:43:43,391 Validation result (greedy) at epoch   3, step      350: bleu:   0.00, loss: 104097.6641, ppl: 693.4468, duration: 4.3262s\n",
      "2020-02-19 23:43:50,203 Validation result (greedy) at epoch   3, step      360: bleu:   0.00, loss: 103903.2188, ppl: 685.0249, duration: 4.9608s\n",
      "2020-02-19 23:43:56,836 Validation result (greedy) at epoch   3, step      370: bleu:   0.00, loss: 103901.0781, ppl: 684.9328, duration: 4.8562s\n",
      "2020-02-19 23:43:57,520 Epoch   3: total training loss 17671.35\n",
      "2020-02-19 23:43:57,521 EPOCH 4\n",
      "2020-02-19 23:44:04,086 Validation result (greedy) at epoch   4, step      380: bleu:   0.00, loss: 103971.8281, ppl: 687.9848, duration: 5.5971s\n",
      "2020-02-19 23:44:10,799 Validation result (greedy) at epoch   4, step      390: bleu:   0.00, loss: 103945.0000, ppl: 686.8261, duration: 4.8350s\n",
      "2020-02-19 23:44:17,663 Validation result (greedy) at epoch   4, step      400: bleu:   0.00, loss: 104230.2734, ppl: 699.2496, duration: 5.1340s\n",
      "2020-02-19 23:44:24,779 Validation result (greedy) at epoch   4, step      410: bleu:   0.00, loss: 103950.1172, ppl: 687.0469, duration: 5.2202s\n",
      "2020-02-19 23:44:31,266 Validation result (greedy) at epoch   4, step      420: bleu:   0.00, loss: 103931.7656, ppl: 686.2549, duration: 4.8683s\n",
      "2020-02-19 23:44:37,747 Validation result (greedy) at epoch   4, step      430: bleu:   0.00, loss: 103916.1953, ppl: 685.5837, duration: 4.6204s\n",
      "2020-02-19 23:44:44,351 Validation result (greedy) at epoch   4, step      440: bleu:   0.00, loss: 104048.6016, ppl: 691.3121, duration: 4.8376s\n",
      "2020-02-19 23:44:51,294 Validation result (greedy) at epoch   4, step      450: bleu:   0.00, loss: 103992.4609, ppl: 688.8774, duration: 5.1559s\n",
      "2020-02-19 23:44:57,763 Validation result (greedy) at epoch   4, step      460: bleu:   0.00, loss: 103778.8281, ppl: 679.6911, duration: 4.2537s\n",
      "2020-02-19 23:45:04,665 Validation result (greedy) at epoch   4, step      470: bleu:   0.00, loss: 103858.9531, ppl: 683.1223, duration: 4.9439s\n",
      "2020-02-19 23:45:11,925 Validation result (greedy) at epoch   4, step      480: bleu:   0.00, loss: 104121.6875, ppl: 694.4945, duration: 5.5406s\n",
      "2020-02-19 23:45:19,217 Validation result (greedy) at epoch   4, step      490: bleu:   0.00, loss: 103868.3672, ppl: 683.5263, duration: 5.2785s\n",
      "2020-02-19 23:45:26,498 Validation result (greedy) at epoch   4, step      500: bleu:   0.00, loss: 103835.8047, ppl: 682.1291, duration: 5.2355s\n",
      "2020-02-19 23:45:26,498 Epoch   4: total training loss 17577.51\n",
      "2020-02-19 23:45:26,498 EPOCH 5\n",
      "2020-02-19 23:45:32,771 Validation result (greedy) at epoch   5, step      510: bleu:   0.00, loss: 103874.7578, ppl: 683.8008, duration: 4.7989s\n",
      "2020-02-19 23:45:39,303 Validation result (greedy) at epoch   5, step      520: bleu:   0.00, loss: 103742.1484, ppl: 678.1262, duration: 4.6265s\n",
      "2020-02-19 23:45:46,978 Validation result (greedy) at epoch   5, step      530: bleu:   0.00, loss: 104038.9375, ppl: 690.8923, duration: 5.6571s\n",
      "2020-02-19 23:45:54,303 Validation result (greedy) at epoch   5, step      540: bleu:   0.00, loss: 103842.8672, ppl: 682.4320, duration: 5.3572s\n",
      "2020-02-19 23:46:02,175 Validation result (greedy) at epoch   5, step      550: bleu:   0.00, loss: 103953.2266, ppl: 687.1812, duration: 5.7771s\n",
      "2020-02-19 23:46:09,008 Validation result (greedy) at epoch   5, step      560: bleu:   0.00, loss: 103886.7812, ppl: 684.3177, duration: 4.8122s\n",
      "2020-02-19 23:46:15,694 Validation result (greedy) at epoch   5, step      570: bleu:   0.00, loss: 103825.6094, ppl: 681.6921, duration: 4.8790s\n",
      "2020-02-19 23:46:22,390 Validation result (greedy) at epoch   5, step      580: bleu:   0.00, loss: 103892.7969, ppl: 684.5766, duration: 4.9591s\n",
      "2020-02-19 23:46:29,469 Validation result (greedy) at epoch   5, step      590: bleu:   0.00, loss: 104089.5234, ppl: 693.0922, duration: 5.4318s\n",
      "2020-02-19 23:46:36,796 Validation result (greedy) at epoch   5, step      600: bleu:   0.00, loss: 103939.6641, ppl: 686.5956, duration: 5.1665s\n",
      "2020-02-19 23:46:43,928 Validation result (greedy) at epoch   5, step      610: bleu:   0.00, loss: 103828.8750, ppl: 681.8322, duration: 4.9966s\n",
      "2020-02-19 23:46:51,526 Validation result (greedy) at epoch   5, step      620: bleu:   0.00, loss: 103885.4609, ppl: 684.2610, duration: 5.6331s\n",
      "2020-02-19 23:46:52,461 Epoch   5: total training loss 17511.83\n",
      "2020-02-19 23:46:52,461 EPOCH 6\n",
      "2020-02-19 23:46:57,843 Validation result (greedy) at epoch   6, step      630: bleu:   0.00, loss: 103770.1094, ppl: 679.3188, duration: 4.2898s\n",
      "2020-02-19 23:47:04,386 Validation result (greedy) at epoch   6, step      640: bleu:   0.00, loss: 103852.7734, ppl: 682.8568, duration: 4.6701s\n",
      "2020-02-19 23:47:11,704 Validation result (greedy) at epoch   6, step      650: bleu:   0.00, loss: 103835.9609, ppl: 682.1356, duration: 5.4136s\n"
     ]
    }
   ],
   "source": [
    "base_path = 'data/translate/preprocessed'\n",
    "datas = os.listdir(base_path)\n",
    "emb_size = 300\n",
    "hidden_size = 512\n",
    "for data in datas:\n",
    "    data_path = os.path.join(base_path, data)\n",
    "    for lang_in, lang_out in [['es', 'shp'], ['shp', 'es']]:\n",
    "        segmentations = os.listdir(data_path)\n",
    "        for segment in segmentations:\n",
    "            segment_path = os.path.join(data_path, segment)\n",
    "            print(os.path.join('results/translate', data, segment))\n",
    "            if 'bpe_drop' in segment:\n",
    "                level = 'bpe'\n",
    "            elif 'bpe' in segment:\n",
    "                level = 'bpe'\n",
    "            elif 'char' in segment:\n",
    "                level = 'char'\n",
    "            elif 'word' in segment:\n",
    "                level = 'word'\n",
    "            elif 'syl' in segment:\n",
    "                level = 'syl'\n",
    "            else:\n",
    "                level = None\n",
    "                \n",
    "            val_freq = 10\n",
    "            f_config = config.format(lang_src=lang_in, lang_tgt=lang_out, \n",
    "                                     train_path=os.path.join(segment_path, 'train'),\n",
    "                                     test_path=os.path.join(segment_path, 'test'),\n",
    "                                     dev_path=os.path.join(segment_path, 'valid'),\n",
    "                                     level=level,\n",
    "                                     emb_size=emb_size,\n",
    "                                     hidden_size=hidden_size,\n",
    "                                     val_freq=val_freq,\n",
    "                                     model_dir=os.path.join('results/translate',\\\n",
    "                                                            f'{lang_in}-{lang_out}_{data}_{emb_size}_{hidden_size}', segment))\n",
    "\n",
    "            with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=\"test\"),'w') as f:\n",
    "                f.write(f_config)\n",
    "\n",
    "            !python3 joeynmt/joeynmt train \"joeynmt/configs/transformer_test.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
