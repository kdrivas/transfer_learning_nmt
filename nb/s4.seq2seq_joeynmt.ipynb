{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘./nb/.ipynb_checkpoints’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!find . -name .ipynb* -exec rm -rf {} \\;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "name: \"my_experiment\"\n",
    "\n",
    "# This configuration serves the purpose of documenting and explaining the settings, *NOT* as an example for good hyperparamter settings.\n",
    "\n",
    "data: # specify your data here\n",
    "    src: {lang_src}                       # src language: expected suffix of train files, e.g. \"train.de\"\n",
    "    trg: {lang_tgt}                       # trg language\n",
    "    train: {train_path}     # training data\n",
    "    dev: {dev_path}         # development data for validation\n",
    "    test: {test_path}       # test data for testing final model; optional\n",
    "    level: {level}                  # segmentation level: either \"word\", \"bpe\" or \"char\"\n",
    "    lowercase: True                 # lowercase the data, also for validation\n",
    "    max_sent_length: 130             # filter out longer sentences from training (src+trg)\n",
    "    src_voc_min_freq: 1             # src minimum frequency for a token to become part of the vocabulary\n",
    "    trg_voc_min_freq: 1             # trg minimum frequency for a token to become part of the vocabulary\n",
    "    #src_vocab: \"my_model/src_vocab.txt\"  # if specified, load a vocabulary from this file\n",
    "    #trg_vocab: \"my_model/trg_vocab.txt\"  # one token per line, line number is index\n",
    "\n",
    "testing:                            # specify which inference algorithm to use for testing (for validation it's always greedy decoding)\n",
    "    beam_size: 5                    # size of the beam for beam search\n",
    "    alpha: 1.0                      # length penalty for beam search\n",
    "\n",
    "training:                           # specify training details here\n",
    "    reset_best_ckpt: False          # if True, reset the tracking of the best checkpoint and scores. Use for domain adaptation or fine-tuning with new metrics or dev data.\n",
    "    reset_scheduler: False          # if True, overwrite scheduler in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    reset_optimizer: False          # if True, overwrite optimizer in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    random_seed: 42                 # set this seed to make training deterministic\n",
    "    optimizer: \"adam\"               # choices: \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", default is SGD\n",
    "    learning_rate: 0.0005           # initial learning rate, default: 3.0e-4 / 0.005\n",
    "    learning_rate_min: 0.0001       # stop learning when learning rate is reduced below this threshold, default: 1.0e-8\n",
    "    #learning_rate_factor: 1        # factor for Noam scheduler (used with Transformer)\n",
    "    #learning_rate_warmup: 4000     # warmup steps for Noam scheduler (used with Transformer)\n",
    "    clip_grad_val: 1.0              # clip the gradients to this value when they exceed it, optional\n",
    "    #clip_grad_norm: 1.0            # norm clipping instead of value clipping\n",
    "    weight_decay: 0.                # l2 regularization, default: 0\n",
    "    batch_size: 48                  # mini-batch size as number of sentences (when batch_type is \"sentence\"; default) or total number of tokens (when batch_type is \"token\")\n",
    "    batch_type: \"sentence\"          # create batches with sentences (\"sentence\", default) or tokens (\"token\")\n",
    "    eval_batch_size: 10            # mini-batch size for evaluation (see batch_size above)\n",
    "    eval_batch_type: \"sentence\"     # evaluation batch type (\"sentence\", default) or tokens (\"token\")\n",
    "    batch_multiplier: 1             # increase the effective batch size with values >1 to batch_multiplier*batch_size without increasing memory consumption by making updates only every batch_multiplier batches\n",
    "    scheduling: \"plateau\"           # learning rate scheduling, optional, if not specified stays constant, options: \"plateau\", \"exponential\", \"decaying\", \"noam\" (for Transformer), \"warmupexponentialdecay\"\n",
    "    patience: 500                     # specific to plateau scheduler: wait for this many validations without improvement before decreasing the learning rate\n",
    "    decrease_factor: 0.5            # specific to plateau & exponential scheduler: decrease the learning rate by this factor\n",
    "    epochs: 20                      # train for this many epochs\n",
    "    validation_freq: {val_freq}            # validate after this many updates (number of mini-batches), default: 1000\n",
    "    logging_freq: 1000               # log the training progress after this many updates, default: 100\n",
    "    eval_metric: \"bleu\"             # validation metric, default: \"bleu\", other options: \"chrf\", \"token_accuracy\", \"sequence_accuracy\"\n",
    "    early_stopping_metric: \"eval_metric\"   # when a new high score on this metric is achieved, a checkpoint is written, when \"eval_metric\" (default) is maximized, when \"loss\" or \"ppl\" is minimized\n",
    "    model_dir: {model_dir} # directory where models and validation results are stored, required\n",
    "    overwrite: True                 # overwrite existing model directory, default: False. Do not set to True unless for debugging!\n",
    "    shuffle: True                   # shuffle the training data, default: True\n",
    "    use_cuda: True                  # use CUDA for acceleration on GPU, required. Set to False when working on CPU.\n",
    "    max_output_length: 60           # maximum output length for decoding, default: None. If set to None, allow sentences of max 1.5*src length\n",
    "    print_valid_sents: []    # print this many validation sentences during each validation run, default: [0, 1, 2]\n",
    "    keep_last_ckpts: 3              # keep this many of the latest checkpoints, if -1: all of them, default: 5\n",
    "    label_smoothing: 0.0            # label smoothing: reference tokens will have 1-label_smoothing probability instead of 1, rest of probability mass is uniformly distributed over the rest of the vocabulary, default: 0.0 (off)\n",
    "\n",
    "model:                              # specify your model architecture here\n",
    "    initializer: \"xavier\"           # initializer for all trainable weights (xavier, zeros, normal, uniform)\n",
    "    init_weight: 0.01               # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    init_gain: 1.0                  # gain for Xavier initializer (default: 1.0)\n",
    "    bias_initializer: \"zeros\"       # initializer for bias terms (xavier, zeros, normal, uniform)\n",
    "    embed_initializer: \"normal\"     # initializer for embeddings (xavier, zeros, normal, uniform)\n",
    "    embed_init_weight: 0.1          # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    embed_init_gain: 1.0            # gain for Xavier initializer for embeddings (default: 1.0)\n",
    "    init_rnn_orthogonal: False      # use orthogonal initialization for recurrent weights (default: False)\n",
    "    lstm_forget_gate: 1.            # initialize LSTM forget gate with this value (default: 1.)\n",
    "    tied_embeddings: False           # tie src and trg embeddings, only applicable if vocabularies are the same, default: False\n",
    "    tied_softmax: False             # tie trg embeddings and softmax (for Transformer; can be used together with tied_embeddings), default: False\n",
    "    encoder:\n",
    "        type: \"recurrent\"           # encoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"             # type of recurrent unit to use, either \"gru\" or \"lstm\", default: \"lstm\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}      # size of embeddings\n",
    "            scale: False            # scale the embeddings by sqrt of their size, default: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}            # size of RNN\n",
    "        bidirectional: True         # use a bi-directional encoder, default: True\n",
    "        dropout: 0.3                # apply dropout to the inputs to the RNN, default: 0.0\n",
    "        num_layers: 2               # stack this many layers of equal size, default: 1\n",
    "        freeze: False               # if True, encoder parameters are not updated during training (does not include embedding parameters)\n",
    "    decoder:\n",
    "        type: \"recurrent\"           # decoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}\n",
    "            scale: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}\n",
    "        dropout: 0.3\n",
    "        hidden_dropout: 0.2         # apply dropout to the attention vector, default: 0.0\n",
    "        num_layers: 2\n",
    "        input_feeding: True         # combine hidden state and attention vector before feeding to rnn, default: True\n",
    "        init_hidden: \"last\"         # initialized the decoder hidden state: use linear projection of last encoder state (\"bridge\") or simply the last state (\"last\") or zeros (\"zero\"), default: \"bridge\"\n",
    "        attention: \"bahdanau\"       # attention mechanism, choices: \"bahdanau\" (MLP attention), \"luong\" (bilinear attention), default: \"bahdanau\"\n",
    "        freeze: False               # if True, decoder parameters are not updated during training (does not include embedding parameters, but attention)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/translate/Religioso/char\n",
      "2020-03-03 21:49:42,521 Hello! This is Joey-NMT.\n",
      "2020-03-03 21:49:43.343525: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-03 21:49:43.343631: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-03 21:49:43.343647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-03-03 21:49:44,340 Total params: 12451936\n",
      "2020-03-03 21:49:44,340 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-03-03 21:49:46,602 cfg.name                           : my_experiment\n",
      "2020-03-03 21:49:46,602 cfg.data.src                       : es\n",
      "2020-03-03 21:49:46,602 cfg.data.trg                       : shp\n",
      "2020-03-03 21:49:46,602 cfg.data.train                     : data/translate/preprocessed/Religioso/char/train\n",
      "2020-03-03 21:49:46,602 cfg.data.dev                       : data/translate/preprocessed/Religioso/char/valid\n",
      "2020-03-03 21:49:46,602 cfg.data.test                      : data/translate/preprocessed/Religioso/char/test\n",
      "2020-03-03 21:49:46,602 cfg.data.level                     : char\n",
      "2020-03-03 21:49:46,602 cfg.data.lowercase                 : True\n",
      "2020-03-03 21:49:46,602 cfg.data.max_sent_length           : 130\n",
      "2020-03-03 21:49:46,602 cfg.data.src_voc_min_freq          : 1\n",
      "2020-03-03 21:49:46,602 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-03-03 21:49:46,602 cfg.testing.beam_size              : 5\n",
      "2020-03-03 21:49:46,602 cfg.testing.alpha                  : 1.0\n",
      "2020-03-03 21:49:46,602 cfg.training.reset_best_ckpt       : False\n",
      "2020-03-03 21:49:46,602 cfg.training.reset_scheduler       : False\n",
      "2020-03-03 21:49:46,602 cfg.training.reset_optimizer       : False\n",
      "2020-03-03 21:49:46,602 cfg.training.random_seed           : 42\n",
      "2020-03-03 21:49:46,602 cfg.training.optimizer             : adam\n",
      "2020-03-03 21:49:46,603 cfg.training.learning_rate         : 0.0005\n",
      "2020-03-03 21:49:46,603 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-03-03 21:49:46,603 cfg.training.clip_grad_val         : 1.0\n",
      "2020-03-03 21:49:46,603 cfg.training.weight_decay          : 0.0\n",
      "2020-03-03 21:49:46,603 cfg.training.batch_size            : 48\n",
      "2020-03-03 21:49:46,603 cfg.training.batch_type            : sentence\n",
      "2020-03-03 21:49:46,603 cfg.training.eval_batch_size       : 10\n",
      "2020-03-03 21:49:46,603 cfg.training.eval_batch_type       : sentence\n",
      "2020-03-03 21:49:46,603 cfg.training.batch_multiplier      : 1\n",
      "2020-03-03 21:49:46,603 cfg.training.scheduling            : plateau\n",
      "2020-03-03 21:49:46,603 cfg.training.patience              : 500\n",
      "2020-03-03 21:49:46,603 cfg.training.decrease_factor       : 0.5\n",
      "2020-03-03 21:49:46,603 cfg.training.epochs                : 20\n",
      "2020-03-03 21:49:46,603 cfg.training.validation_freq       : 10\n",
      "2020-03-03 21:49:46,603 cfg.training.logging_freq          : 1000\n",
      "2020-03-03 21:49:46,603 cfg.training.eval_metric           : bleu\n",
      "2020-03-03 21:49:46,603 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-03-03 21:49:46,603 cfg.training.model_dir             : results/translate/es-shp_Religioso_300_512/char\n",
      "2020-03-03 21:49:46,603 cfg.training.overwrite             : True\n",
      "2020-03-03 21:49:46,603 cfg.training.shuffle               : True\n",
      "2020-03-03 21:49:46,603 cfg.training.use_cuda              : True\n",
      "2020-03-03 21:49:46,603 cfg.training.max_output_length     : 60\n",
      "2020-03-03 21:49:46,603 cfg.training.print_valid_sents     : []\n",
      "2020-03-03 21:49:46,603 cfg.training.keep_last_ckpts       : 3\n",
      "2020-03-03 21:49:46,603 cfg.training.label_smoothing       : 0.0\n",
      "2020-03-03 21:49:46,603 cfg.model.initializer              : xavier\n",
      "2020-03-03 21:49:46,603 cfg.model.init_weight              : 0.01\n",
      "2020-03-03 21:49:46,603 cfg.model.init_gain                : 1.0\n",
      "2020-03-03 21:49:46,604 cfg.model.bias_initializer         : zeros\n",
      "2020-03-03 21:49:46,604 cfg.model.embed_initializer        : normal\n",
      "2020-03-03 21:49:46,604 cfg.model.embed_init_weight        : 0.1\n",
      "2020-03-03 21:49:46,604 cfg.model.embed_init_gain          : 1.0\n",
      "2020-03-03 21:49:46,604 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-03-03 21:49:46,604 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-03-03 21:49:46,604 cfg.model.tied_embeddings          : False\n",
      "2020-03-03 21:49:46,604 cfg.model.tied_softmax             : False\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.type             : recurrent\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.rnn_type         : gru\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.embeddings.scale : False\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.hidden_size      : 512\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.bidirectional    : True\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.dropout          : 0.3\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.num_layers       : 2\n",
      "2020-03-03 21:49:46,604 cfg.model.encoder.freeze           : False\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.type             : recurrent\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.rnn_type         : gru\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.embeddings.scale : False\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.hidden_size      : 512\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.dropout          : 0.3\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.num_layers       : 2\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.input_feeding    : True\n",
      "2020-03-03 21:49:46,604 cfg.model.decoder.init_hidden      : last\n",
      "2020-03-03 21:49:46,605 cfg.model.decoder.attention        : bahdanau\n",
      "2020-03-03 21:49:46,605 cfg.model.decoder.freeze           : False\n",
      "2020-03-03 21:49:46,605 Data set sizes: \n",
      "\ttrain 4439,\n",
      "\tvalid 749,\n",
      "\ttest 749\n",
      "2020-03-03 21:49:46,605 First training example:\n",
      "\t[SRC] @@ i k a x b i @@ j a @@ n o n @@ i b o n @@ j o i r a @@ j a w e t i a n b i @@ k e y ó y a m a i @@ i k i\n",
      "\t[TRG] @@ p e r o @@ l a @@ p a l a b r a @@ d e l @@ s e ñ o r @@ p e r m a n e c e @@ e t e r n a m e n t e @@ e s t a @@ p a l a b r a @@ e s @@ e l @@ e v a n g e l i o @@ q u e @@ s e @@ l e s @@ h a @@ a n u n c i a d o @@ a @@ u s t e d e s\n",
      "2020-03-03 21:49:46,605 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) @@ (6) i (7) n (8) o (9) k\n",
      "2020-03-03 21:49:46,605 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) a (7) o (8) s (9) n\n",
      "2020-03-03 21:49:46,605 Number of Src words (types): 36\n",
      "2020-03-03 21:49:46,605 Number of Trg words (types): 36\n",
      "2020-03-03 21:49:46,605 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=36),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=36))\n",
      "2020-03-03 21:49:46,605 EPOCH 1\n",
      "2020-03-03 21:50:08,609 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 21:50:08,609 Saving new checkpoint.\n",
      "2020-03-03 21:50:08,773 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 167629.7188, ppl:  18.3547, duration: 18.0771s\n",
      "2020-03-03 21:50:30,385 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 162874.4531, ppl:  16.9004, duration: 17.9622s\n",
      "2020-03-03 21:50:50,533 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 156949.6406, ppl:  15.2486, duration: 16.9603s\n",
      "2020-03-03 21:51:11,765 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 148039.7500, ppl:  13.0635, duration: 17.2110s\n",
      "2020-03-03 21:51:33,889 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 138733.1406, ppl:  11.1147, duration: 18.1006s\n",
      "2020-03-03 21:51:56,875 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 133648.7812, ppl:  10.1758, duration: 19.3345s\n",
      "2020-03-03 21:52:16,824 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 127022.6250, ppl:   9.0701, duration: 15.8389s\n",
      "2020-03-03 21:52:37,283 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 124908.2656, ppl:   8.7433, duration: 17.5510s\n",
      "2020-03-03 21:52:58,521 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 121245.6406, ppl:   8.2047, duration: 17.6663s\n",
      "2020-03-03 21:52:59,618 Epoch   1: total training loss 14520.26\n",
      "2020-03-03 21:52:59,619 EPOCH 2\n",
      "2020-03-03 21:53:19,934 Validation result (greedy) at epoch   2, step      100: bleu:   0.00, loss: 120417.8672, ppl:   8.0876, duration: 18.0430s\n",
      "2020-03-03 21:53:39,772 Validation result (greedy) at epoch   2, step      110: bleu:   0.00, loss: 119138.1953, ppl:   7.9099, duration: 16.7726s\n",
      "2020-03-03 21:54:00,378 Validation result (greedy) at epoch   2, step      120: bleu:   0.00, loss: 117157.1797, ppl:   7.6426, duration: 16.6639s\n",
      "2020-03-03 21:54:20,179 Validation result (greedy) at epoch   2, step      130: bleu:   0.00, loss: 115488.1484, ppl:   7.4243, duration: 16.7331s\n",
      "2020-03-03 21:54:41,248 Validation result (greedy) at epoch   2, step      140: bleu:   0.00, loss: 114793.2578, ppl:   7.3353, duration: 17.4809s\n",
      "2020-03-03 21:55:01,550 Validation result (greedy) at epoch   2, step      150: bleu:   0.00, loss: 112839.9531, ppl:   7.0907, duration: 16.5628s\n",
      "2020-03-03 21:55:21,572 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 111768.9375, ppl:   6.9601, duration: 16.4577s\n",
      "2020-03-03 21:55:43,355 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 110306.3359, ppl:   6.7856, duration: 17.7187s\n",
      "2020-03-03 21:56:04,316 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 109145.4141, ppl:   6.6503, duration: 17.2231s\n",
      "2020-03-03 21:56:06,405 Epoch   2: total training loss 11607.50\n",
      "2020-03-03 21:56:06,405 EPOCH 3\n",
      "2020-03-03 21:56:27,107 Validation result (greedy) at epoch   3, step      190: bleu:   0.00, loss: 108215.7422, ppl:   6.5438, duration: 19.5436s\n",
      "2020-03-03 21:56:50,255 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 21:56:50,255 Saving new checkpoint.\n",
      "2020-03-03 21:56:50,397 Validation result (greedy) at epoch   3, step      200: bleu:   0.15, loss: 107335.0703, ppl:   6.4445, duration: 19.6876s\n",
      "2020-03-03 21:57:11,323 Validation result (greedy) at epoch   3, step      210: bleu:   0.00, loss: 106862.6875, ppl:   6.3919, duration: 17.2232s\n",
      "2020-03-03 21:57:33,090 Validation result (greedy) at epoch   3, step      220: bleu:   0.00, loss: 106232.2422, ppl:   6.3223, duration: 18.3302s\n",
      "2020-03-03 21:57:54,343 Validation result (greedy) at epoch   3, step      230: bleu:   0.00, loss: 105341.5547, ppl:   6.2253, duration: 17.5913s\n",
      "2020-03-03 21:58:16,551 Validation result (greedy) at epoch   3, step      240: bleu:   0.00, loss: 103269.6328, ppl:   6.0054, duration: 18.3236s\n",
      "2020-03-03 21:58:38,106 Validation result (greedy) at epoch   3, step      250: bleu:   0.00, loss: 103322.8359, ppl:   6.0109, duration: 18.1327s\n",
      "2020-03-03 21:59:00,685 Validation result (greedy) at epoch   3, step      260: bleu:   0.00, loss: 101792.3359, ppl:   5.8533, duration: 18.5981s\n",
      "2020-03-03 21:59:21,159 Validation result (greedy) at epoch   3, step      270: bleu:   0.00, loss: 101017.8125, ppl:   5.7752, duration: 16.6158s\n",
      "2020-03-03 21:59:24,375 Epoch   3: total training loss 10670.88\n",
      "2020-03-03 21:59:24,376 EPOCH 4\n",
      "2020-03-03 21:59:40,822 Validation result (greedy) at epoch   4, step      280: bleu:   0.00, loss: 100996.0078, ppl:   5.7730, duration: 16.1642s\n",
      "2020-03-03 22:00:02,787 Validation result (greedy) at epoch   4, step      290: bleu:   0.00, loss: 99208.2344, ppl:   5.5966, duration: 18.3173s\n",
      "2020-03-03 22:00:22,401 Validation result (greedy) at epoch   4, step      300: bleu:   0.00, loss: 98754.7734, ppl:   5.5527, duration: 16.2446s\n",
      "2020-03-03 22:00:43,557 Validation result (greedy) at epoch   4, step      310: bleu:   0.00, loss: 97541.6875, ppl:   5.4370, duration: 17.1060s\n",
      "2020-03-03 22:01:04,717 Validation result (greedy) at epoch   4, step      320: bleu:   0.00, loss: 96999.3047, ppl:   5.3860, duration: 17.6633s\n",
      "2020-03-03 22:01:25,755 Validation result (greedy) at epoch   4, step      330: bleu:   0.00, loss: 96172.5547, ppl:   5.3093, duration: 17.4448s\n",
      "2020-03-03 22:01:45,826 Validation result (greedy) at epoch   4, step      340: bleu:   0.00, loss: 96311.9609, ppl:   5.3222, duration: 17.1363s\n",
      "2020-03-03 22:02:07,538 Validation result (greedy) at epoch   4, step      350: bleu:   0.00, loss: 94913.2891, ppl:   5.1945, duration: 17.9518s\n",
      "2020-03-03 22:02:28,436 Validation result (greedy) at epoch   4, step      360: bleu:   0.00, loss: 94621.1953, ppl:   5.1682, duration: 17.2138s\n",
      "2020-03-03 22:02:48,723 Validation result (greedy) at epoch   4, step      370: bleu:   0.00, loss: 93328.6406, ppl:   5.0536, duration: 16.9075s\n",
      "2020-03-03 22:02:49,369 Epoch   4: total training loss 9919.90\n",
      "2020-03-03 22:02:49,369 EPOCH 5\n",
      "2020-03-03 22:03:08,958 Validation result (greedy) at epoch   5, step      380: bleu:   0.00, loss: 92674.5391, ppl:   4.9965, duration: 16.4437s\n",
      "2020-03-03 22:03:29,592 Validation result (greedy) at epoch   5, step      390: bleu:   0.00, loss: 92470.3516, ppl:   4.9788, duration: 17.0962s\n",
      "2020-03-03 22:03:50,126 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:03:50,126 Saving new checkpoint.\n",
      "2020-03-03 22:03:50,284 Validation result (greedy) at epoch   5, step      400: bleu:   0.40, loss: 92044.6797, ppl:   4.9422, duration: 16.9925s\n",
      "2020-03-03 22:04:10,675 Validation result (greedy) at epoch   5, step      410: bleu:   0.00, loss: 91488.0703, ppl:   4.8946, duration: 16.6739s\n",
      "2020-03-03 22:04:30,997 Validation result (greedy) at epoch   5, step      420: bleu:   0.33, loss: 90671.7031, ppl:   4.8258, duration: 16.8761s\n",
      "2020-03-03 22:04:52,957 Validation result (greedy) at epoch   5, step      430: bleu:   0.31, loss: 90321.6328, ppl:   4.7965, duration: 18.3614s\n",
      "2020-03-03 22:05:12,786 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:05:12,787 Saving new checkpoint.\n",
      "2020-03-03 22:05:12,921 Validation result (greedy) at epoch   5, step      440: bleu:   0.43, loss: 89075.6094, ppl:   4.6939, duration: 16.8109s\n",
      "2020-03-03 22:05:33,273 Validation result (greedy) at epoch   5, step      450: bleu:   0.00, loss: 89392.2969, ppl:   4.7198, duration: 17.4427s\n",
      "2020-03-03 22:05:52,787 Validation result (greedy) at epoch   5, step      460: bleu:   0.00, loss: 88282.3125, ppl:   4.6297, duration: 16.0274s\n",
      "2020-03-03 22:05:54,643 Epoch   5: total training loss 9326.70\n",
      "2020-03-03 22:05:54,644 EPOCH 6\n",
      "2020-03-03 22:06:12,508 Validation result (greedy) at epoch   6, step      470: bleu:   0.00, loss: 88178.4844, ppl:   4.6214, duration: 16.2514s\n",
      "2020-03-03 22:06:33,930 Validation result (greedy) at epoch   6, step      480: bleu:   0.37, loss: 87141.2031, ppl:   4.5389, duration: 17.9522s\n",
      "2020-03-03 22:06:55,519 Validation result (greedy) at epoch   6, step      490: bleu:   0.00, loss: 87947.9766, ppl:   4.6029, duration: 18.0666s\n",
      "2020-03-03 22:07:17,481 Validation result (greedy) at epoch   6, step      500: bleu:   0.31, loss: 86120.3750, ppl:   4.4592, duration: 18.0537s\n",
      "2020-03-03 22:07:39,556 Validation result (greedy) at epoch   6, step      510: bleu:   0.00, loss: 86426.6250, ppl:   4.4829, duration: 18.5290s\n",
      "2020-03-03 22:08:01,017 Validation result (greedy) at epoch   6, step      520: bleu:   0.00, loss: 85805.7188, ppl:   4.4349, duration: 17.7106s\n",
      "2020-03-03 22:08:21,284 Validation result (greedy) at epoch   6, step      530: bleu:   0.00, loss: 85097.3906, ppl:   4.3807, duration: 16.4887s\n",
      "2020-03-03 22:08:41,873 Validation result (greedy) at epoch   6, step      540: bleu:   0.00, loss: 84627.2656, ppl:   4.3451, duration: 17.1662s\n",
      "2020-03-03 22:09:02,908 Validation result (greedy) at epoch   6, step      550: bleu:   0.00, loss: 84255.2656, ppl:   4.3171, duration: 17.3154s\n",
      "2020-03-03 22:09:05,676 Epoch   6: total training loss 8806.94\n",
      "2020-03-03 22:09:05,676 EPOCH 7\n",
      "2020-03-03 22:09:24,538 Validation result (greedy) at epoch   7, step      560: bleu:   0.00, loss: 84058.2266, ppl:   4.3024, duration: 18.1560s\n",
      "2020-03-03 22:09:45,122 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:09:45,123 Saving new checkpoint.\n",
      "2020-03-03 22:09:45,261 Validation result (greedy) at epoch   7, step      570: bleu:   0.44, loss: 83359.6172, ppl:   4.2505, duration: 17.0477s\n",
      "2020-03-03 22:10:05,136 Validation result (greedy) at epoch   7, step      580: bleu:   0.00, loss: 83114.2734, ppl:   4.2324, duration: 16.5744s\n",
      "2020-03-03 22:10:24,505 Validation result (greedy) at epoch   7, step      590: bleu:   0.00, loss: 83325.2734, ppl:   4.2480, duration: 15.9059s\n",
      "2020-03-03 22:10:45,925 Validation result (greedy) at epoch   7, step      600: bleu:   0.35, loss: 82476.9453, ppl:   4.1859, duration: 17.8548s\n",
      "2020-03-03 22:11:06,524 Validation result (greedy) at epoch   7, step      610: bleu:   0.38, loss: 82030.9297, ppl:   4.1536, duration: 16.6929s\n",
      "2020-03-03 22:11:26,715 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:11:26,715 Saving new checkpoint.\n",
      "2020-03-03 22:11:26,861 Validation result (greedy) at epoch   7, step      620: bleu:   0.53, loss: 82167.9453, ppl:   4.1635, duration: 17.0713s\n",
      "2020-03-03 22:11:47,815 Validation result (greedy) at epoch   7, step      630: bleu:   0.49, loss: 81149.3203, ppl:   4.0905, duration: 17.6728s\n",
      "2020-03-03 22:12:09,573 Validation result (greedy) at epoch   7, step      640: bleu:   0.48, loss: 81016.6562, ppl:   4.0811, duration: 17.9559s\n",
      "2020-03-03 22:12:30,634 Validation result (greedy) at epoch   7, step      650: bleu:   0.00, loss: 80858.0312, ppl:   4.0699, duration: 17.5170s\n",
      "2020-03-03 22:12:30,993 Epoch   7: total training loss 8377.14\n",
      "2020-03-03 22:12:30,994 EPOCH 8\n",
      "2020-03-03 22:12:52,494 Validation result (greedy) at epoch   8, step      660: bleu:   0.40, loss: 80970.9453, ppl:   4.0779, duration: 18.1406s\n",
      "2020-03-03 22:13:13,363 Validation result (greedy) at epoch   8, step      670: bleu:   0.00, loss: 80436.4922, ppl:   4.0402, duration: 17.3717s\n",
      "2020-03-03 22:13:33,342 Validation result (greedy) at epoch   8, step      680: bleu:   0.00, loss: 80124.7422, ppl:   4.0184, duration: 16.5468s\n",
      "2020-03-03 22:13:52,492 Validation result (greedy) at epoch   8, step      690: bleu:   0.00, loss: 79914.4766, ppl:   4.0038, duration: 15.9216s\n",
      "2020-03-03 22:14:12,754 Validation result (greedy) at epoch   8, step      700: bleu:   0.00, loss: 79904.1641, ppl:   4.0030, duration: 17.5062s\n",
      "2020-03-03 22:14:33,592 Validation result (greedy) at epoch   8, step      710: bleu:   0.42, loss: 78880.3125, ppl:   3.9325, duration: 16.5034s\n",
      "2020-03-03 22:14:55,578 Validation result (greedy) at epoch   8, step      720: bleu:   0.00, loss: 78728.7734, ppl:   3.9222, duration: 18.2514s\n",
      "2020-03-03 22:15:15,266 Validation result (greedy) at epoch   8, step      730: bleu:   0.00, loss: 78269.3047, ppl:   3.8910, duration: 16.2464s\n",
      "2020-03-03 22:15:35,773 Validation result (greedy) at epoch   8, step      740: bleu:   0.00, loss: 78123.5156, ppl:   3.8812, duration: 17.2083s\n",
      "2020-03-03 22:15:36,893 Epoch   8: total training loss 8004.39\n",
      "2020-03-03 22:15:36,893 EPOCH 9\n",
      "2020-03-03 22:15:59,033 Validation result (greedy) at epoch   9, step      750: bleu:   0.00, loss: 77896.4844, ppl:   3.8659, duration: 19.6276s\n",
      "2020-03-03 22:16:19,985 Validation result (greedy) at epoch   9, step      760: bleu:   0.00, loss: 78716.2344, ppl:   3.9213, duration: 17.5966s\n",
      "2020-03-03 22:16:41,271 Validation result (greedy) at epoch   9, step      770: bleu:   0.41, loss: 78898.2578, ppl:   3.9338, duration: 17.9799s\n",
      "2020-03-03 22:17:02,577 Validation result (greedy) at epoch   9, step      780: bleu:   0.42, loss: 77755.9844, ppl:   3.8565, duration: 17.4330s\n",
      "2020-03-03 22:17:22,606 Validation result (greedy) at epoch   9, step      790: bleu:   0.00, loss: 77484.0938, ppl:   3.8384, duration: 16.0455s\n",
      "2020-03-03 22:17:44,085 Validation result (greedy) at epoch   9, step      800: bleu:   0.48, loss: 77271.8516, ppl:   3.8242, duration: 18.3790s\n",
      "2020-03-03 22:18:03,564 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:18:03,564 Saving new checkpoint.\n",
      "2020-03-03 22:18:03,699 Validation result (greedy) at epoch   9, step      810: bleu:   0.63, loss: 76851.6172, ppl:   3.7965, duration: 16.6967s\n",
      "2020-03-03 22:18:24,596 Validation result (greedy) at epoch   9, step      820: bleu:   0.46, loss: 76432.0156, ppl:   3.7689, duration: 17.1055s\n",
      "2020-03-03 22:18:44,890 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:18:44,890 Saving new checkpoint.\n",
      "2020-03-03 22:18:45,040 Validation result (greedy) at epoch   9, step      830: bleu:   0.67, loss: 76015.5391, ppl:   3.7418, duration: 16.7624s\n",
      "2020-03-03 22:18:47,869 Epoch   9: total training loss 7719.96\n",
      "2020-03-03 22:18:47,870 EPOCH 10\n",
      "2020-03-03 22:19:05,692 Validation result (greedy) at epoch  10, step      840: bleu:   0.00, loss: 76295.4922, ppl:   3.7600, duration: 16.9571s\n",
      "2020-03-03 22:19:25,499 Validation result (greedy) at epoch  10, step      850: bleu:   0.00, loss: 75862.4844, ppl:   3.7318, duration: 16.5234s\n",
      "2020-03-03 22:19:45,411 Validation result (greedy) at epoch  10, step      860: bleu:   0.00, loss: 76363.1016, ppl:   3.7644, duration: 16.9557s\n",
      "2020-03-03 22:20:06,586 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:20:06,586 Saving new checkpoint.\n",
      "2020-03-03 22:20:06,744 Validation result (greedy) at epoch  10, step      870: bleu:   0.83, loss: 75525.3359, ppl:   3.7100, duration: 17.1058s\n",
      "2020-03-03 22:20:26,374 Validation result (greedy) at epoch  10, step      880: bleu:   0.00, loss: 75939.4531, ppl:   3.7368, duration: 15.9557s\n",
      "2020-03-03 22:20:47,522 Validation result (greedy) at epoch  10, step      890: bleu:   0.00, loss: 75995.6875, ppl:   3.7405, duration: 17.4418s\n",
      "2020-03-03 22:21:08,441 Validation result (greedy) at epoch  10, step      900: bleu:   0.47, loss: 75364.3828, ppl:   3.6997, duration: 17.6167s\n",
      "2020-03-03 22:21:29,543 Validation result (greedy) at epoch  10, step      910: bleu:   0.00, loss: 75132.3203, ppl:   3.6848, duration: 17.5995s\n",
      "2020-03-03 22:21:49,758 Validation result (greedy) at epoch  10, step      920: bleu:   0.48, loss: 74998.3984, ppl:   3.6763, duration: 17.1415s\n",
      "2020-03-03 22:22:11,556 Validation result (greedy) at epoch  10, step      930: bleu:   0.00, loss: 74524.0703, ppl:   3.6461, duration: 18.1185s\n",
      "2020-03-03 22:22:11,557 Epoch  10: total training loss 7433.90\n",
      "2020-03-03 22:22:11,557 EPOCH 11\n",
      "2020-03-03 22:22:33,031 Validation result (greedy) at epoch  11, step      940: bleu:   0.65, loss: 74428.4141, ppl:   3.6401, duration: 18.3253s\n",
      "2020-03-03 22:22:54,234 Validation result (greedy) at epoch  11, step      950: bleu:   0.00, loss: 74407.1094, ppl:   3.6387, duration: 17.6314s\n",
      "2020-03-03 22:23:16,667 Validation result (greedy) at epoch  11, step      960: bleu:   0.63, loss: 74055.3359, ppl:   3.6166, duration: 18.9901s\n",
      "2020-03-03 22:23:37,312 Validation result (greedy) at epoch  11, step      970: bleu:   0.52, loss: 74159.2500, ppl:   3.6231, duration: 16.7583s\n",
      "2020-03-03 22:23:58,835 Validation result (greedy) at epoch  11, step      980: bleu:   0.00, loss: 74526.9922, ppl:   3.6463, duration: 17.7411s\n",
      "2020-03-03 22:24:20,138 Validation result (greedy) at epoch  11, step      990: bleu:   0.00, loss: 73856.8047, ppl:   3.6041, duration: 17.5251s\n",
      "2020-03-03 22:24:23,402 Epoch  11 Step:     1000 Batch Loss:    69.182487 Tokens per Sec:     8020, Lr: 0.000500\n",
      "2020-03-03 22:24:40,208 Validation result (greedy) at epoch  11, step     1000: bleu:   0.00, loss: 73541.2031, ppl:   3.5844, duration: 16.8053s\n",
      "2020-03-03 22:25:03,108 Validation result (greedy) at epoch  11, step     1010: bleu:   0.00, loss: 73353.7656, ppl:   3.5728, duration: 18.9040s\n",
      "2020-03-03 22:25:23,099 Validation result (greedy) at epoch  11, step     1020: bleu:   0.00, loss: 73220.6250, ppl:   3.5645, duration: 16.3800s\n",
      "2020-03-03 22:25:23,984 Epoch  11: total training loss 7175.15\n",
      "2020-03-03 22:25:23,986 EPOCH 12\n",
      "2020-03-03 22:25:43,770 Validation result (greedy) at epoch  12, step     1030: bleu:   0.53, loss: 73208.5703, ppl:   3.5638, duration: 17.2927s\n",
      "2020-03-03 22:26:03,877 Validation result (greedy) at epoch  12, step     1040: bleu:   0.56, loss: 73182.1250, ppl:   3.5622, duration: 16.6904s\n",
      "2020-03-03 22:26:24,733 Validation result (greedy) at epoch  12, step     1050: bleu:   0.64, loss: 73121.4688, ppl:   3.5584, duration: 17.2862s\n",
      "2020-03-03 22:26:45,119 Validation result (greedy) at epoch  12, step     1060: bleu:   0.79, loss: 72855.4141, ppl:   3.5420, duration: 16.5703s\n",
      "2020-03-03 22:27:05,135 Validation result (greedy) at epoch  12, step     1070: bleu:   0.77, loss: 72768.5781, ppl:   3.5367, duration: 16.6309s\n",
      "2020-03-03 22:27:25,574 Validation result (greedy) at epoch  12, step     1080: bleu:   0.00, loss: 73025.9453, ppl:   3.5525, duration: 16.9413s\n",
      "2020-03-03 22:27:46,940 Validation result (greedy) at epoch  12, step     1090: bleu:   0.56, loss: 72845.8906, ppl:   3.5414, duration: 17.5690s\n",
      "2020-03-03 22:28:08,305 Validation result (greedy) at epoch  12, step     1100: bleu:   0.70, loss: 73010.5938, ppl:   3.5516, duration: 17.5670s\n",
      "2020-03-03 22:28:28,558 Validation result (greedy) at epoch  12, step     1110: bleu:   0.00, loss: 72832.2266, ppl:   3.5406, duration: 17.1781s\n",
      "2020-03-03 22:28:31,135 Epoch  12: total training loss 6942.61\n",
      "2020-03-03 22:28:31,136 EPOCH 13\n",
      "2020-03-03 22:28:51,225 Validation result (greedy) at epoch  13, step     1120: bleu:   0.54, loss: 72244.2031, ppl:   3.5046, duration: 18.3975s\n",
      "2020-03-03 22:29:11,595 Validation result (greedy) at epoch  13, step     1130: bleu:   0.59, loss: 72689.3281, ppl:   3.5318, duration: 17.2685s\n",
      "2020-03-03 22:29:32,194 Validation result (greedy) at epoch  13, step     1140: bleu:   0.00, loss: 72578.7031, ppl:   3.5250, duration: 16.6230s\n",
      "2020-03-03 22:29:52,267 Validation result (greedy) at epoch  13, step     1150: bleu:   0.80, loss: 72261.9609, ppl:   3.5057, duration: 16.5324s\n",
      "2020-03-03 22:30:12,962 Validation result (greedy) at epoch  13, step     1160: bleu:   0.74, loss: 72121.5234, ppl:   3.4972, duration: 16.9422s\n",
      "2020-03-03 22:30:34,110 Validation result (greedy) at epoch  13, step     1170: bleu:   0.76, loss: 71712.8594, ppl:   3.4725, duration: 17.4913s\n",
      "2020-03-03 22:30:53,978 Validation result (greedy) at epoch  13, step     1180: bleu:   0.55, loss: 71740.9766, ppl:   3.4742, duration: 16.5904s\n",
      "2020-03-03 22:31:15,095 Validation result (greedy) at epoch  13, step     1190: bleu:   0.71, loss: 72513.3906, ppl:   3.5211, duration: 17.5164s\n",
      "2020-03-03 22:31:36,465 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:31:36,465 Saving new checkpoint.\n",
      "2020-03-03 22:31:36,613 Validation result (greedy) at epoch  13, step     1200: bleu:   0.86, loss: 71613.6094, ppl:   3.4665, duration: 17.7217s\n",
      "2020-03-03 22:31:40,204 Epoch  13: total training loss 6724.79\n",
      "2020-03-03 22:31:40,205 EPOCH 14\n",
      "2020-03-03 22:31:58,118 Validation result (greedy) at epoch  14, step     1210: bleu:   0.62, loss: 71465.6719, ppl:   3.4576, duration: 17.4660s\n",
      "2020-03-03 22:32:18,763 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:32:18,764 Saving new checkpoint.\n",
      "2020-03-03 22:32:18,945 Validation result (greedy) at epoch  14, step     1220: bleu:   0.99, loss: 71769.5156, ppl:   3.4759, duration: 17.1610s\n",
      "2020-03-03 22:32:40,950 Validation result (greedy) at epoch  14, step     1230: bleu:   0.62, loss: 71629.4219, ppl:   3.4674, duration: 17.6339s\n",
      "2020-03-03 22:33:01,773 Validation result (greedy) at epoch  14, step     1240: bleu:   0.78, loss: 71735.2344, ppl:   3.4738, duration: 17.1235s\n",
      "2020-03-03 22:33:21,913 Validation result (greedy) at epoch  14, step     1250: bleu:   0.61, loss: 72017.8594, ppl:   3.4909, duration: 16.6852s\n",
      "2020-03-03 22:33:42,014 Validation result (greedy) at epoch  14, step     1260: bleu:   0.88, loss: 71874.1953, ppl:   3.4822, duration: 16.6846s\n",
      "2020-03-03 22:34:02,633 Validation result (greedy) at epoch  14, step     1270: bleu:   0.70, loss: 70944.4297, ppl:   3.4264, duration: 16.7155s\n",
      "2020-03-03 22:34:22,682 Validation result (greedy) at epoch  14, step     1280: bleu:   0.75, loss: 70999.0312, ppl:   3.4297, duration: 16.8623s\n",
      "2020-03-03 22:34:43,347 Validation result (greedy) at epoch  14, step     1290: bleu:   0.84, loss: 70882.9375, ppl:   3.4228, duration: 16.9225s\n",
      "2020-03-03 22:35:03,660 Validation result (greedy) at epoch  14, step     1300: bleu:   0.69, loss: 71172.2188, ppl:   3.4400, duration: 16.8061s\n",
      "2020-03-03 22:35:04,514 Epoch  14: total training loss 6490.77\n",
      "2020-03-03 22:35:04,515 EPOCH 15\n",
      "2020-03-03 22:35:25,648 Validation result (greedy) at epoch  15, step     1310: bleu:   0.70, loss: 70892.3828, ppl:   3.4234, duration: 18.2063s\n",
      "2020-03-03 22:35:47,445 Validation result (greedy) at epoch  15, step     1320: bleu:   0.77, loss: 70875.7891, ppl:   3.4224, duration: 17.8179s\n",
      "2020-03-03 22:36:10,055 Validation result (greedy) at epoch  15, step     1330: bleu:   0.70, loss: 71558.5391, ppl:   3.4632, duration: 18.6867s\n",
      "2020-03-03 22:36:30,487 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:36:30,488 Saving new checkpoint.\n",
      "2020-03-03 22:36:30,640 Validation result (greedy) at epoch  15, step     1340: bleu:   1.11, loss: 71590.1562, ppl:   3.4651, duration: 17.1438s\n",
      "2020-03-03 22:36:50,212 Validation result (greedy) at epoch  15, step     1350: bleu:   1.04, loss: 70896.6250, ppl:   3.4236, duration: 16.5837s\n",
      "2020-03-03 22:37:10,995 Validation result (greedy) at epoch  15, step     1360: bleu:   1.02, loss: 70624.1562, ppl:   3.4075, duration: 17.2820s\n",
      "2020-03-03 22:37:32,084 Validation result (greedy) at epoch  15, step     1370: bleu:   0.84, loss: 70814.9922, ppl:   3.4188, duration: 17.2066s\n",
      "2020-03-03 22:37:53,059 Validation result (greedy) at epoch  15, step     1380: bleu:   0.81, loss: 70619.9453, ppl:   3.4072, duration: 17.0386s\n",
      "2020-03-03 22:38:15,283 Validation result (greedy) at epoch  15, step     1390: bleu:   0.92, loss: 70833.5078, ppl:   3.4199, duration: 18.2407s\n",
      "2020-03-03 22:38:16,659 Epoch  15: total training loss 6276.19\n",
      "2020-03-03 22:38:16,659 EPOCH 16\n",
      "2020-03-03 22:38:34,507 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:38:34,508 Saving new checkpoint.\n",
      "2020-03-03 22:38:34,695 Validation result (greedy) at epoch  16, step     1400: bleu:   1.43, loss: 70915.7031, ppl:   3.4247, duration: 16.6369s\n",
      "2020-03-03 22:38:56,600 Validation result (greedy) at epoch  16, step     1410: bleu:   0.89, loss: 71765.1016, ppl:   3.4756, duration: 18.2505s\n",
      "2020-03-03 22:39:18,118 Validation result (greedy) at epoch  16, step     1420: bleu:   1.11, loss: 70856.2734, ppl:   3.4212, duration: 17.9731s\n",
      "2020-03-03 22:39:39,565 Validation result (greedy) at epoch  16, step     1430: bleu:   0.88, loss: 70981.1875, ppl:   3.4286, duration: 17.9242s\n",
      "2020-03-03 22:39:59,302 Validation result (greedy) at epoch  16, step     1440: bleu:   0.73, loss: 70789.8047, ppl:   3.4173, duration: 16.1855s\n",
      "2020-03-03 22:40:19,978 Validation result (greedy) at epoch  16, step     1450: bleu:   0.70, loss: 70782.7500, ppl:   3.4168, duration: 16.5926s\n",
      "2020-03-03 22:40:40,857 Validation result (greedy) at epoch  16, step     1460: bleu:   1.16, loss: 70563.6562, ppl:   3.4039, duration: 17.0685s\n",
      "2020-03-03 22:41:01,886 Validation result (greedy) at epoch  16, step     1470: bleu:   1.01, loss: 70919.9375, ppl:   3.4250, duration: 17.7601s\n",
      "2020-03-03 22:41:22,144 Validation result (greedy) at epoch  16, step     1480: bleu:   1.07, loss: 71362.7891, ppl:   3.4514, duration: 17.4046s\n",
      "2020-03-03 22:41:25,724 Epoch  16: total training loss 6040.00\n",
      "2020-03-03 22:41:25,725 EPOCH 17\n",
      "2020-03-03 22:41:44,382 Validation result (greedy) at epoch  17, step     1490: bleu:   0.79, loss: 70993.4141, ppl:   3.4294, duration: 17.9223s\n",
      "2020-03-03 22:42:04,649 Validation result (greedy) at epoch  17, step     1500: bleu:   1.32, loss: 70543.3281, ppl:   3.4027, duration: 16.6382s\n",
      "2020-03-03 22:42:26,603 Validation result (greedy) at epoch  17, step     1510: bleu:   0.92, loss: 71406.0156, ppl:   3.4540, duration: 18.3432s\n",
      "2020-03-03 22:42:48,663 Validation result (greedy) at epoch  17, step     1520: bleu:   1.01, loss: 71992.5312, ppl:   3.4894, duration: 18.4373s\n",
      "2020-03-03 22:43:10,371 Validation result (greedy) at epoch  17, step     1530: bleu:   1.09, loss: 70982.1250, ppl:   3.4287, duration: 18.3123s\n",
      "2020-03-03 22:43:31,038 Validation result (greedy) at epoch  17, step     1540: bleu:   0.99, loss: 71651.3750, ppl:   3.4688, duration: 16.6065s\n",
      "2020-03-03 22:43:51,932 Validation result (greedy) at epoch  17, step     1550: bleu:   1.14, loss: 70971.2109, ppl:   3.4280, duration: 17.2474s\n",
      "2020-03-03 22:44:12,784 Validation result (greedy) at epoch  17, step     1560: bleu:   1.20, loss: 70474.8047, ppl:   3.3986, duration: 17.0649s\n",
      "2020-03-03 22:44:33,775 Validation result (greedy) at epoch  17, step     1570: bleu:   0.87, loss: 70454.2422, ppl:   3.3974, duration: 16.9145s\n",
      "2020-03-03 22:44:55,455 Validation result (greedy) at epoch  17, step     1580: bleu:   1.19, loss: 70378.7500, ppl:   3.3930, duration: 18.1025s\n",
      "2020-03-03 22:44:55,619 Epoch  17: total training loss 5832.69\n",
      "2020-03-03 22:44:55,619 EPOCH 18\n",
      "2020-03-03 22:45:16,466 Validation result (greedy) at epoch  18, step     1590: bleu:   1.17, loss: 70742.3281, ppl:   3.4144, duration: 17.2699s\n",
      "2020-03-03 22:45:36,554 Validation result (greedy) at epoch  18, step     1600: bleu:   1.07, loss: 71482.1250, ppl:   3.4586, duration: 16.4872s\n",
      "2020-03-03 22:45:57,488 Validation result (greedy) at epoch  18, step     1610: bleu:   1.03, loss: 70833.0391, ppl:   3.4198, duration: 17.5937s\n",
      "2020-03-03 22:46:19,599 Validation result (greedy) at epoch  18, step     1620: bleu:   0.94, loss: 71723.1328, ppl:   3.4731, duration: 18.6319s\n",
      "2020-03-03 22:46:40,338 Validation result (greedy) at epoch  18, step     1630: bleu:   1.21, loss: 71247.3125, ppl:   3.4445, duration: 16.6595s\n",
      "2020-03-03 22:47:01,523 Validation result (greedy) at epoch  18, step     1640: bleu:   0.91, loss: 71159.4922, ppl:   3.4393, duration: 17.1780s\n",
      "2020-03-03 22:47:22,046 Validation result (greedy) at epoch  18, step     1650: bleu:   1.09, loss: 70693.4297, ppl:   3.4116, duration: 16.7975s\n",
      "2020-03-03 22:47:42,315 Validation result (greedy) at epoch  18, step     1660: bleu:   1.22, loss: 70746.6641, ppl:   3.4147, duration: 17.1505s\n",
      "2020-03-03 22:48:03,312 Validation result (greedy) at epoch  18, step     1670: bleu:   1.29, loss: 71329.4844, ppl:   3.4494, duration: 17.7834s\n",
      "2020-03-03 22:48:04,422 Epoch  18: total training loss 5573.65\n",
      "2020-03-03 22:48:04,422 EPOCH 19\n",
      "2020-03-03 22:48:22,708 Validation result (greedy) at epoch  19, step     1680: bleu:   1.08, loss: 70864.6484, ppl:   3.4217, duration: 16.5179s\n",
      "2020-03-03 22:48:44,078 Validation result (greedy) at epoch  19, step     1690: bleu:   1.18, loss: 71118.9531, ppl:   3.4368, duration: 18.1678s\n",
      "2020-03-03 22:49:04,832 Validation result (greedy) at epoch  19, step     1700: bleu:   1.38, loss: 72193.6797, ppl:   3.5016, duration: 16.8745s\n",
      "2020-03-03 22:49:25,040 Validation result (greedy) at epoch  19, step     1710: bleu:   1.38, loss: 71275.2812, ppl:   3.4462, duration: 16.5653s\n",
      "2020-03-03 22:49:44,642 Validation result (greedy) at epoch  19, step     1720: bleu:   1.10, loss: 71581.6797, ppl:   3.4646, duration: 16.2199s\n",
      "2020-03-03 22:50:06,392 Validation result (greedy) at epoch  19, step     1730: bleu:   1.01, loss: 71492.2969, ppl:   3.4592, duration: 18.2677s\n",
      "2020-03-03 22:50:27,759 Validation result (greedy) at epoch  19, step     1740: bleu:   1.11, loss: 72438.7266, ppl:   3.5165, duration: 18.1815s\n",
      "2020-03-03 22:50:48,720 Validation result (greedy) at epoch  19, step     1750: bleu:   1.30, loss: 71156.1328, ppl:   3.4391, duration: 16.9417s\n",
      "2020-03-03 22:51:09,343 Validation result (greedy) at epoch  19, step     1760: bleu:   1.03, loss: 71131.6797, ppl:   3.4376, duration: 17.2047s\n",
      "2020-03-03 22:51:11,997 Epoch  19: total training loss 5322.94\n",
      "2020-03-03 22:51:11,998 EPOCH 20\n",
      "2020-03-03 22:51:31,585 Validation result (greedy) at epoch  20, step     1770: bleu:   1.02, loss: 71642.0000, ppl:   3.4682, duration: 18.2712s\n",
      "2020-03-03 22:51:51,633 Validation result (greedy) at epoch  20, step     1780: bleu:   1.03, loss: 72534.3984, ppl:   3.5223, duration: 16.2865s\n",
      "2020-03-03 22:52:12,261 Validation result (greedy) at epoch  20, step     1790: bleu:   1.24, loss: 72295.0391, ppl:   3.5077, duration: 17.6844s\n",
      "2020-03-03 22:52:33,652 Validation result (greedy) at epoch  20, step     1800: bleu:   1.19, loss: 72258.9688, ppl:   3.5055, duration: 18.0330s\n",
      "2020-03-03 22:52:55,381 Validation result (greedy) at epoch  20, step     1810: bleu:   1.19, loss: 72966.0000, ppl:   3.5488, duration: 18.3933s\n",
      "2020-03-03 22:53:15,284 Validation result (greedy) at epoch  20, step     1820: bleu:   1.16, loss: 72545.5312, ppl:   3.5230, duration: 16.6455s\n",
      "2020-03-03 22:53:35,652 Validation result (greedy) at epoch  20, step     1830: bleu:   1.04, loss: 71936.8672, ppl:   3.4860, duration: 16.5457s\n",
      "2020-03-03 22:53:58,994 Validation result (greedy) at epoch  20, step     1840: bleu:   1.11, loss: 72001.8438, ppl:   3.4899, duration: 19.2656s\n",
      "2020-03-03 22:54:21,051 Validation result (greedy) at epoch  20, step     1850: bleu:   1.04, loss: 71623.6328, ppl:   3.4671, duration: 18.2943s\n",
      "2020-03-03 22:54:41,716 Validation result (greedy) at epoch  20, step     1860: bleu:   1.14, loss: 71574.6094, ppl:   3.4641, duration: 17.1145s\n",
      "2020-03-03 22:54:41,717 Epoch  20: total training loss 5163.57\n",
      "2020-03-03 22:54:41,717 Training ended after  20 epochs.\n",
      "2020-03-03 22:54:41,717 Best validation result (greedy) at step     1400:   1.43 eval_metric.\n",
      "2020-03-03 22:54:53,822  dev bleu:   1.16 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-03 22:54:53,823 Translations saved to: results/translate/es-shp_Religioso_300_512/char/00001400.hyps.dev\n",
      "2020-03-03 22:55:06,346 test bleu:   1.09 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-03 22:55:06,346 Translations saved to: results/translate/es-shp_Religioso_300_512/char/00001400.hyps.test\n",
      "results/translate/Educativo/char\n",
      "2020-03-03 22:55:08,831 Hello! This is Joey-NMT.\n",
      "2020-03-03 22:55:09.750500: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-03 22:55:09.750604: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-03 22:55:09.750618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-03-03 22:55:10,673 Total params: 12471652\n",
      "2020-03-03 22:55:10,673 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-03-03 22:55:13,286 cfg.name                           : my_experiment\n",
      "2020-03-03 22:55:13,286 cfg.data.src                       : es\n",
      "2020-03-03 22:55:13,286 cfg.data.trg                       : shp\n",
      "2020-03-03 22:55:13,286 cfg.data.train                     : data/translate/preprocessed/Educativo/char/train\n",
      "2020-03-03 22:55:13,286 cfg.data.dev                       : data/translate/preprocessed/Educativo/char/valid\n",
      "2020-03-03 22:55:13,286 cfg.data.test                      : data/translate/preprocessed/Educativo/char/test\n",
      "2020-03-03 22:55:13,286 cfg.data.level                     : char\n",
      "2020-03-03 22:55:13,286 cfg.data.lowercase                 : True\n",
      "2020-03-03 22:55:13,286 cfg.data.max_sent_length           : 130\n",
      "2020-03-03 22:55:13,286 cfg.data.src_voc_min_freq          : 1\n",
      "2020-03-03 22:55:13,286 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-03-03 22:55:13,286 cfg.testing.beam_size              : 5\n",
      "2020-03-03 22:55:13,286 cfg.testing.alpha                  : 1.0\n",
      "2020-03-03 22:55:13,286 cfg.training.reset_best_ckpt       : False\n",
      "2020-03-03 22:55:13,286 cfg.training.reset_scheduler       : False\n",
      "2020-03-03 22:55:13,286 cfg.training.reset_optimizer       : False\n",
      "2020-03-03 22:55:13,286 cfg.training.random_seed           : 42\n",
      "2020-03-03 22:55:13,286 cfg.training.optimizer             : adam\n",
      "2020-03-03 22:55:13,286 cfg.training.learning_rate         : 0.0005\n",
      "2020-03-03 22:55:13,286 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-03-03 22:55:13,286 cfg.training.clip_grad_val         : 1.0\n",
      "2020-03-03 22:55:13,286 cfg.training.weight_decay          : 0.0\n",
      "2020-03-03 22:55:13,287 cfg.training.batch_size            : 48\n",
      "2020-03-03 22:55:13,287 cfg.training.batch_type            : sentence\n",
      "2020-03-03 22:55:13,287 cfg.training.eval_batch_size       : 10\n",
      "2020-03-03 22:55:13,287 cfg.training.eval_batch_type       : sentence\n",
      "2020-03-03 22:55:13,287 cfg.training.batch_multiplier      : 1\n",
      "2020-03-03 22:55:13,287 cfg.training.scheduling            : plateau\n",
      "2020-03-03 22:55:13,287 cfg.training.patience              : 500\n",
      "2020-03-03 22:55:13,287 cfg.training.decrease_factor       : 0.5\n",
      "2020-03-03 22:55:13,287 cfg.training.epochs                : 20\n",
      "2020-03-03 22:55:13,287 cfg.training.validation_freq       : 10\n",
      "2020-03-03 22:55:13,287 cfg.training.logging_freq          : 1000\n",
      "2020-03-03 22:55:13,287 cfg.training.eval_metric           : bleu\n",
      "2020-03-03 22:55:13,287 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-03-03 22:55:13,287 cfg.training.model_dir             : results/translate/es-shp_Educativo_300_512/char\n",
      "2020-03-03 22:55:13,287 cfg.training.overwrite             : True\n",
      "2020-03-03 22:55:13,287 cfg.training.shuffle               : True\n",
      "2020-03-03 22:55:13,287 cfg.training.use_cuda              : True\n",
      "2020-03-03 22:55:13,287 cfg.training.max_output_length     : 60\n",
      "2020-03-03 22:55:13,287 cfg.training.print_valid_sents     : []\n",
      "2020-03-03 22:55:13,287 cfg.training.keep_last_ckpts       : 3\n",
      "2020-03-03 22:55:13,287 cfg.training.label_smoothing       : 0.0\n",
      "2020-03-03 22:55:13,287 cfg.model.initializer              : xavier\n",
      "2020-03-03 22:55:13,287 cfg.model.init_weight              : 0.01\n",
      "2020-03-03 22:55:13,287 cfg.model.init_gain                : 1.0\n",
      "2020-03-03 22:55:13,287 cfg.model.bias_initializer         : zeros\n",
      "2020-03-03 22:55:13,287 cfg.model.embed_initializer        : normal\n",
      "2020-03-03 22:55:13,287 cfg.model.embed_init_weight        : 0.1\n",
      "2020-03-03 22:55:13,288 cfg.model.embed_init_gain          : 1.0\n",
      "2020-03-03 22:55:13,288 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-03-03 22:55:13,288 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-03-03 22:55:13,288 cfg.model.tied_embeddings          : False\n",
      "2020-03-03 22:55:13,288 cfg.model.tied_softmax             : False\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.type             : recurrent\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.rnn_type         : gru\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.embeddings.scale : False\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.hidden_size      : 512\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.bidirectional    : True\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.dropout          : 0.3\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.num_layers       : 2\n",
      "2020-03-03 22:55:13,288 cfg.model.encoder.freeze           : False\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.type             : recurrent\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.rnn_type         : gru\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.embeddings.scale : False\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.hidden_size      : 512\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.dropout          : 0.3\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.num_layers       : 2\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.input_feeding    : True\n",
      "2020-03-03 22:55:13,288 cfg.model.decoder.init_hidden      : last\n",
      "2020-03-03 22:55:13,289 cfg.model.decoder.attention        : bahdanau\n",
      "2020-03-03 22:55:13,289 cfg.model.decoder.freeze           : False\n",
      "2020-03-03 22:55:13,289 Data set sizes: \n",
      "\ttrain 3815,\n",
      "\tvalid 498,\n",
      "\ttest 498\n",
      "2020-03-03 22:55:13,289 First training example:\n",
      "\t[SRC] @@ n e n o r a @@ n o n @@ a k i @@ k a i @@ t a n a k i n @@ w e s t i o r a b o @@ k i r i k a @@ w i s h a m a x o n @@ o n a n k i a k a n a @@ i x o n\n",
      "\t[TRG] @@ s e @@ e v a l u a r á @@ m e d i a n t e @@ p r o b l e m a s @@ p r o p u e s t o s @@ e n @@ u n a @@ h o j a @@ d e @@ a p l i c a c i ó n @@ i n d i v i d u a l\n",
      "2020-03-03 22:55:13,289 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) a (5) @@ (6) i (7) n (8) o (9) k\n",
      "2020-03-03 22:55:13,289 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) a (7) s (8) o (9) n\n",
      "2020-03-03 22:55:13,289 Number of Src words (types): 53\n",
      "2020-03-03 22:55:13,289 Number of Trg words (types): 54\n",
      "2020-03-03 22:55:13,289 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=53),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=54))\n",
      "2020-03-03 22:55:13,289 EPOCH 1\n",
      "2020-03-03 22:55:25,621 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:55:25,621 Saving new checkpoint.\n",
      "2020-03-03 22:55:25,752 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 77736.8203, ppl:  20.8366, duration: 9.7592s\n",
      "2020-03-03 22:55:38,875 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 74036.1875, ppl:  18.0321, duration: 10.5264s\n",
      "2020-03-03 22:55:51,567 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 73678.6016, ppl:  17.7819, duration: 10.3115s\n",
      "2020-03-03 22:56:04,023 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 69800.3203, ppl:  15.2821, duration: 10.1720s\n",
      "2020-03-03 22:56:17,259 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 64953.2188, ppl:  12.6459, duration: 9.8354s\n",
      "2020-03-03 22:56:30,179 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 61480.2930, ppl:  11.0416, duration: 10.4480s\n",
      "2020-03-03 22:56:42,086 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 57977.4219, ppl:   9.6295, duration: 9.4957s\n",
      "2020-03-03 22:56:54,451 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 55877.0156, ppl:   8.8709, duration: 9.8491s\n",
      "2020-03-03 22:56:54,452 Epoch   1: total training loss 10647.96\n",
      "2020-03-03 22:56:54,452 EPOCH 2\n",
      "2020-03-03 22:57:06,230 Validation result (greedy) at epoch   2, step       90: bleu:   0.00, loss: 53831.0586, ppl:   8.1895, duration: 9.1848s\n",
      "2020-03-03 22:57:19,010 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:57:19,011 Saving new checkpoint.\n",
      "2020-03-03 22:57:19,177 Validation result (greedy) at epoch   2, step      100: bleu:   1.38, loss: 51968.2617, ppl:   7.6148, duration: 10.3461s\n",
      "2020-03-03 22:57:32,607 Validation result (greedy) at epoch   2, step      110: bleu:   0.00, loss: 50636.0469, ppl:   7.2286, duration: 10.4794s\n",
      "2020-03-03 22:57:45,090 Validation result (greedy) at epoch   2, step      120: bleu:   0.00, loss: 49363.6797, ppl:   6.8781, duration: 9.6073s\n",
      "2020-03-03 22:57:58,152 Validation result (greedy) at epoch   2, step      130: bleu:   1.30, loss: 48110.8008, ppl:   6.5496, duration: 10.2046s\n",
      "2020-03-03 22:58:09,847 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:58:09,848 Saving new checkpoint.\n",
      "2020-03-03 22:58:09,975 Validation result (greedy) at epoch   2, step      140: bleu:   2.16, loss: 46916.8281, ppl:   6.2511, duration: 9.2161s\n",
      "2020-03-03 22:58:21,902 Validation result (greedy) at epoch   2, step      150: bleu:   0.00, loss: 46067.1953, ppl:   6.0470, duration: 10.2377s\n",
      "2020-03-03 22:58:34,589 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 45263.6641, ppl:   5.8602, duration: 9.9960s\n",
      "2020-03-03 22:58:34,590 Epoch   2: total training loss 7916.26\n",
      "2020-03-03 22:58:34,590 EPOCH 3\n",
      "2020-03-03 22:58:46,789 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:58:46,790 Saving new checkpoint.\n",
      "2020-03-03 22:58:46,932 Validation result (greedy) at epoch   3, step      170: bleu:   2.42, loss: 44439.4258, ppl:   5.6745, duration: 9.9563s\n",
      "2020-03-03 22:58:58,393 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 22:58:58,394 Saving new checkpoint.\n",
      "2020-03-03 22:58:58,528 Validation result (greedy) at epoch   3, step      180: bleu:   3.18, loss: 43645.6445, ppl:   5.5012, duration: 9.5252s\n",
      "2020-03-03 22:59:11,244 Validation result (greedy) at epoch   3, step      190: bleu:   0.00, loss: 42413.9375, ppl:   5.2428, duration: 9.8386s\n",
      "2020-03-03 22:59:23,920 Validation result (greedy) at epoch   3, step      200: bleu:   0.00, loss: 41531.5156, ppl:   5.0652, duration: 9.9045s\n",
      "2020-03-03 22:59:36,585 Validation result (greedy) at epoch   3, step      210: bleu:   1.34, loss: 40560.7734, ppl:   4.8767, duration: 10.1394s\n",
      "2020-03-03 22:59:48,674 Validation result (greedy) at epoch   3, step      220: bleu:   1.25, loss: 40227.8984, ppl:   4.8137, duration: 9.3074s\n",
      "2020-03-03 23:00:01,374 Validation result (greedy) at epoch   3, step      230: bleu:   0.84, loss: 39626.9492, ppl:   4.7020, duration: 9.5834s\n",
      "2020-03-03 23:00:13,930 Validation result (greedy) at epoch   3, step      240: bleu:   0.00, loss: 38978.8516, ppl:   4.5845, duration: 10.3741s\n",
      "2020-03-03 23:00:13,930 Epoch   3: total training loss 6783.42\n",
      "2020-03-03 23:00:13,931 EPOCH 4\n",
      "2020-03-03 23:00:26,708 Validation result (greedy) at epoch   4, step      250: bleu:   0.00, loss: 38130.9883, ppl:   4.4351, duration: 10.1631s\n",
      "2020-03-03 23:00:39,821 Validation result (greedy) at epoch   4, step      260: bleu:   0.00, loss: 37370.4219, ppl:   4.3053, duration: 10.5877s\n",
      "2020-03-03 23:00:53,159 Validation result (greedy) at epoch   4, step      270: bleu:   2.13, loss: 37512.8633, ppl:   4.3293, duration: 10.9510s\n",
      "2020-03-03 23:01:05,139 Validation result (greedy) at epoch   4, step      280: bleu:   0.00, loss: 36792.0977, ppl:   4.2091, duration: 9.3543s\n",
      "2020-03-03 23:01:17,485 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:01:17,485 Saving new checkpoint.\n",
      "2020-03-03 23:01:17,626 Validation result (greedy) at epoch   4, step      290: bleu:   3.84, loss: 35995.1797, ppl:   4.0801, duration: 9.3520s\n",
      "2020-03-03 23:01:30,044 Validation result (greedy) at epoch   4, step      300: bleu:   1.50, loss: 35079.8008, ppl:   3.9368, duration: 10.3576s\n",
      "2020-03-03 23:01:42,325 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:01:42,325 Saving new checkpoint.\n",
      "2020-03-03 23:01:42,452 Validation result (greedy) at epoch   4, step      310: bleu:   4.20, loss: 34424.0586, ppl:   3.8372, duration: 10.1092s\n",
      "2020-03-03 23:01:55,559 Validation result (greedy) at epoch   4, step      320: bleu:   2.20, loss: 33885.7266, ppl:   3.7573, duration: 10.5999s\n",
      "2020-03-03 23:01:55,561 Epoch   4: total training loss 5977.39\n",
      "2020-03-03 23:01:55,561 EPOCH 5\n",
      "2020-03-03 23:02:07,673 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:02:07,673 Saving new checkpoint.\n",
      "2020-03-03 23:02:07,818 Validation result (greedy) at epoch   5, step      330: bleu:   4.25, loss: 33627.5234, ppl:   3.7196, duration: 10.1215s\n",
      "2020-03-03 23:02:19,986 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:02:19,987 Saving new checkpoint.\n",
      "2020-03-03 23:02:20,120 Validation result (greedy) at epoch   5, step      340: bleu:   4.39, loss: 32872.3906, ppl:   3.6115, duration: 9.5049s\n",
      "2020-03-03 23:02:32,879 Validation result (greedy) at epoch   5, step      350: bleu:   4.06, loss: 32331.8555, ppl:   3.5361, duration: 9.8357s\n",
      "2020-03-03 23:02:46,057 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:02:46,057 Saving new checkpoint.\n",
      "2020-03-03 23:02:46,208 Validation result (greedy) at epoch   5, step      360: bleu:   5.00, loss: 32036.0312, ppl:   3.4954, duration: 10.5435s\n",
      "2020-03-03 23:02:58,284 Validation result (greedy) at epoch   5, step      370: bleu:   1.30, loss: 31903.4316, ppl:   3.4774, duration: 9.3147s\n",
      "2020-03-03 23:03:11,049 Validation result (greedy) at epoch   5, step      380: bleu:   4.38, loss: 31139.0312, ppl:   3.3751, duration: 9.8310s\n",
      "2020-03-03 23:03:23,911 Validation result (greedy) at epoch   5, step      390: bleu:   4.41, loss: 30774.7129, ppl:   3.3274, duration: 10.1250s\n",
      "2020-03-03 23:03:36,262 Validation result (greedy) at epoch   5, step      400: bleu:   3.93, loss: 30391.3086, ppl:   3.2779, duration: 10.0854s\n",
      "2020-03-03 23:03:36,263 Epoch   5: total training loss 5324.81\n",
      "2020-03-03 23:03:36,264 EPOCH 6\n",
      "2020-03-03 23:03:48,892 Validation result (greedy) at epoch   6, step      410: bleu:   2.11, loss: 30310.6543, ppl:   3.2676, duration: 9.8953s\n",
      "2020-03-03 23:04:01,710 Validation result (greedy) at epoch   6, step      420: bleu:   4.78, loss: 29719.3691, ppl:   3.1930, duration: 9.9774s\n",
      "2020-03-03 23:04:15,349 Validation result (greedy) at epoch   6, step      430: bleu:   4.15, loss: 29461.4414, ppl:   3.1610, duration: 11.0384s\n",
      "2020-03-03 23:04:27,423 Validation result (greedy) at epoch   6, step      440: bleu:   3.71, loss: 29263.7129, ppl:   3.1367, duration: 9.9569s\n",
      "2020-03-03 23:04:40,074 Validation result (greedy) at epoch   6, step      450: bleu:   4.10, loss: 29314.4648, ppl:   3.1429, duration: 10.3226s\n",
      "2020-03-03 23:04:53,528 Validation result (greedy) at epoch   6, step      460: bleu:   4.87, loss: 28832.3047, ppl:   3.0842, duration: 10.4509s\n",
      "2020-03-03 23:05:05,253 Validation result (greedy) at epoch   6, step      470: bleu:   4.47, loss: 29377.8691, ppl:   3.1507, duration: 9.6486s\n",
      "2020-03-03 23:05:17,976 Validation result (greedy) at epoch   6, step      480: bleu:   3.59, loss: 28765.2461, ppl:   3.0762, duration: 9.5591s\n",
      "2020-03-03 23:05:17,977 Epoch   6: total training loss 4880.81\n",
      "2020-03-03 23:05:17,977 EPOCH 7\n",
      "2020-03-03 23:05:30,351 Validation result (greedy) at epoch   7, step      490: bleu:   4.67, loss: 28134.8164, ppl:   3.0013, duration: 9.5138s\n",
      "2020-03-03 23:05:42,884 Validation result (greedy) at epoch   7, step      500: bleu:   4.97, loss: 28028.2324, ppl:   2.9889, duration: 10.1457s\n",
      "2020-03-03 23:05:54,015 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:05:54,015 Saving new checkpoint.\n",
      "2020-03-03 23:05:54,152 Validation result (greedy) at epoch   7, step      510: bleu:   5.63, loss: 27398.8105, ppl:   2.9163, duration: 9.4692s\n",
      "2020-03-03 23:06:06,210 Validation result (greedy) at epoch   7, step      520: bleu:   4.89, loss: 27066.0820, ppl:   2.8786, duration: 9.4788s\n",
      "2020-03-03 23:06:18,379 Validation result (greedy) at epoch   7, step      530: bleu:   3.93, loss: 27152.2188, ppl:   2.8883, duration: 10.1570s\n",
      "2020-03-03 23:06:30,445 Validation result (greedy) at epoch   7, step      540: bleu:   5.00, loss: 26903.3008, ppl:   2.8604, duration: 9.2936s\n",
      "2020-03-03 23:06:42,450 Validation result (greedy) at epoch   7, step      550: bleu:   5.49, loss: 26673.7129, ppl:   2.8348, duration: 9.2895s\n",
      "2020-03-03 23:06:56,053 Validation result (greedy) at epoch   7, step      560: bleu:   5.10, loss: 26723.5391, ppl:   2.8404, duration: 10.3944s\n",
      "2020-03-03 23:06:56,054 Epoch   7: total training loss 4508.23\n",
      "2020-03-03 23:06:56,054 EPOCH 8\n",
      "2020-03-03 23:07:11,052 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:07:11,053 Saving new checkpoint.\n",
      "2020-03-03 23:07:11,200 Validation result (greedy) at epoch   8, step      570: bleu:   5.84, loss: 26082.6152, ppl:   2.7701, duration: 12.2827s\n",
      "2020-03-03 23:07:24,061 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:07:24,062 Saving new checkpoint.\n",
      "2020-03-03 23:07:24,247 Validation result (greedy) at epoch   8, step      580: bleu:   5.98, loss: 26190.9785, ppl:   2.7819, duration: 10.7575s\n",
      "2020-03-03 23:07:37,398 Validation result (greedy) at epoch   8, step      590: bleu:   4.79, loss: 25797.1270, ppl:   2.7394, duration: 10.3929s\n",
      "2020-03-03 23:07:50,238 Validation result (greedy) at epoch   8, step      600: bleu:   5.37, loss: 25720.5312, ppl:   2.7312, duration: 10.4324s\n",
      "2020-03-03 23:08:03,026 Validation result (greedy) at epoch   8, step      610: bleu:   4.82, loss: 25508.4238, ppl:   2.7087, duration: 9.6424s\n",
      "2020-03-03 23:08:16,027 Validation result (greedy) at epoch   8, step      620: bleu:   5.63, loss: 25223.0898, ppl:   2.6787, duration: 10.5327s\n",
      "2020-03-03 23:08:28,374 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:08:28,375 Saving new checkpoint.\n",
      "2020-03-03 23:08:28,521 Validation result (greedy) at epoch   8, step      630: bleu:   6.18, loss: 24926.5215, ppl:   2.6478, duration: 9.7420s\n",
      "2020-03-03 23:08:39,817 Validation result (greedy) at epoch   8, step      640: bleu:   5.92, loss: 24835.9375, ppl:   2.6385, duration: 8.7489s\n",
      "2020-03-03 23:08:39,818 Epoch   8: total training loss 4186.32\n",
      "2020-03-03 23:08:39,818 EPOCH 9\n",
      "2020-03-03 23:08:52,618 Validation result (greedy) at epoch   9, step      650: bleu:   5.25, loss: 24643.4355, ppl:   2.6187, duration: 9.8301s\n",
      "2020-03-03 23:09:04,687 Validation result (greedy) at epoch   9, step      660: bleu:   6.17, loss: 24280.3848, ppl:   2.5818, duration: 9.0429s\n",
      "2020-03-03 23:09:16,613 Validation result (greedy) at epoch   9, step      670: bleu:   3.50, loss: 24649.9473, ppl:   2.6193, duration: 9.6997s\n",
      "2020-03-03 23:09:28,901 Validation result (greedy) at epoch   9, step      680: bleu:   5.93, loss: 24553.4551, ppl:   2.6095, duration: 10.2212s\n",
      "2020-03-03 23:09:40,362 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:09:40,362 Saving new checkpoint.\n",
      "2020-03-03 23:09:40,492 Validation result (greedy) at epoch   9, step      690: bleu:   6.23, loss: 24150.8398, ppl:   2.5688, duration: 9.2047s\n",
      "2020-03-03 23:09:53,913 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:09:53,913 Saving new checkpoint.\n",
      "2020-03-03 23:09:54,042 Validation result (greedy) at epoch   9, step      700: bleu:   6.28, loss: 24165.0801, ppl:   2.5702, duration: 10.8909s\n",
      "2020-03-03 23:10:06,802 Validation result (greedy) at epoch   9, step      710: bleu:   5.23, loss: 23833.0176, ppl:   2.5371, duration: 10.1660s\n",
      "2020-03-03 23:10:17,737 Validation result (greedy) at epoch   9, step      720: bleu:   6.25, loss: 23603.9023, ppl:   2.5145, duration: 8.9289s\n",
      "2020-03-03 23:10:17,738 Epoch   9: total training loss 3916.50\n",
      "2020-03-03 23:10:17,738 EPOCH 10\n",
      "2020-03-03 23:10:30,152 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:10:30,152 Saving new checkpoint.\n",
      "2020-03-03 23:10:30,287 Validation result (greedy) at epoch  10, step      730: bleu:   6.85, loss: 23514.7109, ppl:   2.5057, duration: 10.1079s\n",
      "2020-03-03 23:10:42,995 Validation result (greedy) at epoch  10, step      740: bleu:   6.24, loss: 23435.2598, ppl:   2.4980, duration: 9.6064s\n",
      "2020-03-03 23:10:54,828 Validation result (greedy) at epoch  10, step      750: bleu:   6.76, loss: 23259.6953, ppl:   2.4809, duration: 9.4411s\n",
      "2020-03-03 23:11:08,034 Validation result (greedy) at epoch  10, step      760: bleu:   6.42, loss: 23248.4805, ppl:   2.4798, duration: 10.4246s\n",
      "2020-03-03 23:11:20,170 Validation result (greedy) at epoch  10, step      770: bleu:   3.87, loss: 23841.3711, ppl:   2.5379, duration: 9.9443s\n",
      "2020-03-03 23:11:32,432 Validation result (greedy) at epoch  10, step      780: bleu:   6.42, loss: 23002.6816, ppl:   2.4561, duration: 9.5567s\n",
      "2020-03-03 23:11:43,916 Validation result (greedy) at epoch  10, step      790: bleu:   6.58, loss: 22879.5098, ppl:   2.4443, duration: 8.9478s\n",
      "2020-03-03 23:11:58,229 Validation result (greedy) at epoch  10, step      800: bleu:   6.66, loss: 22852.7207, ppl:   2.4418, duration: 11.5687s\n",
      "2020-03-03 23:11:58,229 Epoch  10: total training loss 3678.52\n",
      "2020-03-03 23:11:58,229 EPOCH 11\n",
      "2020-03-03 23:12:10,338 Validation result (greedy) at epoch  11, step      810: bleu:   6.02, loss: 22969.8477, ppl:   2.4530, duration: 9.4146s\n",
      "2020-03-03 23:12:23,279 Validation result (greedy) at epoch  11, step      820: bleu:   5.24, loss: 22565.1816, ppl:   2.4145, duration: 10.7572s\n",
      "2020-03-03 23:12:34,923 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:12:34,923 Saving new checkpoint.\n",
      "2020-03-03 23:12:35,105 Validation result (greedy) at epoch  11, step      830: bleu:   7.15, loss: 22295.1016, ppl:   2.3891, duration: 9.2503s\n",
      "2020-03-03 23:12:47,684 Validation result (greedy) at epoch  11, step      840: bleu:   6.51, loss: 22660.9258, ppl:   2.4235, duration: 10.0776s\n",
      "2020-03-03 23:13:01,625 Validation result (greedy) at epoch  11, step      850: bleu:   5.94, loss: 22604.3984, ppl:   2.4182, duration: 11.3668s\n",
      "2020-03-03 23:13:14,264 Validation result (greedy) at epoch  11, step      860: bleu:   6.09, loss: 22265.8926, ppl:   2.3864, duration: 9.7163s\n",
      "2020-03-03 23:13:26,979 Validation result (greedy) at epoch  11, step      870: bleu:   6.19, loss: 22484.4668, ppl:   2.4069, duration: 9.6318s\n",
      "2020-03-03 23:13:40,487 Validation result (greedy) at epoch  11, step      880: bleu:   6.20, loss: 22173.2812, ppl:   2.3778, duration: 11.3826s\n",
      "2020-03-03 23:13:40,488 Epoch  11: total training loss 3482.19\n",
      "2020-03-03 23:13:40,488 EPOCH 12\n",
      "2020-03-03 23:13:54,182 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:13:54,183 Saving new checkpoint.\n",
      "2020-03-03 23:13:54,382 Validation result (greedy) at epoch  12, step      890: bleu:   7.45, loss: 21924.8672, ppl:   2.3548, duration: 10.5581s\n",
      "2020-03-03 23:14:07,082 Validation result (greedy) at epoch  12, step      900: bleu:   6.74, loss: 21906.9023, ppl:   2.3532, duration: 10.4929s\n",
      "2020-03-03 23:14:18,354 Validation result (greedy) at epoch  12, step      910: bleu:   6.09, loss: 22125.4258, ppl:   2.3734, duration: 9.4298s\n",
      "2020-03-03 23:14:30,079 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:14:30,079 Saving new checkpoint.\n",
      "2020-03-03 23:14:30,210 Validation result (greedy) at epoch  12, step      920: bleu:   7.47, loss: 21935.1133, ppl:   2.3558, duration: 9.1655s\n",
      "2020-03-03 23:14:43,661 Validation result (greedy) at epoch  12, step      930: bleu:   6.63, loss: 21702.2891, ppl:   2.3345, duration: 10.6522s\n",
      "2020-03-03 23:14:57,604 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:14:57,604 Saving new checkpoint.\n",
      "2020-03-03 23:14:57,750 Validation result (greedy) at epoch  12, step      940: bleu:   7.96, loss: 21948.5547, ppl:   2.3570, duration: 11.3335s\n",
      "2020-03-03 23:15:11,510 Validation result (greedy) at epoch  12, step      950: bleu:   6.57, loss: 21475.9355, ppl:   2.3139, duration: 11.0314s\n",
      "2020-03-03 23:15:24,176 Validation result (greedy) at epoch  12, step      960: bleu:   7.47, loss: 21279.7852, ppl:   2.2962, duration: 10.4547s\n",
      "2020-03-03 23:15:24,177 Epoch  12: total training loss 3287.42\n",
      "2020-03-03 23:15:24,177 EPOCH 13\n",
      "2020-03-03 23:15:37,345 Validation result (greedy) at epoch  13, step      970: bleu:   6.93, loss: 21107.0312, ppl:   2.2808, duration: 10.3441s\n",
      "2020-03-03 23:15:50,177 Validation result (greedy) at epoch  13, step      980: bleu:   7.51, loss: 21174.0801, ppl:   2.2868, duration: 10.3766s\n",
      "2020-03-03 23:16:02,194 Validation result (greedy) at epoch  13, step      990: bleu:   6.94, loss: 21221.5664, ppl:   2.2910, duration: 9.6998s\n",
      "2020-03-03 23:16:04,963 Epoch  13 Step:     1000 Batch Loss:    21.578831 Tokens per Sec:     8121, Lr: 0.000500\n",
      "2020-03-03 23:16:14,480 Validation result (greedy) at epoch  13, step     1000: bleu:   7.19, loss: 21443.8418, ppl:   2.3110, duration: 9.5168s\n",
      "2020-03-03 23:16:27,217 Validation result (greedy) at epoch  13, step     1010: bleu:   7.84, loss: 20955.5234, ppl:   2.2673, duration: 9.9525s\n",
      "2020-03-03 23:16:39,761 Validation result (greedy) at epoch  13, step     1020: bleu:   7.54, loss: 20766.8750, ppl:   2.2507, duration: 9.9264s\n",
      "2020-03-03 23:16:51,357 Validation result (greedy) at epoch  13, step     1030: bleu:   7.58, loss: 21022.5000, ppl:   2.2733, duration: 9.1367s\n",
      "2020-03-03 23:17:03,675 Validation result (greedy) at epoch  13, step     1040: bleu:   7.44, loss: 20796.1855, ppl:   2.2533, duration: 9.8667s\n",
      "2020-03-03 23:17:03,676 Epoch  13: total training loss 3057.51\n",
      "2020-03-03 23:17:03,677 EPOCH 14\n",
      "2020-03-03 23:17:16,116 Validation result (greedy) at epoch  14, step     1050: bleu:   7.36, loss: 21307.1465, ppl:   2.2987, duration: 9.7920s\n",
      "2020-03-03 23:17:28,608 Validation result (greedy) at epoch  14, step     1060: bleu:   7.02, loss: 21298.7324, ppl:   2.2979, duration: 9.7517s\n",
      "2020-03-03 23:17:40,929 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:17:40,929 Saving new checkpoint.\n",
      "2020-03-03 23:17:41,065 Validation result (greedy) at epoch  14, step     1070: bleu:   8.41, loss: 20885.3223, ppl:   2.2611, duration: 9.3718s\n",
      "2020-03-03 23:17:54,938 Validation result (greedy) at epoch  14, step     1080: bleu:   7.44, loss: 20695.2188, ppl:   2.2444, duration: 11.5883s\n",
      "2020-03-03 23:18:05,919 Validation result (greedy) at epoch  14, step     1090: bleu:   7.34, loss: 20784.2500, ppl:   2.2522, duration: 8.7782s\n",
      "2020-03-03 23:18:18,852 Validation result (greedy) at epoch  14, step     1100: bleu:   7.91, loss: 20474.5625, ppl:   2.2251, duration: 9.7076s\n",
      "2020-03-03 23:18:31,326 Validation result (greedy) at epoch  14, step     1110: bleu:   7.62, loss: 20224.9199, ppl:   2.2035, duration: 10.1910s\n",
      "2020-03-03 23:18:42,789 Validation result (greedy) at epoch  14, step     1120: bleu:   7.83, loss: 20205.2988, ppl:   2.2019, duration: 8.9832s\n",
      "2020-03-03 23:18:42,790 Epoch  14: total training loss 2912.09\n",
      "2020-03-03 23:18:42,790 EPOCH 15\n",
      "2020-03-03 23:18:54,533 Validation result (greedy) at epoch  15, step     1130: bleu:   8.19, loss: 20308.2051, ppl:   2.2107, duration: 8.6561s\n",
      "2020-03-03 23:19:05,390 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:19:05,390 Saving new checkpoint.\n",
      "2020-03-03 23:19:05,517 Validation result (greedy) at epoch  15, step     1140: bleu:   8.62, loss: 20244.5957, ppl:   2.2052, duration: 8.7302s\n",
      "2020-03-03 23:19:16,683 Validation result (greedy) at epoch  15, step     1150: bleu:   8.24, loss: 20342.8477, ppl:   2.2137, duration: 8.9626s\n",
      "2020-03-03 23:19:27,900 Validation result (greedy) at epoch  15, step     1160: bleu:   6.60, loss: 20343.2441, ppl:   2.2138, duration: 8.9283s\n",
      "2020-03-03 23:19:40,013 Validation result (greedy) at epoch  15, step     1170: bleu:   7.84, loss: 20228.6484, ppl:   2.2039, duration: 9.8249s\n",
      "2020-03-03 23:19:52,852 Validation result (greedy) at epoch  15, step     1180: bleu:   7.50, loss: 20906.0957, ppl:   2.2630, duration: 9.9907s\n",
      "2020-03-03 23:20:04,923 Validation result (greedy) at epoch  15, step     1190: bleu:   7.58, loss: 20983.1602, ppl:   2.2698, duration: 9.7042s\n",
      "2020-03-03 23:20:16,985 Validation result (greedy) at epoch  15, step     1200: bleu:   7.84, loss: 21283.9727, ppl:   2.2966, duration: 9.8842s\n",
      "2020-03-03 23:20:16,986 Epoch  15: total training loss 2737.69\n",
      "2020-03-03 23:20:16,986 EPOCH 16\n",
      "2020-03-03 23:20:28,324 Validation result (greedy) at epoch  16, step     1210: bleu:   7.74, loss: 20148.9648, ppl:   2.1970, duration: 8.6661s\n",
      "2020-03-03 23:20:41,561 Validation result (greedy) at epoch  16, step     1220: bleu:   7.78, loss: 20053.9648, ppl:   2.1889, duration: 10.3382s\n",
      "2020-03-03 23:20:54,624 Validation result (greedy) at epoch  16, step     1230: bleu:   8.24, loss: 20558.3281, ppl:   2.2324, duration: 10.4379s\n",
      "2020-03-03 23:21:06,349 Validation result (greedy) at epoch  16, step     1240: bleu:   8.02, loss: 20368.0684, ppl:   2.2159, duration: 9.3930s\n",
      "2020-03-03 23:21:18,542 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:21:18,542 Saving new checkpoint.\n",
      "2020-03-03 23:21:18,686 Validation result (greedy) at epoch  16, step     1250: bleu:   9.00, loss: 19897.2930, ppl:   2.1755, duration: 9.8026s\n",
      "2020-03-03 23:21:31,533 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:21:31,533 Saving new checkpoint.\n",
      "2020-03-03 23:21:31,673 Validation result (greedy) at epoch  16, step     1260: bleu:   9.24, loss: 19740.6641, ppl:   2.1623, duration: 10.2962s\n",
      "2020-03-03 23:21:43,891 Validation result (greedy) at epoch  16, step     1270: bleu:   8.68, loss: 20034.3047, ppl:   2.1872, duration: 9.6293s\n",
      "2020-03-03 23:21:56,878 Validation result (greedy) at epoch  16, step     1280: bleu:   8.83, loss: 19821.3809, ppl:   2.1691, duration: 10.3767s\n",
      "2020-03-03 23:21:56,879 Epoch  16: total training loss 2579.23\n",
      "2020-03-03 23:21:56,879 EPOCH 17\n",
      "2020-03-03 23:22:10,012 Validation result (greedy) at epoch  17, step     1290: bleu:   8.79, loss: 20021.9238, ppl:   2.1861, duration: 10.8550s\n",
      "2020-03-03 23:22:23,020 Validation result (greedy) at epoch  17, step     1300: bleu:   8.24, loss: 20050.1406, ppl:   2.1885, duration: 10.4686s\n",
      "2020-03-03 23:22:36,374 Validation result (greedy) at epoch  17, step     1310: bleu:   8.40, loss: 19855.8516, ppl:   2.1720, duration: 10.4400s\n",
      "2020-03-03 23:22:48,338 Validation result (greedy) at epoch  17, step     1320: bleu:   8.45, loss: 20207.3555, ppl:   2.2020, duration: 10.0984s\n",
      "2020-03-03 23:23:01,132 Validation result (greedy) at epoch  17, step     1330: bleu:   8.68, loss: 19889.8613, ppl:   2.1749, duration: 9.9273s\n",
      "2020-03-03 23:23:15,914 Validation result (greedy) at epoch  17, step     1340: bleu:   8.96, loss: 19971.3066, ppl:   2.1818, duration: 11.5617s\n",
      "2020-03-03 23:23:28,836 Validation result (greedy) at epoch  17, step     1350: bleu:   8.76, loss: 19984.3398, ppl:   2.1829, duration: 10.1846s\n",
      "2020-03-03 23:23:40,603 Validation result (greedy) at epoch  17, step     1360: bleu:   8.99, loss: 19881.3613, ppl:   2.1742, duration: 9.8043s\n",
      "2020-03-03 23:23:40,604 Epoch  17: total training loss 2365.02\n",
      "2020-03-03 23:23:40,604 EPOCH 18\n",
      "2020-03-03 23:23:52,355 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:23:52,356 Saving new checkpoint.\n",
      "2020-03-03 23:23:52,525 Validation result (greedy) at epoch  18, step     1370: bleu:   9.54, loss: 19774.3906, ppl:   2.1651, duration: 9.4280s\n",
      "2020-03-03 23:24:05,534 Validation result (greedy) at epoch  18, step     1380: bleu:   8.41, loss: 19826.0742, ppl:   2.1695, duration: 10.3488s\n",
      "2020-03-03 23:24:17,880 Validation result (greedy) at epoch  18, step     1390: bleu:   9.03, loss: 19740.2168, ppl:   2.1622, duration: 9.5600s\n",
      "2020-03-03 23:24:29,062 Validation result (greedy) at epoch  18, step     1400: bleu:   9.22, loss: 19878.3125, ppl:   2.1739, duration: 9.3318s\n",
      "2020-03-03 23:24:41,696 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:24:41,696 Saving new checkpoint.\n",
      "2020-03-03 23:24:41,842 Validation result (greedy) at epoch  18, step     1410: bleu:   9.61, loss: 19734.0234, ppl:   2.1617, duration: 10.2990s\n",
      "2020-03-03 23:24:54,138 Validation result (greedy) at epoch  18, step     1420: bleu:   8.66, loss: 19776.5723, ppl:   2.1653, duration: 9.0070s\n",
      "2020-03-03 23:25:06,483 Validation result (greedy) at epoch  18, step     1430: bleu:   8.66, loss: 20050.6582, ppl:   2.1886, duration: 10.1690s\n",
      "2020-03-03 23:25:18,961 Validation result (greedy) at epoch  18, step     1440: bleu:   8.06, loss: 19737.1426, ppl:   2.1620, duration: 9.8436s\n",
      "2020-03-03 23:25:18,962 Epoch  18: total training loss 2207.06\n",
      "2020-03-03 23:25:18,963 EPOCH 19\n",
      "2020-03-03 23:25:32,402 Validation result (greedy) at epoch  19, step     1450: bleu:   9.13, loss: 20278.3320, ppl:   2.2081, duration: 10.6243s\n",
      "2020-03-03 23:25:44,673 Validation result (greedy) at epoch  19, step     1460: bleu:   9.21, loss: 20405.5215, ppl:   2.2191, duration: 9.7801s\n",
      "2020-03-03 23:25:56,991 Validation result (greedy) at epoch  19, step     1470: bleu:   9.28, loss: 19880.9473, ppl:   2.1741, duration: 9.4533s\n",
      "2020-03-03 23:26:08,976 Validation result (greedy) at epoch  19, step     1480: bleu:   9.23, loss: 20290.4258, ppl:   2.2092, duration: 9.6406s\n",
      "2020-03-03 23:26:21,980 Validation result (greedy) at epoch  19, step     1490: bleu:   9.49, loss: 19741.7461, ppl:   2.1623, duration: 10.7963s\n",
      "2020-03-03 23:26:34,544 Validation result (greedy) at epoch  19, step     1500: bleu:   9.06, loss: 19880.9336, ppl:   2.1741, duration: 9.8376s\n",
      "2020-03-03 23:26:46,914 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:26:46,914 Saving new checkpoint.\n",
      "2020-03-03 23:26:47,068 Validation result (greedy) at epoch  19, step     1510: bleu:   9.68, loss: 20360.6211, ppl:   2.2153, duration: 9.9723s\n",
      "2020-03-03 23:27:00,720 Validation result (greedy) at epoch  19, step     1520: bleu:   9.30, loss: 20924.9785, ppl:   2.2646, duration: 11.1713s\n",
      "2020-03-03 23:27:00,721 Epoch  19: total training loss 2067.45\n",
      "2020-03-03 23:27:00,721 EPOCH 20\n",
      "2020-03-03 23:27:13,061 Validation result (greedy) at epoch  20, step     1530: bleu:   8.71, loss: 20232.5781, ppl:   2.2042, duration: 9.8585s\n",
      "2020-03-03 23:27:24,781 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:27:24,782 Saving new checkpoint.\n",
      "2020-03-03 23:27:24,961 Validation result (greedy) at epoch  20, step     1540: bleu:   9.70, loss: 19774.3984, ppl:   2.1651, duration: 9.3732s\n",
      "2020-03-03 23:27:37,311 Validation result (greedy) at epoch  20, step     1550: bleu:   8.73, loss: 19808.5273, ppl:   2.1680, duration: 9.8796s\n",
      "2020-03-03 23:27:50,090 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:27:50,090 Saving new checkpoint.\n",
      "2020-03-03 23:27:50,228 Validation result (greedy) at epoch  20, step     1560: bleu:   9.92, loss: 20203.6680, ppl:   2.2017, duration: 10.1718s\n",
      "2020-03-03 23:28:03,165 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-03 23:28:03,166 Saving new checkpoint.\n",
      "2020-03-03 23:28:03,343 Validation result (greedy) at epoch  20, step     1570: bleu:  10.16, loss: 20146.4707, ppl:   2.1968, duration: 10.7001s\n",
      "2020-03-03 23:28:15,963 Validation result (greedy) at epoch  20, step     1580: bleu:   9.71, loss: 20095.5195, ppl:   2.1924, duration: 10.1292s\n",
      "2020-03-03 23:28:28,792 Validation result (greedy) at epoch  20, step     1590: bleu:  10.08, loss: 19865.8066, ppl:   2.1728, duration: 9.8380s\n",
      "2020-03-03 23:28:42,195 Validation result (greedy) at epoch  20, step     1600: bleu:   9.49, loss: 20448.2480, ppl:   2.2229, duration: 10.5863s\n",
      "2020-03-03 23:28:42,195 Epoch  20: total training loss 1892.35\n",
      "2020-03-03 23:28:42,196 Training ended after  20 epochs.\n",
      "2020-03-03 23:28:42,196 Best validation result (greedy) at step     1570:  10.16 eval_metric.\n",
      "2020-03-03 23:28:49,624  dev bleu:  11.36 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-03 23:28:49,625 Translations saved to: results/translate/es-shp_Educativo_300_512/char/00001570.hyps.dev\n",
      "2020-03-03 23:28:56,374 test bleu:  10.41 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-03 23:28:56,375 Translations saved to: results/translate/es-shp_Educativo_300_512/char/00001570.hyps.test\n"
     ]
    }
   ],
   "source": [
    "base_path = 'data/translate/preprocessed'\n",
    "datas = os.listdir(base_path)\n",
    "emb_size = 300\n",
    "hidden_size = 512\n",
    "for data in ['Religioso', 'Educativo']:\n",
    "    data_path = os.path.join(base_path, data)\n",
    "    for lang_in, lang_out in [['es', 'shp']]:\n",
    "        segmentations = os.listdir(data_path)\n",
    "        for segment in segmentations:\n",
    "            if 'char' in segment:\n",
    "                segment_path = os.path.join(data_path, segment)\n",
    "                print(os.path.join('results/translate', data, segment))\n",
    "                if 'bpe_drop' in segment:\n",
    "                    level = 'bpe'\n",
    "                elif 'bpe' in segment:\n",
    "                    level = 'bpe'\n",
    "                elif 'char' in segment:\n",
    "                    level = 'char'\n",
    "                elif 'word' in segment:\n",
    "                    level = 'word'\n",
    "                elif 'syl' in segment:\n",
    "                    level = 'syl'\n",
    "                else:\n",
    "                    level = None\n",
    "\n",
    "                val_freq = 10\n",
    "                f_config = config.format(lang_src=lang_in, lang_tgt=lang_out, \n",
    "                                         train_path=os.path.join(segment_path, 'train'),\n",
    "                                         test_path=os.path.join(segment_path, 'test'),\n",
    "                                         dev_path=os.path.join(segment_path, 'valid'),\n",
    "                                         level=level,\n",
    "                                         emb_size=emb_size,\n",
    "                                         hidden_size=hidden_size,\n",
    "                                         val_freq=val_freq,\n",
    "                                         model_dir=os.path.join('results/translate',\\\n",
    "                                                                f'{lang_in}-{lang_out}_{data}_{emb_size}_{hidden_size}', segment))\n",
    "\n",
    "                with open(\"joeynmt/configs/transformer_{name}.yaml\".format(name=\"test\"),'w') as f:\n",
    "                    f.write(f_config)\n",
    "\n",
    "                !python3 joeynmt/joeynmt train \"joeynmt/configs/transformer_test.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
