{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"\"\"\n",
    "name: \"my_experiment\"\n",
    "\n",
    "# This configuration serves the purpose of documenting and explaining the settings, *NOT* as an example for good hyperparamter settings.\n",
    "\n",
    "data: # specify your data here\n",
    "    src: {lang_src}                       # src language: expected suffix of train files, e.g. \"train.de\"\n",
    "    trg: {lang_tgt}                       # trg language\n",
    "    train: {train_path}     # training data\n",
    "    dev: {dev_path}         # development data for validation\n",
    "    test: {test_path}       # test data for testing final model; optional\n",
    "    level: {level}                  # segmentation level: either \"word\", \"bpe\" or \"char\"\n",
    "    lowercase: True                 # lowercase the data, also for validation\n",
    "    max_sent_length: 130             # filter out longer sentences from training (src+trg)\n",
    "    src_voc_min_freq: 1             # src minimum frequency for a token to become part of the vocabulary\n",
    "    trg_voc_min_freq: 1             # trg minimum frequency for a token to become part of the vocabulary\n",
    "    #src_vocab: \"my_model/src_vocab.txt\"  # if specified, load a vocabulary from this file\n",
    "    #trg_vocab: \"my_model/trg_vocab.txt\"  # one token per line, line number is index\n",
    "\n",
    "pretrained_data: # specify your data here\n",
    "    src: {pretrained_lang_src}                       # src language: expected suffix of train files, e.g. \"train.de\"\n",
    "    trg: {pretrained_lang_tgt}                       # trg language\n",
    "    train: {pretrained_train_path}     # training data\n",
    "    dev: {pretrained_dev_path}         # development data for validation\n",
    "    test: {pretrained_test_path}       # test data for testing final model; optional\n",
    "    level: {level}                  # segmentation level: either \"word\", \"bpe\" or \"char\"\n",
    "    lowercase: True                 # lowercase the data, also for validation\n",
    "    max_sent_length: 150             # filter out longer sentences from training (src+trg)\n",
    "    src_voc_min_freq: 1             # src minimum frequency for a token to become part of the vocabulary\n",
    "    trg_voc_min_freq: 1             # trg minimum frequency for a token to become part of the vocabulary\n",
    "    #src_vocab: \"my_model/src_vocab.txt\"  # if specified, load a vocabulary from this file\n",
    "    #trg_vocab: \"my_model/trg_vocab.txt\"  # one token per line, line number is index\n",
    "\n",
    "testing:                            # specify which inference algorithm to use for testing (for validation it's always greedy decoding)\n",
    "    beam_size: 5                    # size of the beam for beam search\n",
    "    alpha: 1.0                      # length penalty for beam search\n",
    "\n",
    "training:                           # specify training details here\n",
    "    reset_best_ckpt: False          # if True, reset the tracking of the best checkpoint and scores. Use for domain adaptation or fine-tuning with new metrics or dev data.\n",
    "    reset_scheduler: False          # if True, overwrite scheduler in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    reset_optimizer: False          # if True, overwrite optimizer in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    random_seed: 42                 # set this seed to make training deterministic\n",
    "    optimizer: \"adam\"               # choices: \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", default is SGD\n",
    "    learning_rate: 0.0002          # initial learning rate, default: 3.0e-4 / 0.005\n",
    "    learning_rate_min: 0.0001       # stop learning when learning rate is reduced below this threshold, default: 1.0e-8\n",
    "    #learning_rate_factor: 1        # factor for Noam scheduler (used with Transformer)\n",
    "    #learning_rate_warmup: 4000     # warmup steps for Noam scheduler (used with Transformer)\n",
    "    clip_grad_val: 1.0              # clip the gradients to this value when they exceed it, optional\n",
    "    #clip_grad_norm: 1.0            # norm clipping instead of value clipping\n",
    "    weight_decay: 0.                # l2 regularization, default: 0\n",
    "    batch_size: 48                  # mini-batch size as number of sentences (when batch_type is \"sentence\"; default) or total number of tokens (when batch_type is \"token\")\n",
    "    batch_type: \"sentence\"          # create batches with sentences (\"sentence\", default) or tokens (\"token\")\n",
    "    eval_batch_size: 10            # mini-batch size for evaluation (see batch_size above)\n",
    "    eval_batch_type: \"sentence\"     # evaluation batch type (\"sentence\", default) or tokens (\"token\")\n",
    "    batch_multiplier: 1             # increase the effective batch size with values >1 to batch_multiplier*batch_size without increasing memory consumption by making updates only every batch_multiplier batches\n",
    "    scheduling: \"plateau\"           # learning rate scheduling, optional, if not specified stays constant, options: \"plateau\", \"exponential\", \"decaying\", \"noam\" (for Transformer), \"warmupexponentialdecay\"\n",
    "    patience: 600                     # specific to plateau scheduler: wait for this many validations without improvement before decreasing the learning rate\n",
    "    decrease_factor: 0.5            # specific to plateau & exponential scheduler: decrease the learning rate by this factor\n",
    "    epochs: 20                      # train for this many epochs\n",
    "    validation_freq: {val_freq}            # validate after this many updates (number of mini-batches), default: 1000\n",
    "    logging_freq: 1000               # log the training progress after this many updates, default: 100\n",
    "    eval_metric: \"bleu\"             # validation metric, default: \"bleu\", other options: \"chrf\", \"token_accuracy\", \"sequence_accuracy\"\n",
    "    early_stopping_metric: \"eval_metric\"   # when a new high score on this metric is achieved, a checkpoint is written, when \"eval_metric\" (default) is maximized, when \"loss\" or \"ppl\" is minimized\n",
    "    model_dir: {model_dir} # directory where models and validation results are stored, required\n",
    "    overwrite: True                 # overwrite existing model directory, default: False. Do not set to True unless for debugging!\n",
    "    shuffle: True                   # shuffle the training data, default: True\n",
    "    use_cuda: True                  # use CUDA for acceleration on GPU, required. Set to False when working on CPU.\n",
    "    max_output_length: 60           # maximum output length for decoding, default: None. If set to None, allow sentences of max 1.5*src length\n",
    "    print_valid_sents: []    # print this many validation sentences during each validation run, default: [0, 1, 2]\n",
    "    keep_last_ckpts: 3              # keep this many of the latest checkpoints, if -1: all of them, default: 5\n",
    "    label_smoothing: 0.0            # label smoothing: reference tokens will have 1-label_smoothing probability instead of 1, rest of probability mass is uniformly distributed over the rest of the vocabulary, default: 0.0 (off)\n",
    "\n",
    "pretraining:                           # specify training details here\n",
    "    reset_best_ckpt: False          # if True, reset the tracking of the best checkpoint and scores. Use for domain adaptation or fine-tuning with new metrics or dev data.\n",
    "    reset_scheduler: False          # if True, overwrite scheduler in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    reset_optimizer: False          # if True, overwrite optimizer in loaded checkpoint with parameters specified in this config. Use for domain adaptation or fine-tuning.\n",
    "    random_seed: 42                 # set this seed to make training deterministic\n",
    "    optimizer: \"adam\"               # choices: \"sgd\", \"adam\", \"adadelta\", \"adagrad\", \"rmsprop\", default is SGD\n",
    "    learning_rate: 0.0004           # initial learning rate, default: 3.0e-4 / 0.005\n",
    "    learning_rate_min: 0.00001       # stop learning when learning rate is reduced below this threshold, default: 1.0e-8\n",
    "    #learning_rate_factor: 1        # factor for Noam scheduler (used with Transformer)\n",
    "    #learning_rate_warmup: 4000     # warmup steps for Noam scheduler (used with Transformer)\n",
    "    clip_grad_val: 1.0              # clip the gradients to this value when they exceed it, optional\n",
    "    #clip_grad_norm: 1.0            # norm clipping instead of value clipping\n",
    "    weight_decay: 0.                # l2 regularization, default: 0\n",
    "    batch_size: 48                  # mini-batch size as number of sentences (when batch_type is \"sentence\"; default) or total number of tokens (when batch_type is \"token\")\n",
    "    batch_type: \"sentence\"          # create batches with sentences (\"sentence\", default) or tokens (\"token\")\n",
    "    eval_batch_size: 10            # mini-batch size for evaluation (see batch_size above)\n",
    "    eval_batch_type: \"sentence\"     # evaluation batch type (\"sentence\", default) or tokens (\"token\")\n",
    "    batch_multiplier: 1             # increase the effective batch size with values >1 to batch_multiplier*batch_size without increasing memory consumption by making updates only every batch_multiplier batches\n",
    "    scheduling: \"plateau\"           # learning rate scheduling, optional, if not specified stays constant, options: \"plateau\", \"exponential\", \"decaying\", \"noam\" (for Transformer), \"warmupexponentialdecay\"\n",
    "    patience: 600                     # specific to plateau scheduler: wait for this many validations without improvement before decreasing the learning rate\n",
    "    decrease_factor: 0.5            # specific to plateau & exponential scheduler: decrease the learning rate by this factor\n",
    "    epochs: 25                      # train for this many epochs\n",
    "    validation_freq: {val_freq}            # validate after this many updates (number of mini-batches), default: 1000\n",
    "    logging_freq: 1000               # log the training progress after this many updates, default: 100\n",
    "    eval_metric: \"bleu\"             # validation metric, default: \"bleu\", other options: \"chrf\", \"token_accuracy\", \"sequence_accuracy\"\n",
    "    early_stopping_metric: \"eval_metric\"   # when a new high score on this metric is achieved, a checkpoint is written, when \"eval_metric\" (default) is maximized, when \"loss\" or \"ppl\" is minimized\n",
    "    model_dir: {model_dir} # directory where models and validation results are stored, required\n",
    "    overwrite: True                 # overwrite existing model directory, default: False. Do not set to True unless for debugging!\n",
    "    shuffle: True                   # shuffle the training data, default: True\n",
    "    use_cuda: True                  # use CUDA for acceleration on GPU, required. Set to False when working on CPU.\n",
    "    max_output_length: 60           # maximum output length for decoding, default: None. If set to None, allow sentences of max 1.5*src length\n",
    "    print_valid_sents: []    # print this many validation sentences during each validation run, default: [0, 1, 2]\n",
    "    keep_last_ckpts: 3              # keep this many of the latest checkpoints, if -1: all of them, default: 5\n",
    "    label_smoothing: 0.0            # label smoothing: reference tokens will have 1-label_smoothing probability instead of 1, rest of probability mass is uniformly distributed over the rest of the vocabulary, default: 0.0 (off)\n",
    "\n",
    "model:                              # specify your model architecture here\n",
    "    initializer: \"xavier\"           # initializer for all trainable weights (xavier, zeros, normal, uniform)\n",
    "    init_weight: 0.01               # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    init_gain: 1.0                  # gain for Xavier initializer (default: 1.0)\n",
    "    bias_initializer: \"zeros\"       # initializer for bias terms (xavier, zeros, normal, uniform)\n",
    "    embed_initializer: \"normal\"     # initializer for embeddings (xavier, zeros, normal, uniform)\n",
    "    embed_init_weight: 0.1          # weight to initialize; for uniform, will use [-weight, weight]\n",
    "    embed_init_gain: 1.0            # gain for Xavier initializer for embeddings (default: 1.0)\n",
    "    init_rnn_orthogonal: False      # use orthogonal initialization for recurrent weights (default: False)\n",
    "    lstm_forget_gate: 1.            # initialize LSTM forget gate with this value (default: 1.)\n",
    "    tied_embeddings: False           # tie src and trg embeddings, only applicable if vocabularies are the same, default: False\n",
    "    tied_softmax: False             # tie trg embeddings and softmax (for Transformer; can be used together with tied_embeddings), default: False\n",
    "    encoder:\n",
    "        type: \"recurrent\"           # encoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"             # type of recurrent unit to use, either \"gru\" or \"lstm\", default: \"lstm\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}      # size of embeddings\n",
    "            scale: False            # scale the embeddings by sqrt of their size, default: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}            # size of RNN\n",
    "        bidirectional: True         # use a bi-directional encoder, default: True\n",
    "        dropout: 0.3                # apply dropout to the inputs to the RNN, default: 0.0\n",
    "        num_layers: 2               # stack this many layers of equal size, default: 1\n",
    "        freeze: False               # if True, encoder parameters are not updated during training (does not include embedding parameters)\n",
    "    decoder:\n",
    "        type: \"recurrent\"           # decoder type: \"recurrent\" for LSTM or GRU, or \"transformer\" for a Transformer\n",
    "        rnn_type: \"gru\"\n",
    "        embeddings:\n",
    "            embedding_dim: {emb_size}\n",
    "            scale: False\n",
    "            freeze: False           # if True, embeddings are not updated during training\n",
    "        hidden_size: {hidden_size}\n",
    "        dropout: 0.3\n",
    "        hidden_dropout: 0.2         # apply dropout to the attention vector, default: 0.0\n",
    "        num_layers: 2\n",
    "        input_feeding: True         # combine hidden state and attention vector before feeding to rnn, default: True\n",
    "        init_hidden: \"last\"         # initialized the decoder hidden state: use linear projection of last encoder state (\"bridge\") or simply the last state (\"last\") or zeros (\"zero\"), default: \"bridge\"\n",
    "        attention: \"bahdanau\"       # attention mechanism, choices: \"bahdanau\" (MLP attention), \"luong\" (bilinear attention), default: \"bahdanau\"\n",
    "        freeze: False               # if True, decoder parameters are not updated during training (does not include embedding parameters, but attention)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_file = \"joeynmt/configs/sample_{name}.yaml\".format(name=\"transfer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03-04 00:17:20,551 Hello! This is Joey-NMT.\n",
      "2020-03-04 00:17:21.314911: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-04 00:17:21.314978: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\n",
      "2020-03-04 00:17:21.314988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2020-03-04 00:17:21,968 Total params: 12477124\n",
      "2020-03-04 00:17:21,969 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-03-04 00:17:24,142 cfg.name                           : my_experiment\n",
      "2020-03-04 00:17:24,143 cfg.data.src                       : en\n",
      "2020-03-04 00:17:24,143 cfg.data.trg                       : shp\n",
      "2020-03-04 00:17:24,143 cfg.data.train                     : data/transfer/preprocessed/splits.en/en-shp/char/train\n",
      "2020-03-04 00:17:24,143 cfg.data.dev                       : data/transfer/preprocessed/splits.en/en-shp/char/valid\n",
      "2020-03-04 00:17:24,143 cfg.data.test                      : data/transfer/preprocessed/splits.en/en-shp/char/test\n",
      "2020-03-04 00:17:24,143 cfg.data.level                     : char\n",
      "2020-03-04 00:17:24,143 cfg.data.lowercase                 : True\n",
      "2020-03-04 00:17:24,143 cfg.data.max_sent_length           : 130\n",
      "2020-03-04 00:17:24,143 cfg.data.src_voc_min_freq          : 1\n",
      "2020-03-04 00:17:24,143 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-03-04 00:17:24,143 cfg.pretrained_data.src            : en\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.trg            : lt\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.train          : data/transfer/preprocessed/splits.en/en-lt/char/train\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.dev            : data/transfer/preprocessed/splits.en/en-lt/char/valid\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.test           : data/transfer/preprocessed/splits.en/en-lt/char/test\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.level          : char\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.lowercase      : True\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.max_sent_length : 150\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.src_voc_min_freq : 1\n",
      "2020-03-04 00:17:24,144 cfg.pretrained_data.trg_voc_min_freq : 1\n",
      "2020-03-04 00:17:24,144 cfg.testing.beam_size              : 5\n",
      "2020-03-04 00:17:24,144 cfg.testing.alpha                  : 1.0\n",
      "2020-03-04 00:17:24,144 cfg.training.reset_best_ckpt       : False\n",
      "2020-03-04 00:17:24,144 cfg.training.reset_scheduler       : False\n",
      "2020-03-04 00:17:24,145 cfg.training.reset_optimizer       : False\n",
      "2020-03-04 00:17:24,145 cfg.training.random_seed           : 42\n",
      "2020-03-04 00:17:24,145 cfg.training.optimizer             : adam\n",
      "2020-03-04 00:17:24,145 cfg.training.learning_rate         : 0.0002\n",
      "2020-03-04 00:17:24,145 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-03-04 00:17:24,145 cfg.training.clip_grad_val         : 1.0\n",
      "2020-03-04 00:17:24,145 cfg.training.weight_decay          : 0.0\n",
      "2020-03-04 00:17:24,145 cfg.training.batch_size            : 48\n",
      "2020-03-04 00:17:24,145 cfg.training.batch_type            : sentence\n",
      "2020-03-04 00:17:24,145 cfg.training.eval_batch_size       : 10\n",
      "2020-03-04 00:17:24,145 cfg.training.eval_batch_type       : sentence\n",
      "2020-03-04 00:17:24,145 cfg.training.batch_multiplier      : 1\n",
      "2020-03-04 00:17:24,145 cfg.training.scheduling            : plateau\n",
      "2020-03-04 00:17:24,145 cfg.training.patience              : 600\n",
      "2020-03-04 00:17:24,146 cfg.training.decrease_factor       : 0.5\n",
      "2020-03-04 00:17:24,146 cfg.training.epochs                : 20\n",
      "2020-03-04 00:17:24,146 cfg.training.validation_freq       : 10\n",
      "2020-03-04 00:17:24,146 cfg.training.logging_freq          : 1000\n",
      "2020-03-04 00:17:24,146 cfg.training.eval_metric           : bleu\n",
      "2020-03-04 00:17:24,146 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:17:24,146 cfg.training.model_dir             : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:17:24,146 cfg.training.overwrite             : True\n",
      "2020-03-04 00:17:24,146 cfg.training.shuffle               : True\n",
      "2020-03-04 00:17:24,146 cfg.training.use_cuda              : True\n",
      "2020-03-04 00:17:24,146 cfg.training.max_output_length     : 60\n",
      "2020-03-04 00:17:24,146 cfg.training.print_valid_sents     : []\n",
      "2020-03-04 00:17:24,146 cfg.training.keep_last_ckpts       : 3\n",
      "2020-03-04 00:17:24,146 cfg.training.label_smoothing       : 0.0\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.reset_best_ckpt    : False\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.reset_scheduler    : False\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.reset_optimizer    : False\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.random_seed        : 42\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.optimizer          : adam\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.learning_rate      : 0.0004\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.learning_rate_min  : 1e-05\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.clip_grad_val      : 1.0\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.weight_decay       : 0.0\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.batch_size         : 48\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.batch_type         : sentence\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.eval_batch_size    : 10\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.eval_batch_type    : sentence\n",
      "2020-03-04 00:17:24,147 cfg.pretraining.batch_multiplier   : 1\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.scheduling         : plateau\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.patience           : 600\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.decrease_factor    : 0.5\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.epochs             : 25\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.validation_freq    : 10\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.logging_freq       : 1000\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.eval_metric        : bleu\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.model_dir          : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.overwrite          : True\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.shuffle            : True\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.use_cuda           : True\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.max_output_length  : 60\n",
      "2020-03-04 00:17:24,148 cfg.pretraining.print_valid_sents  : []\n",
      "2020-03-04 00:17:24,149 cfg.pretraining.keep_last_ckpts    : 3\n",
      "2020-03-04 00:17:24,149 cfg.pretraining.label_smoothing    : 0.0\n",
      "2020-03-04 00:17:24,149 cfg.model.initializer              : xavier\n",
      "2020-03-04 00:17:24,149 cfg.model.init_weight              : 0.01\n",
      "2020-03-04 00:17:24,149 cfg.model.init_gain                : 1.0\n",
      "2020-03-04 00:17:24,149 cfg.model.bias_initializer         : zeros\n",
      "2020-03-04 00:17:24,149 cfg.model.embed_initializer        : normal\n",
      "2020-03-04 00:17:24,149 cfg.model.embed_init_weight        : 0.1\n",
      "2020-03-04 00:17:24,149 cfg.model.embed_init_gain          : 1.0\n",
      "2020-03-04 00:17:24,149 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-03-04 00:17:24,149 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-03-04 00:17:24,149 cfg.model.tied_embeddings          : False\n",
      "2020-03-04 00:17:24,149 cfg.model.tied_softmax             : False\n",
      "2020-03-04 00:17:24,149 cfg.model.encoder.type             : recurrent\n",
      "2020-03-04 00:17:24,149 cfg.model.encoder.rnn_type         : gru\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.embeddings.scale : False\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.hidden_size      : 512\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.bidirectional    : True\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.dropout          : 0.3\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.num_layers       : 2\n",
      "2020-03-04 00:17:24,150 cfg.model.encoder.freeze           : False\n",
      "2020-03-04 00:17:24,150 cfg.model.decoder.type             : recurrent\n",
      "2020-03-04 00:17:24,150 cfg.model.decoder.rnn_type         : gru\n",
      "2020-03-04 00:17:24,150 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:17:24,150 cfg.model.decoder.embeddings.scale : False\n",
      "2020-03-04 00:17:24,150 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.hidden_size      : 512\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.dropout          : 0.3\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.num_layers       : 2\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.input_feeding    : True\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.init_hidden      : last\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.attention        : bahdanau\n",
      "2020-03-04 00:17:24,151 cfg.model.decoder.freeze           : False\n",
      "2020-03-04 00:17:24,151 Data set sizes: \n",
      "\ttrain 4996,\n",
      "\tvalid 407,\n",
      "\ttest 407\n",
      "2020-03-04 00:17:24,151 First training example:\n",
      "\t[SRC] @@ \" @@ d o @@ y o u @@ l i k e @@ t o @@ t r a v e l @@ ? @@ \" @@ \" @@ y e s @@ . @@ \"\n",
      "\t[TRG] @@ \" @@ a r @@ m ė g s t i @@ k e l i a u t i @@ ? @@ \" @@ \" @@ t a i p @@ . @@ \"\n",
      "2020-03-04 00:17:24,151 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) t (7) o (8) a (9) i\n",
      "2020-03-04 00:17:24,152 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) a (6) i (7) s (8) t (9) u\n",
      "2020-03-04 00:17:24,152 Number of Src words (types): 55\n",
      "2020-03-04 00:17:24,152 Number of Trg words (types): 60\n",
      "2020-03-04 00:17:24,152 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=55),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=60))\n",
      "2020-03-04 00:17:24,152 EPOCH 1\n",
      "2020-03-04 00:17:31,795 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:17:31,795 Saving new checkpoint.\n",
      "2020-03-04 00:17:31,955 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 30304.0801, ppl:  20.4757, duration: 6.1238s\n",
      "2020-03-04 00:17:38,215 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 29477.6094, ppl:  18.8572, duration: 4.5456s\n",
      "2020-03-04 00:17:44,600 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 30338.6055, ppl:  20.5462, duration: 4.6396s\n",
      "2020-03-04 00:17:50,712 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 28709.0488, ppl:  17.4671, duration: 4.7730s\n",
      "2020-03-04 00:17:57,494 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 27603.6699, ppl:  15.6456, duration: 5.1525s\n",
      "2020-03-04 00:18:01,612 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 25788.8145, ppl:  13.0577, duration: 2.5073s\n",
      "2020-03-04 00:18:05,731 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 25036.5156, ppl:  12.1147, duration: 2.9692s\n",
      "2020-03-04 00:18:10,283 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 23945.9297, ppl:  10.8674, duration: 2.8332s\n",
      "2020-03-04 00:18:15,104 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 23254.7930, ppl:  10.1442, duration: 3.3431s\n",
      "2020-03-04 00:18:19,835 Validation result (greedy) at epoch   1, step      100: bleu:   0.00, loss: 22646.5605, ppl:   9.5478, duration: 3.1089s\n",
      "2020-03-04 00:18:20,632 Epoch   1: total training loss 9991.51\n",
      "2020-03-04 00:18:20,632 EPOCH 2\n",
      "2020-03-04 00:18:24,795 Validation result (greedy) at epoch   2, step      110: bleu:   0.00, loss: 22330.5254, ppl:   9.2518, duration: 3.4746s\n",
      "2020-03-04 00:18:30,492 Validation result (greedy) at epoch   2, step      120: bleu:   0.00, loss: 21914.2793, ppl:   8.8760, duration: 3.6474s\n",
      "2020-03-04 00:18:34,937 Validation result (greedy) at epoch   2, step      130: bleu:   0.00, loss: 21481.6621, ppl:   8.5015, duration: 3.0332s\n",
      "2020-03-04 00:18:39,927 Validation result (greedy) at epoch   2, step      140: bleu:   0.00, loss: 21142.7344, ppl:   8.2193, duration: 3.4235s\n",
      "2020-03-04 00:18:45,394 Validation result (greedy) at epoch   2, step      150: bleu:   0.00, loss: 20895.2988, ppl:   8.0191, duration: 3.8702s\n",
      "2020-03-04 00:18:49,897 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 20648.1426, ppl:   7.8241, duration: 3.2252s\n",
      "2020-03-04 00:18:54,473 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 20337.3027, ppl:   7.5855, duration: 3.1522s\n",
      "2020-03-04 00:18:59,241 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 20129.4375, ppl:   7.4300, duration: 3.1583s\n",
      "2020-03-04 00:19:05,826 Validation result (greedy) at epoch   2, step      190: bleu:   0.00, loss: 20020.9980, ppl:   7.3501, duration: 4.9197s\n",
      "2020-03-04 00:19:10,425 Validation result (greedy) at epoch   2, step      200: bleu:   0.00, loss: 19632.7891, ppl:   7.0713, duration: 3.2795s\n",
      "2020-03-04 00:19:16,223 Validation result (greedy) at epoch   2, step      210: bleu:   0.00, loss: 20198.8945, ppl:   7.4816, duration: 4.0818s\n",
      "2020-03-04 00:19:16,224 Epoch   2: total training loss 7809.48\n",
      "2020-03-04 00:19:16,224 EPOCH 3\n",
      "2020-03-04 00:19:22,626 Validation result (greedy) at epoch   3, step      220: bleu:   0.00, loss: 19805.4180, ppl:   7.1940, duration: 4.4343s\n",
      "2020-03-04 00:19:28,194 Validation result (greedy) at epoch   3, step      230: bleu:   0.00, loss: 19322.5664, ppl:   6.8561, duration: 3.8388s\n",
      "2020-03-04 00:19:33,273 Validation result (greedy) at epoch   3, step      240: bleu:   0.00, loss: 18926.9961, ppl:   6.5911, duration: 3.4467s\n",
      "2020-03-04 00:19:38,032 Validation result (greedy) at epoch   3, step      250: bleu:   0.00, loss: 18666.5938, ppl:   6.4223, duration: 3.5715s\n",
      "2020-03-04 00:19:43,204 Validation result (greedy) at epoch   3, step      260: bleu:   0.00, loss: 18507.2539, ppl:   6.3212, duration: 3.3968s\n",
      "2020-03-04 00:19:48,574 Validation result (greedy) at epoch   3, step      270: bleu:   0.00, loss: 18221.4844, ppl:   6.1437, duration: 3.8771s\n",
      "2020-03-04 00:19:54,032 Validation result (greedy) at epoch   3, step      280: bleu:   0.00, loss: 18075.4316, ppl:   6.0550, duration: 3.4902s\n",
      "2020-03-04 00:19:59,689 Validation result (greedy) at epoch   3, step      290: bleu:   0.00, loss: 17870.0059, ppl:   5.9323, duration: 4.1766s\n",
      "2020-03-04 00:20:05,446 Validation result (greedy) at epoch   3, step      300: bleu:   0.00, loss: 17875.6719, ppl:   5.9357, duration: 4.0584s\n",
      "2020-03-04 00:20:11,020 Validation result (greedy) at epoch   3, step      310: bleu:   0.00, loss: 17604.3926, ppl:   5.7774, duration: 3.9599s\n",
      "2020-03-04 00:20:12,049 Epoch   3: total training loss 7050.79\n",
      "2020-03-04 00:20:12,050 EPOCH 4\n",
      "2020-03-04 00:20:15,907 Validation result (greedy) at epoch   4, step      320: bleu:   0.00, loss: 17668.6113, ppl:   5.8145, duration: 3.0645s\n",
      "2020-03-04 00:20:20,077 Validation result (greedy) at epoch   4, step      330: bleu:   0.00, loss: 17531.9414, ppl:   5.7358, duration: 2.9377s\n",
      "2020-03-04 00:20:26,272 Validation result (greedy) at epoch   4, step      340: bleu:   0.00, loss: 17222.2441, ppl:   5.5615, duration: 4.1989s\n",
      "2020-03-04 00:20:31,538 Validation result (greedy) at epoch   4, step      350: bleu:   0.00, loss: 17035.9062, ppl:   5.4592, duration: 3.8118s\n",
      "2020-03-04 00:20:36,956 Validation result (greedy) at epoch   4, step      360: bleu:   0.00, loss: 16883.8379, ppl:   5.3772, duration: 3.9711s\n",
      "2020-03-04 00:20:43,127 Validation result (greedy) at epoch   4, step      370: bleu:   0.00, loss: 16697.5938, ppl:   5.2783, duration: 4.6040s\n",
      "2020-03-04 00:20:48,357 Validation result (greedy) at epoch   4, step      380: bleu:   0.00, loss: 16655.6680, ppl:   5.2563, duration: 3.8257s\n",
      "2020-03-04 00:20:53,554 Validation result (greedy) at epoch   4, step      390: bleu:   0.00, loss: 16335.2354, ppl:   5.0911, duration: 3.8262s\n",
      "2020-03-04 00:20:58,896 Validation result (greedy) at epoch   4, step      400: bleu:   0.00, loss: 16255.2520, ppl:   5.0507, duration: 3.9179s\n",
      "2020-03-04 00:21:04,164 Validation result (greedy) at epoch   4, step      410: bleu:   0.00, loss: 16067.0361, ppl:   4.9569, duration: 3.8100s\n",
      "2020-03-04 00:21:10,262 Validation result (greedy) at epoch   4, step      420: bleu:   0.00, loss: 16599.0488, ppl:   5.2267, duration: 4.5983s\n",
      "2020-03-04 00:21:10,263 Epoch   4: total training loss 6445.65\n",
      "2020-03-04 00:21:10,263 EPOCH 5\n",
      "2020-03-04 00:21:16,097 Validation result (greedy) at epoch   5, step      430: bleu:   0.00, loss: 16057.5576, ppl:   4.9522, duration: 4.3700s\n",
      "2020-03-04 00:21:22,350 Validation result (greedy) at epoch   5, step      440: bleu:   0.00, loss: 15780.8818, ppl:   4.8176, duration: 4.5256s\n",
      "2020-03-04 00:21:28,043 Validation result (greedy) at epoch   5, step      450: bleu:   0.00, loss: 15598.4883, ppl:   4.7308, duration: 4.2259s\n",
      "2020-03-04 00:21:33,057 Validation result (greedy) at epoch   5, step      460: bleu:   0.00, loss: 15445.4785, ppl:   4.6592, duration: 3.4914s\n",
      "2020-03-04 00:21:39,361 Validation result (greedy) at epoch   5, step      470: bleu:   0.00, loss: 15387.9141, ppl:   4.6326, duration: 4.7897s\n",
      "2020-03-04 00:21:45,083 Validation result (greedy) at epoch   5, step      480: bleu:   0.00, loss: 15249.8076, ppl:   4.5693, duration: 4.1287s\n",
      "2020-03-04 00:21:50,478 Validation result (greedy) at epoch   5, step      490: bleu:   0.00, loss: 15100.6133, ppl:   4.5019, duration: 4.0201s\n",
      "2020-03-04 00:21:56,255 Validation result (greedy) at epoch   5, step      500: bleu:   0.00, loss: 15283.9990, ppl:   4.5849, duration: 3.9715s\n",
      "2020-03-04 00:22:02,844 Validation result (greedy) at epoch   5, step      510: bleu:   0.00, loss: 15619.0791, ppl:   4.7405, duration: 5.3062s\n",
      "2020-03-04 00:22:08,078 Validation result (greedy) at epoch   5, step      520: bleu:   0.00, loss: 14873.8477, ppl:   4.4013, duration: 3.8137s\n",
      "2020-03-04 00:22:08,978 Epoch   5: total training loss 5935.04\n",
      "2020-03-04 00:22:08,978 EPOCH 6\n",
      "2020-03-04 00:22:13,822 Validation result (greedy) at epoch   6, step      530: bleu:   0.00, loss: 14882.3643, ppl:   4.4050, duration: 4.1190s\n",
      "2020-03-04 00:22:19,538 Validation result (greedy) at epoch   6, step      540: bleu:   0.00, loss: 14746.0078, ppl:   4.3456, duration: 4.1145s\n",
      "2020-03-04 00:22:25,582 Validation result (greedy) at epoch   6, step      550: bleu:   0.00, loss: 14846.6582, ppl:   4.3894, duration: 4.7623s\n",
      "2020-03-04 00:22:31,506 Validation result (greedy) at epoch   6, step      560: bleu:   0.00, loss: 14388.1445, ppl:   4.1934, duration: 4.0729s\n",
      "2020-03-04 00:22:36,514 Validation result (greedy) at epoch   6, step      570: bleu:   0.00, loss: 14191.2129, ppl:   4.1119, duration: 3.6791s\n",
      "2020-03-04 00:22:42,049 Validation result (greedy) at epoch   6, step      580: bleu:   0.00, loss: 14077.0908, ppl:   4.0654, duration: 4.2548s\n",
      "2020-03-04 00:22:47,329 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:22:47,329 Saving new checkpoint.\n",
      "2020-03-04 00:22:47,473 Validation result (greedy) at epoch   6, step      590: bleu:   1.58, loss: 13921.4531, ppl:   4.0029, duration: 4.0114s\n",
      "2020-03-04 00:22:52,414 Validation result (greedy) at epoch   6, step      600: bleu:   0.00, loss: 13839.7969, ppl:   3.9704, duration: 3.3601s\n",
      "2020-03-04 00:22:58,166 Validation result (greedy) at epoch   6, step      610: bleu:   0.00, loss: 13722.1729, ppl:   3.9242, duration: 3.7521s\n",
      "2020-03-04 00:23:03,839 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:23:03,839 Saving new checkpoint.\n",
      "2020-03-04 00:23:03,984 Validation result (greedy) at epoch   6, step      620: bleu:   1.83, loss: 13608.3711, ppl:   3.8799, duration: 4.3390s\n",
      "2020-03-04 00:23:10,115 Validation result (greedy) at epoch   6, step      630: bleu:   0.00, loss: 13924.7822, ppl:   4.0042, duration: 4.5908s\n",
      "2020-03-04 00:23:10,116 Epoch   6: total training loss 5464.81\n",
      "2020-03-04 00:23:10,116 EPOCH 7\n",
      "2020-03-04 00:23:15,462 Validation result (greedy) at epoch   7, step      640: bleu:   0.00, loss: 13694.3271, ppl:   3.9133, duration: 4.1124s\n",
      "2020-03-04 00:23:20,477 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:23:20,477 Saving new checkpoint.\n",
      "2020-03-04 00:23:20,612 Validation result (greedy) at epoch   7, step      650: bleu:   2.29, loss: 13489.8281, ppl:   3.8344, duration: 3.7460s\n",
      "2020-03-04 00:23:25,864 Validation result (greedy) at epoch   7, step      660: bleu:   2.07, loss: 13315.4131, ppl:   3.7683, duration: 3.8030s\n",
      "2020-03-04 00:23:31,306 Validation result (greedy) at epoch   7, step      670: bleu:   1.79, loss: 13256.8027, ppl:   3.7464, duration: 3.8975s\n",
      "2020-03-04 00:23:36,777 Validation result (greedy) at epoch   7, step      680: bleu:   2.26, loss: 13262.8262, ppl:   3.7486, duration: 3.8370s\n",
      "2020-03-04 00:23:41,976 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:23:41,977 Saving new checkpoint.\n",
      "2020-03-04 00:23:42,126 Validation result (greedy) at epoch   7, step      690: bleu:   2.69, loss: 13063.2100, ppl:   3.6748, duration: 4.0136s\n",
      "2020-03-04 00:23:47,615 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:23:47,616 Saving new checkpoint.\n",
      "2020-03-04 00:23:47,763 Validation result (greedy) at epoch   7, step      700: bleu:   2.81, loss: 12856.9307, ppl:   3.6001, duration: 3.7820s\n",
      "2020-03-04 00:23:53,454 Validation result (greedy) at epoch   7, step      710: bleu:   2.71, loss: 12812.1475, ppl:   3.5840, duration: 3.9024s\n",
      "2020-03-04 00:23:59,017 Validation result (greedy) at epoch   7, step      720: bleu:   1.75, loss: 12819.7402, ppl:   3.5868, duration: 3.9132s\n",
      "2020-03-04 00:24:04,504 Validation result (greedy) at epoch   7, step      730: bleu:   2.06, loss: 12539.3291, ppl:   3.4879, duration: 3.8040s\n",
      "2020-03-04 00:24:05,393 Epoch   7: total training loss 5070.36\n",
      "2020-03-04 00:24:05,393 EPOCH 8\n",
      "2020-03-04 00:24:10,382 Validation result (greedy) at epoch   8, step      740: bleu:   0.00, loss: 13525.2734, ppl:   3.8480, duration: 4.2198s\n",
      "2020-03-04 00:24:15,421 Validation result (greedy) at epoch   8, step      750: bleu:   0.00, loss: 13033.9854, ppl:   3.6641, duration: 3.7374s\n",
      "2020-03-04 00:24:21,143 Validation result (greedy) at epoch   8, step      760: bleu:   1.68, loss: 12872.1562, ppl:   3.6055, duration: 4.1774s\n",
      "2020-03-04 00:24:27,244 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:24:27,244 Saving new checkpoint.\n",
      "2020-03-04 00:24:27,383 Validation result (greedy) at epoch   8, step      770: bleu:   3.27, loss: 12521.6074, ppl:   3.4818, duration: 4.4746s\n",
      "2020-03-04 00:24:32,437 Validation result (greedy) at epoch   8, step      780: bleu:   3.15, loss: 12323.7861, ppl:   3.4138, duration: 3.6398s\n",
      "2020-03-04 00:24:37,878 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:24:37,878 Saving new checkpoint.\n",
      "2020-03-04 00:24:38,009 Validation result (greedy) at epoch   8, step      790: bleu:   3.84, loss: 12148.7783, ppl:   3.3548, duration: 4.1964s\n",
      "2020-03-04 00:24:43,811 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:24:43,811 Saving new checkpoint.\n",
      "2020-03-04 00:24:43,950 Validation result (greedy) at epoch   8, step      800: bleu:   3.99, loss: 12127.8701, ppl:   3.3478, duration: 4.5039s\n",
      "2020-03-04 00:24:49,387 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:24:49,387 Saving new checkpoint.\n",
      "2020-03-04 00:24:49,548 Validation result (greedy) at epoch   8, step      810: bleu:   4.19, loss: 11903.9229, ppl:   3.2740, duration: 3.9149s\n",
      "2020-03-04 00:24:55,583 Validation result (greedy) at epoch   8, step      820: bleu:   3.50, loss: 11850.2148, ppl:   3.2565, duration: 4.4408s\n",
      "2020-03-04 00:25:01,497 Validation result (greedy) at epoch   8, step      830: bleu:   3.68, loss: 11861.3545, ppl:   3.2601, duration: 4.1864s\n",
      "2020-03-04 00:25:07,765 Validation result (greedy) at epoch   8, step      840: bleu:   3.93, loss: 11758.3936, ppl:   3.2268, duration: 4.4443s\n",
      "2020-03-04 00:25:07,766 Epoch   8: total training loss 4706.95\n",
      "2020-03-04 00:25:07,766 EPOCH 9\n",
      "2020-03-04 00:25:14,112 Validation result (greedy) at epoch   9, step      850: bleu:   3.13, loss: 12058.9453, ppl:   3.3249, duration: 4.7699s\n",
      "2020-03-04 00:25:20,026 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:25:20,026 Saving new checkpoint.\n",
      "2020-03-04 00:25:20,165 Validation result (greedy) at epoch   9, step      860: bleu:   4.49, loss: 11691.8975, ppl:   3.2055, duration: 4.2494s\n",
      "2020-03-04 00:25:25,934 Validation result (greedy) at epoch   9, step      870: bleu:   3.37, loss: 12039.0020, ppl:   3.3183, duration: 4.2202s\n",
      "2020-03-04 00:25:31,183 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:25:31,184 Saving new checkpoint.\n",
      "2020-03-04 00:25:31,316 Validation result (greedy) at epoch   9, step      880: bleu:   5.31, loss: 11381.8857, ppl:   3.1080, duration: 3.5326s\n",
      "2020-03-04 00:25:36,016 Validation result (greedy) at epoch   9, step      890: bleu:   4.67, loss: 11425.0977, ppl:   3.1215, duration: 3.5713s\n",
      "2020-03-04 00:25:41,725 Validation result (greedy) at epoch   9, step      900: bleu:   3.25, loss: 11406.3184, ppl:   3.1156, duration: 4.0726s\n",
      "2020-03-04 00:25:46,760 Validation result (greedy) at epoch   9, step      910: bleu:   4.72, loss: 11278.1553, ppl:   3.0761, duration: 3.6916s\n",
      "2020-03-04 00:25:51,776 Validation result (greedy) at epoch   9, step      920: bleu:   4.70, loss: 11116.5049, ppl:   3.0269, duration: 3.7251s\n",
      "2020-03-04 00:25:57,429 Validation result (greedy) at epoch   9, step      930: bleu:   4.04, loss: 11053.1367, ppl:   3.0079, duration: 3.8170s\n",
      "2020-03-04 00:26:02,749 Validation result (greedy) at epoch   9, step      940: bleu:   5.30, loss: 10853.9277, ppl:   2.9488, duration: 3.8377s\n",
      "2020-03-04 00:26:03,683 Epoch   9: total training loss 4339.13\n",
      "2020-03-04 00:26:03,684 EPOCH 10\n",
      "2020-03-04 00:26:08,179 Validation result (greedy) at epoch  10, step      950: bleu:   4.42, loss: 11399.2998, ppl:   3.1134, duration: 3.8796s\n",
      "2020-03-04 00:26:14,044 Validation result (greedy) at epoch  10, step      960: bleu:   4.80, loss: 11019.7246, ppl:   2.9979, duration: 4.4167s\n",
      "2020-03-04 00:26:19,455 Validation result (greedy) at epoch  10, step      970: bleu:   5.24, loss: 10889.1865, ppl:   2.9592, duration: 3.8581s\n",
      "2020-03-04 00:26:25,113 Validation result (greedy) at epoch  10, step      980: bleu:   4.45, loss: 10882.2197, ppl:   2.9571, duration: 3.8839s\n",
      "2020-03-04 00:26:30,833 Validation result (greedy) at epoch  10, step      990: bleu:   5.08, loss: 10713.2373, ppl:   2.9077, duration: 4.4147s\n",
      "2020-03-04 00:26:32,288 Epoch  10 Step:     1000 Batch Loss:    31.102268 Tokens per Sec:    10834, Lr: 0.000400\n",
      "2020-03-04 00:26:36,045 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:26:36,045 Saving new checkpoint.\n",
      "2020-03-04 00:26:36,217 Validation result (greedy) at epoch  10, step     1000: bleu:   5.91, loss: 10537.5918, ppl:   2.8573, duration: 3.9291s\n",
      "2020-03-04 00:26:41,700 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:26:41,700 Saving new checkpoint.\n",
      "2020-03-04 00:26:41,854 Validation result (greedy) at epoch  10, step     1010: bleu:   7.28, loss: 10506.6465, ppl:   2.8485, duration: 4.1286s\n",
      "2020-03-04 00:26:48,168 Validation result (greedy) at epoch  10, step     1020: bleu:   6.25, loss: 10580.6543, ppl:   2.8696, duration: 4.7136s\n",
      "2020-03-04 00:26:53,235 Validation result (greedy) at epoch  10, step     1030: bleu:   6.36, loss: 10425.1484, ppl:   2.8255, duration: 3.6497s\n",
      "2020-03-04 00:26:58,377 Validation result (greedy) at epoch  10, step     1040: bleu:   6.45, loss: 10461.4297, ppl:   2.8357, duration: 3.7234s\n",
      "2020-03-04 00:27:04,351 Validation result (greedy) at epoch  10, step     1050: bleu:   4.60, loss: 10868.6436, ppl:   2.9531, duration: 4.1704s\n",
      "2020-03-04 00:27:04,351 Epoch  10: total training loss 3984.34\n",
      "2020-03-04 00:27:04,352 EPOCH 11\n",
      "2020-03-04 00:27:09,824 Validation result (greedy) at epoch  11, step     1060: bleu:   5.28, loss: 10573.0928, ppl:   2.8674, duration: 3.8681s\n",
      "2020-03-04 00:27:15,153 Validation result (greedy) at epoch  11, step     1070: bleu:   7.00, loss: 10336.8525, ppl:   2.8007, duration: 4.1347s\n",
      "2020-03-04 00:27:21,066 Validation result (greedy) at epoch  11, step     1080: bleu:   6.66, loss: 10341.6016, ppl:   2.8020, duration: 4.2887s\n",
      "2020-03-04 00:27:27,205 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:27:27,205 Saving new checkpoint.\n",
      "2020-03-04 00:27:27,392 Validation result (greedy) at epoch  11, step     1090: bleu:   7.47, loss: 10167.1338, ppl:   2.7538, duration: 4.6659s\n",
      "2020-03-04 00:27:32,712 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:27:32,713 Saving new checkpoint.\n",
      "2020-03-04 00:27:32,854 Validation result (greedy) at epoch  11, step     1100: bleu:   7.92, loss: 10040.7080, ppl:   2.7193, duration: 3.6882s\n",
      "2020-03-04 00:27:37,904 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:27:37,905 Saving new checkpoint.\n",
      "2020-03-04 00:27:38,054 Validation result (greedy) at epoch  11, step     1110: bleu:   8.48, loss: 9948.1875, ppl:   2.6943, duration: 3.8676s\n",
      "2020-03-04 00:27:42,989 Validation result (greedy) at epoch  11, step     1120: bleu:   8.11, loss: 9935.9062, ppl:   2.6910, duration: 3.3745s\n",
      "2020-03-04 00:27:48,642 Validation result (greedy) at epoch  11, step     1130: bleu:   7.15, loss: 9880.3643, ppl:   2.6762, duration: 3.6148s\n",
      "2020-03-04 00:27:53,802 Validation result (greedy) at epoch  11, step     1140: bleu:   7.86, loss: 9898.3613, ppl:   2.6810, duration: 3.7232s\n",
      "2020-03-04 00:27:59,758 Validation result (greedy) at epoch  11, step     1150: bleu:   6.56, loss: 10047.7812, ppl:   2.7212, duration: 4.5634s\n",
      "2020-03-04 00:28:00,782 Epoch  11: total training loss 3646.19\n",
      "2020-03-04 00:28:00,783 EPOCH 12\n",
      "2020-03-04 00:28:06,040 Validation result (greedy) at epoch  12, step     1160: bleu:   6.54, loss: 10559.6787, ppl:   2.8636, duration: 4.4400s\n",
      "2020-03-04 00:28:11,316 Validation result (greedy) at epoch  12, step     1170: bleu:   7.86, loss: 10131.6641, ppl:   2.7440, duration: 3.8123s\n",
      "2020-03-04 00:28:17,129 Validation result (greedy) at epoch  12, step     1180: bleu:   6.63, loss: 9934.4727, ppl:   2.6907, duration: 4.0508s\n",
      "2020-03-04 00:28:23,066 Validation result (greedy) at epoch  12, step     1190: bleu:   7.60, loss: 9941.4551, ppl:   2.6925, duration: 4.2705s\n",
      "2020-03-04 00:28:28,272 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:28:28,273 Saving new checkpoint.\n",
      "2020-03-04 00:28:28,413 Validation result (greedy) at epoch  12, step     1200: bleu:   8.70, loss: 9806.1699, ppl:   2.6565, duration: 3.6392s\n",
      "2020-03-04 00:28:34,239 Validation result (greedy) at epoch  12, step     1210: bleu:   8.41, loss: 9669.0518, ppl:   2.6204, duration: 4.4802s\n",
      "2020-03-04 00:28:39,910 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:28:39,910 Saving new checkpoint.\n",
      "2020-03-04 00:28:40,094 Validation result (greedy) at epoch  12, step     1220: bleu:   8.77, loss: 9508.3252, ppl:   2.5788, duration: 4.4688s\n",
      "2020-03-04 00:28:46,136 Validation result (greedy) at epoch  12, step     1230: bleu:   7.86, loss: 9497.1201, ppl:   2.5759, duration: 4.5649s\n",
      "2020-03-04 00:28:51,850 Validation result (greedy) at epoch  12, step     1240: bleu:   8.10, loss: 9505.2988, ppl:   2.5780, duration: 4.1806s\n",
      "2020-03-04 00:28:57,630 Validation result (greedy) at epoch  12, step     1250: bleu:   8.39, loss: 9365.5996, ppl:   2.5424, duration: 4.1674s\n",
      "2020-03-04 00:29:02,594 Validation result (greedy) at epoch  12, step     1260: bleu:   8.30, loss: 9511.2754, ppl:   2.5796, duration: 3.3800s\n",
      "2020-03-04 00:29:02,594 Epoch  12: total training loss 3396.30\n",
      "2020-03-04 00:29:02,595 EPOCH 13\n",
      "2020-03-04 00:29:08,426 Validation result (greedy) at epoch  13, step     1270: bleu:   7.51, loss: 9749.8555, ppl:   2.6416, duration: 4.0432s\n",
      "2020-03-04 00:29:13,831 Validation result (greedy) at epoch  13, step     1280: bleu:   8.33, loss: 9543.4209, ppl:   2.5878, duration: 3.9316s\n",
      "2020-03-04 00:29:19,952 Validation result (greedy) at epoch  13, step     1290: bleu:   6.86, loss: 9836.1846, ppl:   2.6644, duration: 4.2680s\n",
      "2020-03-04 00:29:25,908 Validation result (greedy) at epoch  13, step     1300: bleu:   7.97, loss: 9446.0557, ppl:   2.5629, duration: 4.4661s\n",
      "2020-03-04 00:29:31,095 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:29:31,095 Saving new checkpoint.\n",
      "2020-03-04 00:29:31,246 Validation result (greedy) at epoch  13, step     1310: bleu:   9.09, loss: 9297.0195, ppl:   2.5251, duration: 4.0155s\n",
      "2020-03-04 00:29:36,581 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:29:36,581 Saving new checkpoint.\n",
      "2020-03-04 00:29:36,725 Validation result (greedy) at epoch  13, step     1320: bleu:  10.74, loss: 9205.1377, ppl:   2.5021, duration: 3.9186s\n",
      "2020-03-04 00:29:43,849 Validation result (greedy) at epoch  13, step     1330: bleu:   9.78, loss: 9380.2539, ppl:   2.5461, duration: 5.1908s\n",
      "2020-03-04 00:29:49,550 Validation result (greedy) at epoch  13, step     1340: bleu:   8.99, loss: 9190.4297, ppl:   2.4984, duration: 4.2337s\n",
      "2020-03-04 00:29:54,738 Validation result (greedy) at epoch  13, step     1350: bleu:   8.12, loss: 9399.9570, ppl:   2.5511, duration: 3.8634s\n",
      "2020-03-04 00:30:00,415 Validation result (greedy) at epoch  13, step     1360: bleu:   9.00, loss: 9410.6650, ppl:   2.5538, duration: 4.1114s\n",
      "2020-03-04 00:30:01,430 Epoch  13: total training loss 3077.07\n",
      "2020-03-04 00:30:01,431 EPOCH 14\n",
      "2020-03-04 00:30:06,656 Validation result (greedy) at epoch  14, step     1370: bleu:   7.86, loss: 9546.6758, ppl:   2.5887, duration: 4.5305s\n",
      "2020-03-04 00:30:12,152 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:12,152 Saving new checkpoint.\n",
      "2020-03-04 00:30:12,375 Validation result (greedy) at epoch  14, step     1380: bleu:  10.89, loss: 9206.9297, ppl:   2.5025, duration: 4.0739s\n",
      "2020-03-04 00:30:18,019 Validation result (greedy) at epoch  14, step     1390: bleu:  10.46, loss: 9110.0117, ppl:   2.4785, duration: 4.4013s\n",
      "2020-03-04 00:30:23,064 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:23,064 Saving new checkpoint.\n",
      "2020-03-04 00:30:23,215 Validation result (greedy) at epoch  14, step     1400: bleu:  11.14, loss: 9001.4619, ppl:   2.4518, duration: 3.7031s\n",
      "2020-03-04 00:30:29,523 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:29,523 Saving new checkpoint.\n",
      "2020-03-04 00:30:29,657 Validation result (greedy) at epoch  14, step     1410: bleu:  11.77, loss: 8890.1709, ppl:   2.4248, duration: 4.8507s\n",
      "2020-03-04 00:30:34,740 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:34,740 Saving new checkpoint.\n",
      "2020-03-04 00:30:34,887 Validation result (greedy) at epoch  14, step     1420: bleu:  11.91, loss: 8952.2178, ppl:   2.4398, duration: 4.0059s\n",
      "2020-03-04 00:30:40,330 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:40,330 Saving new checkpoint.\n",
      "2020-03-04 00:30:40,486 Validation result (greedy) at epoch  14, step     1430: bleu:  12.04, loss: 8813.5322, ppl:   2.4063, duration: 3.8494s\n",
      "2020-03-04 00:30:46,232 Validation result (greedy) at epoch  14, step     1440: bleu:  10.85, loss: 8728.5654, ppl:   2.3860, duration: 4.1531s\n",
      "2020-03-04 00:30:52,993 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:30:52,993 Saving new checkpoint.\n",
      "2020-03-04 00:30:53,184 Validation result (greedy) at epoch  14, step     1450: bleu:  13.36, loss: 9081.7383, ppl:   2.4715, duration: 4.7353s\n",
      "2020-03-04 00:30:59,285 Validation result (greedy) at epoch  14, step     1460: bleu:  13.22, loss: 8775.7148, ppl:   2.3973, duration: 4.3120s\n",
      "2020-03-04 00:31:04,942 Validation result (greedy) at epoch  14, step     1470: bleu:  12.30, loss: 8730.3379, ppl:   2.3865, duration: 3.7157s\n",
      "2020-03-04 00:31:04,943 Epoch  14: total training loss 2780.27\n",
      "2020-03-04 00:31:04,943 EPOCH 15\n",
      "2020-03-04 00:31:10,918 Validation result (greedy) at epoch  15, step     1480: bleu:  12.11, loss: 9326.7969, ppl:   2.5326, duration: 3.9977s\n",
      "2020-03-04 00:31:16,415 Validation result (greedy) at epoch  15, step     1490: bleu:  11.55, loss: 9178.6514, ppl:   2.4955, duration: 3.8224s\n",
      "2020-03-04 00:31:21,819 Validation result (greedy) at epoch  15, step     1500: bleu:  12.07, loss: 8979.3311, ppl:   2.4464, duration: 3.6901s\n",
      "2020-03-04 00:31:27,688 Validation result (greedy) at epoch  15, step     1510: bleu:  13.02, loss: 8901.5098, ppl:   2.4275, duration: 4.4635s\n",
      "2020-03-04 00:31:33,101 Validation result (greedy) at epoch  15, step     1520: bleu:  11.20, loss: 8901.8906, ppl:   2.4276, duration: 3.9606s\n",
      "2020-03-04 00:31:40,016 Validation result (greedy) at epoch  15, step     1530: bleu:  13.35, loss: 8651.3770, ppl:   2.3678, duration: 5.3769s\n",
      "2020-03-04 00:31:45,641 Validation result (greedy) at epoch  15, step     1540: bleu:  12.84, loss: 8660.1885, ppl:   2.3698, duration: 4.0204s\n",
      "2020-03-04 00:31:51,055 Validation result (greedy) at epoch  15, step     1550: bleu:  11.58, loss: 8704.0898, ppl:   2.3802, duration: 3.9186s\n",
      "2020-03-04 00:31:56,465 Validation result (greedy) at epoch  15, step     1560: bleu:  11.60, loss: 8688.8428, ppl:   2.3766, duration: 3.9850s\n",
      "2020-03-04 00:32:02,280 Validation result (greedy) at epoch  15, step     1570: bleu:  13.19, loss: 8775.9609, ppl:   2.3973, duration: 4.4491s\n",
      "2020-03-04 00:32:03,382 Epoch  15: total training loss 2610.47\n",
      "2020-03-04 00:32:03,382 EPOCH 16\n",
      "2020-03-04 00:32:08,081 Validation result (greedy) at epoch  16, step     1580: bleu:   9.19, loss: 9655.3115, ppl:   2.6169, duration: 4.0451s\n",
      "2020-03-04 00:32:13,507 Validation result (greedy) at epoch  16, step     1590: bleu:  11.73, loss: 9033.2285, ppl:   2.4596, duration: 3.8534s\n",
      "2020-03-04 00:32:19,334 Validation result (greedy) at epoch  16, step     1600: bleu:  12.81, loss: 8807.5537, ppl:   2.4049, duration: 4.5427s\n",
      "2020-03-04 00:32:25,076 Validation result (greedy) at epoch  16, step     1610: bleu:  12.46, loss: 8552.0918, ppl:   2.3445, duration: 4.0497s\n",
      "2020-03-04 00:32:31,287 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:32:31,287 Saving new checkpoint.\n",
      "2020-03-04 00:32:31,430 Validation result (greedy) at epoch  16, step     1620: bleu:  14.71, loss: 8669.1221, ppl:   2.3720, duration: 4.6605s\n",
      "2020-03-04 00:32:36,530 Validation result (greedy) at epoch  16, step     1630: bleu:  12.94, loss: 8656.2080, ppl:   2.3689, duration: 3.5571s\n",
      "2020-03-04 00:32:41,583 Validation result (greedy) at epoch  16, step     1640: bleu:  14.29, loss: 8441.3877, ppl:   2.3187, duration: 3.5808s\n",
      "2020-03-04 00:32:46,878 Validation result (greedy) at epoch  16, step     1650: bleu:  13.69, loss: 8401.8232, ppl:   2.3096, duration: 3.8052s\n",
      "2020-03-04 00:32:52,422 Validation result (greedy) at epoch  16, step     1660: bleu:  13.14, loss: 8389.2559, ppl:   2.3067, duration: 4.1819s\n",
      "2020-03-04 00:32:58,635 Validation result (greedy) at epoch  16, step     1670: bleu:  12.46, loss: 8453.0166, ppl:   2.3214, duration: 4.6879s\n",
      "2020-03-04 00:33:04,939 Validation result (greedy) at epoch  16, step     1680: bleu:  10.55, loss: 8884.3770, ppl:   2.4234, duration: 4.3964s\n",
      "2020-03-04 00:33:04,940 Epoch  16: total training loss 2386.72\n",
      "2020-03-04 00:33:04,940 EPOCH 17\n",
      "2020-03-04 00:33:10,626 Validation result (greedy) at epoch  17, step     1690: bleu:  13.62, loss: 8593.6914, ppl:   2.3542, duration: 4.0894s\n",
      "2020-03-04 00:33:16,256 Validation result (greedy) at epoch  17, step     1700: bleu:  11.86, loss: 8583.9189, ppl:   2.3519, duration: 3.7386s\n",
      "2020-03-04 00:33:21,718 Validation result (greedy) at epoch  17, step     1710: bleu:  14.35, loss: 8435.7363, ppl:   2.3174, duration: 3.7298s\n",
      "2020-03-04 00:33:27,953 Validation result (greedy) at epoch  17, step     1720: bleu:  14.39, loss: 8417.6113, ppl:   2.3133, duration: 4.4999s\n",
      "2020-03-04 00:33:33,017 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:33:33,018 Saving new checkpoint.\n",
      "2020-03-04 00:33:33,172 Validation result (greedy) at epoch  17, step     1730: bleu:  14.79, loss: 8369.8096, ppl:   2.3023, duration: 3.7598s\n",
      "2020-03-04 00:33:38,826 Validation result (greedy) at epoch  17, step     1740: bleu:  13.72, loss: 8338.6865, ppl:   2.2951, duration: 3.9215s\n",
      "2020-03-04 00:33:44,213 Validation result (greedy) at epoch  17, step     1750: bleu:  12.78, loss: 8562.6602, ppl:   2.3469, duration: 3.8908s\n",
      "2020-03-04 00:33:49,809 Validation result (greedy) at epoch  17, step     1760: bleu:  13.82, loss: 8386.2822, ppl:   2.3061, duration: 3.9776s\n",
      "2020-03-04 00:33:56,515 Validation result (greedy) at epoch  17, step     1770: bleu:  13.41, loss: 8435.9795, ppl:   2.3175, duration: 4.9274s\n",
      "2020-03-04 00:34:02,092 Validation result (greedy) at epoch  17, step     1780: bleu:  13.91, loss: 8383.1113, ppl:   2.3053, duration: 3.9578s\n",
      "2020-03-04 00:34:03,030 Epoch  17: total training loss 2139.42\n",
      "2020-03-04 00:34:03,030 EPOCH 18\n",
      "2020-03-04 00:34:07,853 Validation result (greedy) at epoch  18, step     1790: bleu:  13.50, loss: 8683.3740, ppl:   2.3753, duration: 4.0584s\n",
      "2020-03-04 00:34:13,854 Validation result (greedy) at epoch  18, step     1800: bleu:  14.05, loss: 8485.3994, ppl:   2.3289, duration: 4.3140s\n",
      "2020-03-04 00:34:18,871 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:34:18,871 Saving new checkpoint.\n",
      "2020-03-04 00:34:19,006 Validation result (greedy) at epoch  18, step     1810: bleu:  15.29, loss: 8471.7266, ppl:   2.3258, duration: 3.8687s\n",
      "2020-03-04 00:34:24,450 Validation result (greedy) at epoch  18, step     1820: bleu:  14.36, loss: 8383.7705, ppl:   2.3055, duration: 4.0629s\n",
      "2020-03-04 00:34:30,730 Validation result (greedy) at epoch  18, step     1830: bleu:  15.25, loss: 8527.5566, ppl:   2.3387, duration: 4.6906s\n",
      "2020-03-04 00:34:36,321 Validation result (greedy) at epoch  18, step     1840: bleu:  14.44, loss: 8503.6680, ppl:   2.3332, duration: 4.2425s\n",
      "2020-03-04 00:34:42,094 Validation result (greedy) at epoch  18, step     1850: bleu:  14.87, loss: 8389.7627, ppl:   2.3069, duration: 3.8978s\n",
      "2020-03-04 00:34:47,596 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:34:47,596 Saving new checkpoint.\n",
      "2020-03-04 00:34:47,736 Validation result (greedy) at epoch  18, step     1860: bleu:  15.83, loss: 8424.0879, ppl:   2.3148, duration: 4.1894s\n",
      "2020-03-04 00:34:52,731 Validation result (greedy) at epoch  18, step     1870: bleu:  13.36, loss: 8560.5742, ppl:   2.3464, duration: 3.8258s\n",
      "2020-03-04 00:34:58,178 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:34:58,178 Saving new checkpoint.\n",
      "2020-03-04 00:34:58,328 Validation result (greedy) at epoch  18, step     1880: bleu:  16.77, loss: 8402.0781, ppl:   2.3097, duration: 4.1989s\n",
      "2020-03-04 00:35:04,070 Validation result (greedy) at epoch  18, step     1890: bleu:  16.03, loss: 9143.7812, ppl:   2.4868, duration: 3.8584s\n",
      "2020-03-04 00:35:04,070 Epoch  18: total training loss 2012.47\n",
      "2020-03-04 00:35:04,071 EPOCH 19\n",
      "2020-03-04 00:35:09,941 Validation result (greedy) at epoch  19, step     1900: bleu:  10.92, loss: 9125.3086, ppl:   2.4823, duration: 4.3359s\n",
      "2020-03-04 00:35:15,798 Validation result (greedy) at epoch  19, step     1910: bleu:  14.17, loss: 8754.0684, ppl:   2.3921, duration: 4.5699s\n",
      "2020-03-04 00:35:21,359 Validation result (greedy) at epoch  19, step     1920: bleu:  13.87, loss: 8654.5947, ppl:   2.3685, duration: 3.7719s\n",
      "2020-03-04 00:35:26,155 Validation result (greedy) at epoch  19, step     1930: bleu:  14.32, loss: 8436.9434, ppl:   2.3177, duration: 3.3744s\n",
      "2020-03-04 00:35:31,480 Validation result (greedy) at epoch  19, step     1940: bleu:  13.47, loss: 8374.2461, ppl:   2.3033, duration: 3.7595s\n",
      "2020-03-04 00:35:36,552 Validation result (greedy) at epoch  19, step     1950: bleu:  15.65, loss: 8394.4443, ppl:   2.3079, duration: 3.8276s\n",
      "2020-03-04 00:35:41,955 Validation result (greedy) at epoch  19, step     1960: bleu:  15.48, loss: 8339.2998, ppl:   2.2953, duration: 3.9864s\n",
      "2020-03-04 00:35:47,746 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:35:47,747 Saving new checkpoint.\n",
      "2020-03-04 00:35:47,890 Validation result (greedy) at epoch  19, step     1970: bleu:  16.81, loss: 8223.3730, ppl:   2.2689, duration: 3.8671s\n",
      "2020-03-04 00:35:54,013 Validation result (greedy) at epoch  19, step     1980: bleu:  16.23, loss: 8510.1777, ppl:   2.3347, duration: 4.6915s\n",
      "2020-03-04 00:35:59,619 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:35:59,619 Saving new checkpoint.\n",
      "2020-03-04 00:35:59,783 Validation result (greedy) at epoch  19, step     1990: bleu:  17.16, loss: 8390.1797, ppl:   2.3069, duration: 4.2523s\n",
      "2020-03-04 00:36:00,812 Epoch  19: total training loss 1893.12\n",
      "2020-03-04 00:36:00,813 EPOCH 20\n",
      "2020-03-04 00:36:01,442 Epoch  20 Step:     2000 Batch Loss:     9.622401 Tokens per Sec:    11536, Lr: 0.000400\n",
      "2020-03-04 00:36:04,983 Validation result (greedy) at epoch  20, step     2000: bleu:  13.72, loss: 8886.2441, ppl:   2.4238, duration: 3.5408s\n",
      "2020-03-04 00:36:11,162 Validation result (greedy) at epoch  20, step     2010: bleu:  13.74, loss: 8686.3008, ppl:   2.3760, duration: 4.4151s\n",
      "2020-03-04 00:36:16,327 Validation result (greedy) at epoch  20, step     2020: bleu:  16.84, loss: 8679.1602, ppl:   2.3743, duration: 3.8089s\n",
      "2020-03-04 00:36:21,540 Validation result (greedy) at epoch  20, step     2030: bleu:  16.91, loss: 8377.5342, ppl:   2.3040, duration: 3.7281s\n",
      "2020-03-04 00:36:27,025 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:36:27,025 Saving new checkpoint.\n",
      "2020-03-04 00:36:27,162 Validation result (greedy) at epoch  20, step     2040: bleu:  18.30, loss: 8334.4307, ppl:   2.2942, duration: 4.2560s\n",
      "2020-03-04 00:36:32,943 Validation result (greedy) at epoch  20, step     2050: bleu:  16.00, loss: 8486.2910, ppl:   2.3291, duration: 4.3011s\n",
      "2020-03-04 00:36:38,255 Validation result (greedy) at epoch  20, step     2060: bleu:  16.39, loss: 8372.4648, ppl:   2.3029, duration: 3.8642s\n",
      "2020-03-04 00:36:44,393 Validation result (greedy) at epoch  20, step     2070: bleu:  14.95, loss: 8453.2939, ppl:   2.3215, duration: 4.1630s\n",
      "2020-03-04 00:36:50,322 Validation result (greedy) at epoch  20, step     2080: bleu:  17.10, loss: 8310.2217, ppl:   2.2886, duration: 4.5506s\n",
      "2020-03-04 00:36:55,710 Validation result (greedy) at epoch  20, step     2090: bleu:  16.56, loss: 8267.1982, ppl:   2.2789, duration: 3.8913s\n",
      "2020-03-04 00:37:01,247 Validation result (greedy) at epoch  20, step     2100: bleu:  16.29, loss: 8405.8809, ppl:   2.3106, duration: 3.6784s\n",
      "2020-03-04 00:37:01,248 Epoch  20: total training loss 1685.21\n",
      "2020-03-04 00:37:01,248 EPOCH 21\n",
      "2020-03-04 00:37:06,156 Validation result (greedy) at epoch  21, step     2110: bleu:  17.72, loss: 8643.0889, ppl:   2.3658, duration: 3.6491s\n",
      "2020-03-04 00:37:11,944 Validation result (greedy) at epoch  21, step     2120: bleu:  18.05, loss: 8638.7324, ppl:   2.3648, duration: 4.2043s\n",
      "2020-03-04 00:37:17,698 Validation result (greedy) at epoch  21, step     2130: bleu:  15.50, loss: 8533.6035, ppl:   2.3401, duration: 4.0873s\n",
      "2020-03-04 00:37:23,445 Validation result (greedy) at epoch  21, step     2140: bleu:  16.73, loss: 8432.9238, ppl:   2.3168, duration: 4.1080s\n",
      "2020-03-04 00:37:29,421 Validation result (greedy) at epoch  21, step     2150: bleu:  18.03, loss: 8541.2441, ppl:   2.3419, duration: 4.3892s\n",
      "2020-03-04 00:37:34,494 Validation result (greedy) at epoch  21, step     2160: bleu:  17.06, loss: 8480.1143, ppl:   2.3277, duration: 3.6807s\n",
      "2020-03-04 00:37:40,259 Validation result (greedy) at epoch  21, step     2170: bleu:  17.56, loss: 8453.1631, ppl:   2.3215, duration: 3.8751s\n",
      "2020-03-04 00:37:45,713 Validation result (greedy) at epoch  21, step     2180: bleu:  16.42, loss: 8524.5361, ppl:   2.3380, duration: 3.9222s\n",
      "2020-03-04 00:37:51,627 Validation result (greedy) at epoch  21, step     2190: bleu:  16.17, loss: 8618.5020, ppl:   2.3600, duration: 4.1087s\n",
      "2020-03-04 00:37:58,161 Validation result (greedy) at epoch  21, step     2200: bleu:  14.81, loss: 8961.5684, ppl:   2.4421, duration: 4.7744s\n",
      "2020-03-04 00:37:59,084 Epoch  21: total training loss 1535.21\n",
      "2020-03-04 00:37:59,084 EPOCH 22\n",
      "2020-03-04 00:38:04,013 Validation result (greedy) at epoch  22, step     2210: bleu:  18.13, loss: 8728.4062, ppl:   2.3860, duration: 4.1861s\n",
      "2020-03-04 00:38:09,762 Validation result (greedy) at epoch  22, step     2220: bleu:  15.77, loss: 8718.0098, ppl:   2.3835, duration: 3.9077s\n",
      "2020-03-04 00:38:15,472 Validation result (greedy) at epoch  22, step     2230: bleu:  15.84, loss: 8836.4434, ppl:   2.4118, duration: 4.5277s\n",
      "2020-03-04 00:38:21,210 Validation result (greedy) at epoch  22, step     2240: bleu:  17.48, loss: 8547.5322, ppl:   2.3434, duration: 4.0370s\n",
      "2020-03-04 00:38:26,327 Validation result (greedy) at epoch  22, step     2250: bleu:  17.30, loss: 8580.5273, ppl:   2.3511, duration: 3.6090s\n",
      "2020-03-04 00:38:31,501 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:38:31,502 Saving new checkpoint.\n",
      "2020-03-04 00:38:31,641 Validation result (greedy) at epoch  22, step     2260: bleu:  18.79, loss: 8459.0469, ppl:   2.3228, duration: 3.9162s\n",
      "2020-03-04 00:38:36,918 Validation result (greedy) at epoch  22, step     2270: bleu:  18.58, loss: 8368.8418, ppl:   2.3020, duration: 3.8989s\n",
      "2020-03-04 00:38:42,045 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:38:42,045 Saving new checkpoint.\n",
      "2020-03-04 00:38:42,187 Validation result (greedy) at epoch  22, step     2280: bleu:  19.23, loss: 8365.0254, ppl:   2.3012, duration: 3.5539s\n",
      "2020-03-04 00:38:46,919 Validation result (greedy) at epoch  22, step     2290: bleu:  19.16, loss: 8343.0449, ppl:   2.2961, duration: 3.4262s\n",
      "2020-03-04 00:38:52,592 Validation result (greedy) at epoch  22, step     2300: bleu:  19.18, loss: 8314.8652, ppl:   2.2897, duration: 3.9188s\n",
      "2020-03-04 00:38:58,531 Validation result (greedy) at epoch  22, step     2310: bleu:  18.51, loss: 8641.9463, ppl:   2.3655, duration: 4.2789s\n",
      "2020-03-04 00:38:58,532 Epoch  22: total training loss 1428.74\n",
      "2020-03-04 00:38:58,532 EPOCH 23\n",
      "2020-03-04 00:39:04,785 Validation result (greedy) at epoch  23, step     2320: bleu:  17.13, loss: 8960.6309, ppl:   2.4419, duration: 4.9270s\n",
      "2020-03-04 00:39:10,011 Validation result (greedy) at epoch  23, step     2330: bleu:  17.38, loss: 8693.9961, ppl:   2.3778, duration: 3.6983s\n",
      "2020-03-04 00:39:15,474 Validation result (greedy) at epoch  23, step     2340: bleu:  17.10, loss: 8640.7402, ppl:   2.3653, duration: 4.0023s\n",
      "2020-03-04 00:39:22,141 Validation result (greedy) at epoch  23, step     2350: bleu:  17.14, loss: 8907.9570, ppl:   2.4291, duration: 4.8254s\n",
      "2020-03-04 00:39:27,871 Validation result (greedy) at epoch  23, step     2360: bleu:  17.02, loss: 8679.2109, ppl:   2.3743, duration: 4.1721s\n",
      "2020-03-04 00:39:33,444 Validation result (greedy) at epoch  23, step     2370: bleu:  18.13, loss: 8706.9209, ppl:   2.3809, duration: 4.3122s\n",
      "2020-03-04 00:39:38,474 Validation result (greedy) at epoch  23, step     2380: bleu:  17.33, loss: 8533.5771, ppl:   2.3401, duration: 3.5380s\n",
      "2020-03-04 00:39:43,871 Validation result (greedy) at epoch  23, step     2390: bleu:  17.67, loss: 8610.8125, ppl:   2.3582, duration: 3.9223s\n",
      "2020-03-04 00:39:49,148 Validation result (greedy) at epoch  23, step     2400: bleu:  17.19, loss: 8492.0166, ppl:   2.3305, duration: 3.8471s\n",
      "2020-03-04 00:39:54,762 Validation result (greedy) at epoch  23, step     2410: bleu:  17.63, loss: 8391.9531, ppl:   2.3074, duration: 3.7483s\n",
      "2020-03-04 00:39:55,712 Epoch  23: total training loss 1340.12\n",
      "2020-03-04 00:39:55,712 EPOCH 24\n",
      "2020-03-04 00:40:00,890 Validation result (greedy) at epoch  24, step     2420: bleu:  17.34, loss: 9021.4248, ppl:   2.4567, duration: 4.1714s\n",
      "2020-03-04 00:40:06,445 Validation result (greedy) at epoch  24, step     2430: bleu:  17.68, loss: 8682.2910, ppl:   2.3751, duration: 4.1166s\n",
      "2020-03-04 00:40:12,741 Validation result (greedy) at epoch  24, step     2440: bleu:  15.19, loss: 9099.8672, ppl:   2.4760, duration: 4.7631s\n",
      "2020-03-04 00:40:19,372 Validation result (greedy) at epoch  24, step     2450: bleu:  18.36, loss: 8568.4658, ppl:   2.3483, duration: 4.9003s\n",
      "2020-03-04 00:40:24,691 Validation result (greedy) at epoch  24, step     2460: bleu:  17.88, loss: 8835.6562, ppl:   2.4116, duration: 3.7102s\n",
      "2020-03-04 00:40:30,567 Validation result (greedy) at epoch  24, step     2470: bleu:  18.76, loss: 8601.8789, ppl:   2.3561, duration: 4.0335s\n",
      "2020-03-04 00:40:36,100 Validation result (greedy) at epoch  24, step     2480: bleu:  18.35, loss: 8520.6240, ppl:   2.3371, duration: 4.0458s\n",
      "2020-03-04 00:40:41,436 Validation result (greedy) at epoch  24, step     2490: bleu:  18.64, loss: 8572.6201, ppl:   2.3493, duration: 3.6407s\n",
      "2020-03-04 00:40:46,341 Validation result (greedy) at epoch  24, step     2500: bleu:  18.46, loss: 8574.7695, ppl:   2.3498, duration: 3.5243s\n",
      "2020-03-04 00:40:51,610 Validation result (greedy) at epoch  24, step     2510: bleu:  17.52, loss: 8555.8848, ppl:   2.3453, duration: 3.5823s\n",
      "2020-03-04 00:40:57,125 Validation result (greedy) at epoch  24, step     2520: bleu:  16.66, loss: 8976.3828, ppl:   2.4457, duration: 3.8336s\n",
      "2020-03-04 00:40:57,125 Epoch  24: total training loss 1244.63\n",
      "2020-03-04 00:40:57,125 EPOCH 25\n",
      "2020-03-04 00:41:03,050 Validation result (greedy) at epoch  25, step     2530: bleu:  17.51, loss: 9104.7969, ppl:   2.4772, duration: 4.2647s\n",
      "2020-03-04 00:41:08,471 Validation result (greedy) at epoch  25, step     2540: bleu:  16.65, loss: 9017.4893, ppl:   2.4557, duration: 4.0450s\n",
      "2020-03-04 00:41:14,466 Validation result (greedy) at epoch  25, step     2550: bleu:  17.51, loss: 8744.1133, ppl:   2.3897, duration: 4.3604s\n",
      "2020-03-04 00:41:20,807 Validation result (greedy) at epoch  25, step     2560: bleu:  17.62, loss: 8804.5586, ppl:   2.4042, duration: 4.5422s\n",
      "2020-03-04 00:41:26,798 Validation result (greedy) at epoch  25, step     2570: bleu:  18.08, loss: 8712.1250, ppl:   2.3821, duration: 4.0763s\n",
      "2020-03-04 00:41:32,056 Validation result (greedy) at epoch  25, step     2580: bleu:  18.81, loss: 9002.1631, ppl:   2.4520, duration: 3.9537s\n",
      "2020-03-04 00:41:37,751 Validation result (greedy) at epoch  25, step     2590: bleu:  17.40, loss: 8695.5254, ppl:   2.3782, duration: 3.9867s\n",
      "2020-03-04 00:41:43,391 Validation result (greedy) at epoch  25, step     2600: bleu:  17.46, loss: 8713.1650, ppl:   2.3824, duration: 4.0216s\n",
      "2020-03-04 00:41:48,715 Validation result (greedy) at epoch  25, step     2610: bleu:  18.78, loss: 8663.6279, ppl:   2.3707, duration: 4.0019s\n",
      "2020-03-04 00:41:54,041 Validation result (greedy) at epoch  25, step     2620: bleu:  18.39, loss: 8751.3613, ppl:   2.3915, duration: 3.9754s\n",
      "2020-03-04 00:41:54,974 Epoch  25: total training loss 1135.53\n",
      "2020-03-04 00:41:54,974 Training ended after  25 epochs.\n",
      "2020-03-04 00:41:54,974 Best validation result (greedy) at step     2280:  19.23 eval_metric.\n",
      "2020-03-04 00:42:00,029  dev bleu:  21.54 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-04 00:42:00,029 Translations saved to: results/rnn/transfer_top/splits.en/en-lt_300_512/char/00002280.hyps.dev\n",
      "2020-03-04 00:42:03,838 test bleu:  24.22 [Beam search decoding with beam size = 5 and alpha = 1.0]\n",
      "2020-03-04 00:42:03,839 Translations saved to: results/rnn/transfer_top/splits.en/en-lt_300_512/char/00002280.hyps.test\n",
      "2020-03-04 00:42:04,200 Hello! This is Joey-NMT.\n",
      "2020-03-04 00:42:04,200 Hello! This is Joey-NMT.\n",
      "2020-03-04 00:42:04,201 Total params: 12461644\n",
      "2020-03-04 00:42:04,201 Total params: 12461644\n",
      "2020-03-04 00:42:04,201 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-03-04 00:42:04,201 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.energy_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.attention.query_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_hh_l1', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.bias_ih_l1', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_hh_l1', 'decoder.rnn.weight_ih_l0', 'decoder.rnn.weight_ih_l1', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_hh_l1', 'encoder.rnn.bias_hh_l1_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.bias_ih_l1', 'encoder.rnn.bias_ih_l1_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_hh_l1', 'encoder.rnn.weight_hh_l1_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'encoder.rnn.weight_ih_l1', 'encoder.rnn.weight_ih_l1_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']\n",
      "2020-03-04 00:42:04,207 cfg.name                           : my_experiment\n",
      "2020-03-04 00:42:04,207 cfg.name                           : my_experiment\n",
      "2020-03-04 00:42:04,207 cfg.data.src                       : en\n",
      "2020-03-04 00:42:04,207 cfg.data.src                       : en\n",
      "2020-03-04 00:42:04,207 cfg.data.trg                       : shp\n",
      "2020-03-04 00:42:04,207 cfg.data.trg                       : shp\n",
      "2020-03-04 00:42:04,207 cfg.data.train                     : data/transfer/preprocessed/splits.en/en-shp/char/train\n",
      "2020-03-04 00:42:04,207 cfg.data.train                     : data/transfer/preprocessed/splits.en/en-shp/char/train\n",
      "2020-03-04 00:42:04,208 cfg.data.dev                       : data/transfer/preprocessed/splits.en/en-shp/char/valid\n",
      "2020-03-04 00:42:04,208 cfg.data.dev                       : data/transfer/preprocessed/splits.en/en-shp/char/valid\n",
      "2020-03-04 00:42:04,208 cfg.data.test                      : data/transfer/preprocessed/splits.en/en-shp/char/test\n",
      "2020-03-04 00:42:04,208 cfg.data.test                      : data/transfer/preprocessed/splits.en/en-shp/char/test\n",
      "2020-03-04 00:42:04,208 cfg.data.level                     : char\n",
      "2020-03-04 00:42:04,208 cfg.data.level                     : char\n",
      "2020-03-04 00:42:04,208 cfg.data.lowercase                 : True\n",
      "2020-03-04 00:42:04,208 cfg.data.lowercase                 : True\n",
      "2020-03-04 00:42:04,208 cfg.data.max_sent_length           : 130\n",
      "2020-03-04 00:42:04,208 cfg.data.max_sent_length           : 130\n",
      "2020-03-04 00:42:04,208 cfg.data.src_voc_min_freq          : 1\n",
      "2020-03-04 00:42:04,208 cfg.data.src_voc_min_freq          : 1\n",
      "2020-03-04 00:42:04,208 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-03-04 00:42:04,208 cfg.data.trg_voc_min_freq          : 1\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.src            : en\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.src            : en\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.trg            : lt\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.trg            : lt\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.train          : data/transfer/preprocessed/splits.en/en-lt/char/train\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.train          : data/transfer/preprocessed/splits.en/en-lt/char/train\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.dev            : data/transfer/preprocessed/splits.en/en-lt/char/valid\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.dev            : data/transfer/preprocessed/splits.en/en-lt/char/valid\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.test           : data/transfer/preprocessed/splits.en/en-lt/char/test\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.test           : data/transfer/preprocessed/splits.en/en-lt/char/test\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.level          : char\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.level          : char\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.lowercase      : True\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.lowercase      : True\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.max_sent_length : 150\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.max_sent_length : 150\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.src_voc_min_freq : 1\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.src_voc_min_freq : 1\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.trg_voc_min_freq : 1\n",
      "2020-03-04 00:42:04,208 cfg.pretrained_data.trg_voc_min_freq : 1\n",
      "2020-03-04 00:42:04,209 cfg.testing.beam_size              : 5\n",
      "2020-03-04 00:42:04,209 cfg.testing.beam_size              : 5\n",
      "2020-03-04 00:42:04,209 cfg.testing.alpha                  : 1.0\n",
      "2020-03-04 00:42:04,209 cfg.testing.alpha                  : 1.0\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_best_ckpt       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_best_ckpt       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_scheduler       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_scheduler       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_optimizer       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.reset_optimizer       : False\n",
      "2020-03-04 00:42:04,209 cfg.training.random_seed           : 42\n",
      "2020-03-04 00:42:04,209 cfg.training.random_seed           : 42\n",
      "2020-03-04 00:42:04,209 cfg.training.optimizer             : adam\n",
      "2020-03-04 00:42:04,209 cfg.training.optimizer             : adam\n",
      "2020-03-04 00:42:04,209 cfg.training.learning_rate         : 0.0002\n",
      "2020-03-04 00:42:04,209 cfg.training.learning_rate         : 0.0002\n",
      "2020-03-04 00:42:04,209 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-03-04 00:42:04,209 cfg.training.learning_rate_min     : 0.0001\n",
      "2020-03-04 00:42:04,209 cfg.training.clip_grad_val         : 1.0\n",
      "2020-03-04 00:42:04,209 cfg.training.clip_grad_val         : 1.0\n",
      "2020-03-04 00:42:04,209 cfg.training.weight_decay          : 0.0\n",
      "2020-03-04 00:42:04,209 cfg.training.weight_decay          : 0.0\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_size            : 48\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_size            : 48\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_type            : sentence\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_type            : sentence\n",
      "2020-03-04 00:42:04,209 cfg.training.eval_batch_size       : 10\n",
      "2020-03-04 00:42:04,209 cfg.training.eval_batch_size       : 10\n",
      "2020-03-04 00:42:04,209 cfg.training.eval_batch_type       : sentence\n",
      "2020-03-04 00:42:04,209 cfg.training.eval_batch_type       : sentence\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_multiplier      : 1\n",
      "2020-03-04 00:42:04,209 cfg.training.batch_multiplier      : 1\n",
      "2020-03-04 00:42:04,210 cfg.training.scheduling            : plateau\n",
      "2020-03-04 00:42:04,210 cfg.training.scheduling            : plateau\n",
      "2020-03-04 00:42:04,210 cfg.training.patience              : 600\n",
      "2020-03-04 00:42:04,210 cfg.training.patience              : 600\n",
      "2020-03-04 00:42:04,210 cfg.training.decrease_factor       : 0.5\n",
      "2020-03-04 00:42:04,210 cfg.training.decrease_factor       : 0.5\n",
      "2020-03-04 00:42:04,210 cfg.training.epochs                : 20\n",
      "2020-03-04 00:42:04,210 cfg.training.epochs                : 20\n",
      "2020-03-04 00:42:04,210 cfg.training.validation_freq       : 10\n",
      "2020-03-04 00:42:04,210 cfg.training.validation_freq       : 10\n",
      "2020-03-04 00:42:04,210 cfg.training.logging_freq          : 1000\n",
      "2020-03-04 00:42:04,210 cfg.training.logging_freq          : 1000\n",
      "2020-03-04 00:42:04,210 cfg.training.eval_metric           : bleu\n",
      "2020-03-04 00:42:04,210 cfg.training.eval_metric           : bleu\n",
      "2020-03-04 00:42:04,210 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:42:04,210 cfg.training.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:42:04,210 cfg.training.model_dir             : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:42:04,210 cfg.training.model_dir             : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:42:04,210 cfg.training.overwrite             : True\n",
      "2020-03-04 00:42:04,210 cfg.training.overwrite             : True\n",
      "2020-03-04 00:42:04,210 cfg.training.shuffle               : True\n",
      "2020-03-04 00:42:04,210 cfg.training.shuffle               : True\n",
      "2020-03-04 00:42:04,210 cfg.training.use_cuda              : True\n",
      "2020-03-04 00:42:04,210 cfg.training.use_cuda              : True\n",
      "2020-03-04 00:42:04,210 cfg.training.max_output_length     : 60\n",
      "2020-03-04 00:42:04,210 cfg.training.max_output_length     : 60\n",
      "2020-03-04 00:42:04,210 cfg.training.print_valid_sents     : []\n",
      "2020-03-04 00:42:04,210 cfg.training.print_valid_sents     : []\n",
      "2020-03-04 00:42:04,210 cfg.training.keep_last_ckpts       : 3\n",
      "2020-03-04 00:42:04,210 cfg.training.keep_last_ckpts       : 3\n",
      "2020-03-04 00:42:04,210 cfg.training.label_smoothing       : 0.0\n",
      "2020-03-04 00:42:04,210 cfg.training.label_smoothing       : 0.0\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_best_ckpt    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_best_ckpt    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_scheduler    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_scheduler    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_optimizer    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.reset_optimizer    : False\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.random_seed        : 42\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.random_seed        : 42\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.optimizer          : adam\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.optimizer          : adam\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.learning_rate      : 0.0004\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.learning_rate      : 0.0004\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.learning_rate_min  : 1e-05\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.learning_rate_min  : 1e-05\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.clip_grad_val      : 1.0\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.clip_grad_val      : 1.0\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.weight_decay       : 0.0\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.weight_decay       : 0.0\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_size         : 48\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_size         : 48\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_type         : sentence\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_type         : sentence\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.eval_batch_size    : 10\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.eval_batch_size    : 10\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.eval_batch_type    : sentence\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.eval_batch_type    : sentence\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_multiplier   : 1\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.batch_multiplier   : 1\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.scheduling         : plateau\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.scheduling         : plateau\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.patience           : 600\n",
      "2020-03-04 00:42:04,211 cfg.pretraining.patience           : 600\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.decrease_factor    : 0.5\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.decrease_factor    : 0.5\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.epochs             : 25\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.epochs             : 25\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.validation_freq    : 10\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.validation_freq    : 10\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.logging_freq       : 1000\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.logging_freq       : 1000\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.eval_metric        : bleu\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.eval_metric        : bleu\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.early_stopping_metric : eval_metric\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.model_dir          : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.model_dir          : results/rnn/transfer_top/splits.en/en-lt_300_512/char\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.overwrite          : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.overwrite          : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.shuffle            : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.shuffle            : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.use_cuda           : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.use_cuda           : True\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.max_output_length  : 60\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.max_output_length  : 60\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.print_valid_sents  : []\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.print_valid_sents  : []\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.keep_last_ckpts    : 3\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.keep_last_ckpts    : 3\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.label_smoothing    : 0.0\n",
      "2020-03-04 00:42:04,212 cfg.pretraining.label_smoothing    : 0.0\n",
      "2020-03-04 00:42:04,212 cfg.model.initializer              : xavier\n",
      "2020-03-04 00:42:04,212 cfg.model.initializer              : xavier\n",
      "2020-03-04 00:42:04,212 cfg.model.init_weight              : 0.01\n",
      "2020-03-04 00:42:04,212 cfg.model.init_weight              : 0.01\n",
      "2020-03-04 00:42:04,213 cfg.model.init_gain                : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.init_gain                : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.bias_initializer         : zeros\n",
      "2020-03-04 00:42:04,213 cfg.model.bias_initializer         : zeros\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_initializer        : normal\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_initializer        : normal\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_init_weight        : 0.1\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_init_weight        : 0.1\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_init_gain          : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.embed_init_gain          : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-03-04 00:42:04,213 cfg.model.init_rnn_orthogonal      : False\n",
      "2020-03-04 00:42:04,213 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.lstm_forget_gate         : 1.0\n",
      "2020-03-04 00:42:04,213 cfg.model.tied_embeddings          : False\n",
      "2020-03-04 00:42:04,213 cfg.model.tied_embeddings          : False\n",
      "2020-03-04 00:42:04,213 cfg.model.tied_softmax             : False\n",
      "2020-03-04 00:42:04,213 cfg.model.tied_softmax             : False\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.type             : recurrent\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.type             : recurrent\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.rnn_type         : gru\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.rnn_type         : gru\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.scale : False\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.scale : False\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.embeddings.freeze : False\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.hidden_size      : 512\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.hidden_size      : 512\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.bidirectional    : True\n",
      "2020-03-04 00:42:04,213 cfg.model.encoder.bidirectional    : True\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.dropout          : 0.3\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.dropout          : 0.3\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.num_layers       : 2\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.num_layers       : 2\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.freeze           : False\n",
      "2020-03-04 00:42:04,214 cfg.model.encoder.freeze           : False\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.type             : recurrent\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.type             : recurrent\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.rnn_type         : gru\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.rnn_type         : gru\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.embedding_dim : 300\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.scale : False\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.scale : False\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.embeddings.freeze : False\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.hidden_size      : 512\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.hidden_size      : 512\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.dropout          : 0.3\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.dropout          : 0.3\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.hidden_dropout   : 0.2\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.num_layers       : 2\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.num_layers       : 2\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.input_feeding    : True\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.input_feeding    : True\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.init_hidden      : last\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.init_hidden      : last\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.attention        : bahdanau\n",
      "2020-03-04 00:42:04,214 cfg.model.decoder.attention        : bahdanau\n",
      "2020-03-04 00:42:04,215 cfg.model.decoder.freeze           : False\n",
      "2020-03-04 00:42:04,215 cfg.model.decoder.freeze           : False\n",
      "2020-03-04 00:42:04,215 Data set sizes: \n",
      "\ttrain 7332,\n",
      "\tvalid 418,\n",
      "\ttest 418\n",
      "2020-03-04 00:42:04,215 Data set sizes: \n",
      "\ttrain 7332,\n",
      "\tvalid 418,\n",
      "\ttest 418\n",
      "2020-03-04 00:42:04,215 First training example:\n",
      "\t[SRC] @@ \" @@ \" @@ \" @@ l o o k @@ , @@ \" @@ \" @@ s h e @@ s a i d @@ . @@ \"\n",
      "\t[TRG] @@ \" @@ w a t o n i n r a @@ y o i k e @@ \" @@ \" @@ w e n w e @@ \" @@ \" @@ . @@ \"\n",
      "2020-03-04 00:42:04,215 First training example:\n",
      "\t[SRC] @@ \" @@ \" @@ \" @@ l o o k @@ , @@ \" @@ \" @@ s h e @@ s a i d @@ . @@ \"\n",
      "\t[TRG] @@ \" @@ w a t o n i n r a @@ y o i k e @@ \" @@ \" @@ w e n w e @@ \" @@ \" @@ . @@ \"\n",
      "2020-03-04 00:42:04,215 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) o (7) t (8) i (9) a\n",
      "2020-03-04 00:42:04,215 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) e (6) o (7) t (8) i (9) a\n",
      "2020-03-04 00:42:04,215 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) a (6) i (7) n (8) e (9) k\n",
      "2020-03-04 00:42:04,215 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) @@ (5) a (6) i (7) n (8) e (9) k\n",
      "2020-03-04 00:42:04,215 Number of Src words (types): 44\n",
      "2020-03-04 00:42:04,215 Number of Src words (types): 44\n",
      "2020-03-04 00:42:04,215 Number of Trg words (types): 45\n",
      "2020-03-04 00:42:04,215 Number of Trg words (types): 45\n",
      "2020-03-04 00:42:04,215 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=44),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=45))\n",
      "2020-03-04 00:42:04,215 Model(\n",
      "\tencoder=RecurrentEncoder(GRU(300, 512, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)),\n",
      "\tdecoder=RecurrentDecoder(rnn=GRU(812, 512, num_layers=2, batch_first=True, dropout=0.3), attention=BahdanauAttention),\n",
      "\tsrc_embed=Embeddings(embedding_dim=300, vocab_size=44),\n",
      "\ttrg_embed=Embeddings(embedding_dim=300, vocab_size=45))\n",
      "2020-03-04 00:42:04,215 EPOCH 1\n",
      "2020-03-04 00:42:04,215 EPOCH 1\n",
      "2020-03-04 00:42:10,249 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:42:10,249 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:42:10,249 Saving new checkpoint.\n",
      "2020-03-04 00:42:10,249 Saving new checkpoint.\n",
      "2020-03-04 00:42:10,374 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 23828.4961, ppl:  17.3402, duration: 4.8335s\n",
      "2020-03-04 00:42:10,374 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss: 23828.4961, ppl:  17.3402, duration: 4.8335s\n",
      "2020-03-04 00:42:15,886 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 21884.4531, ppl:  13.7394, duration: 4.1485s\n",
      "2020-03-04 00:42:15,886 Validation result (greedy) at epoch   1, step       20: bleu:   0.00, loss: 21884.4531, ppl:  13.7394, duration: 4.1485s\n",
      "2020-03-04 00:42:21,564 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 20260.3730, ppl:  11.3114, duration: 4.5017s\n",
      "2020-03-04 00:42:21,564 Validation result (greedy) at epoch   1, step       30: bleu:   0.00, loss: 20260.3730, ppl:  11.3114, duration: 4.5017s\n",
      "2020-03-04 00:42:26,910 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 18313.0684, ppl:   8.9590, duration: 4.2106s\n",
      "2020-03-04 00:42:26,910 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 18313.0684, ppl:   8.9590, duration: 4.2106s\n",
      "2020-03-04 00:42:30,694 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 16655.8828, ppl:   7.3466, duration: 2.4584s\n",
      "2020-03-04 00:42:30,694 Validation result (greedy) at epoch   1, step       50: bleu:   0.00, loss: 16655.8828, ppl:   7.3466, duration: 2.4584s\n",
      "2020-03-04 00:42:33,858 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 15401.4160, ppl:   6.3220, duration: 1.9439s\n",
      "2020-03-04 00:42:33,858 Validation result (greedy) at epoch   1, step       60: bleu:   0.00, loss: 15401.4160, ppl:   6.3220, duration: 1.9439s\n",
      "2020-03-04 00:42:37,784 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 14489.5146, ppl:   5.6681, duration: 2.6470s\n",
      "2020-03-04 00:42:37,784 Validation result (greedy) at epoch   1, step       70: bleu:   0.00, loss: 14489.5146, ppl:   5.6681, duration: 2.6470s\n",
      "2020-03-04 00:42:41,508 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 13974.7803, ppl:   5.3293, duration: 2.3733s\n",
      "2020-03-04 00:42:41,508 Validation result (greedy) at epoch   1, step       80: bleu:   0.00, loss: 13974.7803, ppl:   5.3293, duration: 2.3733s\n",
      "2020-03-04 00:42:45,096 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 13501.6309, ppl:   5.0358, duration: 2.1698s\n",
      "2020-03-04 00:42:45,096 Validation result (greedy) at epoch   1, step       90: bleu:   0.00, loss: 13501.6309, ppl:   5.0358, duration: 2.1698s\n",
      "2020-03-04 00:42:48,709 Validation result (greedy) at epoch   1, step      100: bleu:   0.00, loss: 13137.0342, ppl:   4.8207, duration: 2.2347s\n",
      "2020-03-04 00:42:48,709 Validation result (greedy) at epoch   1, step      100: bleu:   0.00, loss: 13137.0342, ppl:   4.8207, duration: 2.2347s\n",
      "2020-03-04 00:42:52,155 Validation result (greedy) at epoch   1, step      110: bleu:   0.00, loss: 12655.8213, ppl:   4.5508, duration: 2.1967s\n",
      "2020-03-04 00:42:52,155 Validation result (greedy) at epoch   1, step      110: bleu:   0.00, loss: 12655.8213, ppl:   4.5508, duration: 2.1967s\n",
      "2020-03-04 00:42:56,350 Validation result (greedy) at epoch   1, step      120: bleu:   0.00, loss: 12333.7100, ppl:   4.3786, duration: 2.9193s\n",
      "2020-03-04 00:42:56,350 Validation result (greedy) at epoch   1, step      120: bleu:   0.00, loss: 12333.7100, ppl:   4.3786, duration: 2.9193s\n",
      "2020-03-04 00:43:00,209 Validation result (greedy) at epoch   1, step      130: bleu:   0.00, loss: 11970.8828, ppl:   4.1925, duration: 2.5908s\n",
      "2020-03-04 00:43:00,209 Validation result (greedy) at epoch   1, step      130: bleu:   0.00, loss: 11970.8828, ppl:   4.1925, duration: 2.5908s\n",
      "2020-03-04 00:43:04,986 Validation result (greedy) at epoch   1, step      140: bleu:   0.00, loss: 11711.0625, ppl:   4.0641, duration: 3.5775s\n",
      "2020-03-04 00:43:04,986 Validation result (greedy) at epoch   1, step      140: bleu:   0.00, loss: 11711.0625, ppl:   4.0641, duration: 3.5775s\n",
      "2020-03-04 00:43:08,760 Validation result (greedy) at epoch   1, step      150: bleu:   0.00, loss: 11452.4697, ppl:   3.9402, duration: 2.4478s\n",
      "2020-03-04 00:43:08,760 Validation result (greedy) at epoch   1, step      150: bleu:   0.00, loss: 11452.4697, ppl:   3.9402, duration: 2.4478s\n",
      "2020-03-04 00:43:09,037 Epoch   1: total training loss 6706.62\n",
      "2020-03-04 00:43:09,037 Epoch   1: total training loss 6706.62\n",
      "2020-03-04 00:43:09,038 EPOCH 2\n",
      "2020-03-04 00:43:09,038 EPOCH 2\n",
      "2020-03-04 00:43:11,914 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 11139.7305, ppl:   3.7954, duration: 1.9910s\n",
      "2020-03-04 00:43:11,914 Validation result (greedy) at epoch   2, step      160: bleu:   0.00, loss: 11139.7305, ppl:   3.7954, duration: 1.9910s\n",
      "2020-03-04 00:43:15,255 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 10904.3994, ppl:   3.6899, duration: 2.1085s\n",
      "2020-03-04 00:43:15,255 Validation result (greedy) at epoch   2, step      170: bleu:   0.00, loss: 10904.3994, ppl:   3.6899, duration: 2.1085s\n",
      "2020-03-04 00:43:19,347 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 10716.4941, ppl:   3.6078, duration: 2.8168s\n",
      "2020-03-04 00:43:19,347 Validation result (greedy) at epoch   2, step      180: bleu:   0.00, loss: 10716.4941, ppl:   3.6078, duration: 2.8168s\n",
      "2020-03-04 00:43:22,988 Validation result (greedy) at epoch   2, step      190: bleu:   0.00, loss: 10503.1406, ppl:   3.5168, duration: 2.5294s\n",
      "2020-03-04 00:43:22,988 Validation result (greedy) at epoch   2, step      190: bleu:   0.00, loss: 10503.1406, ppl:   3.5168, duration: 2.5294s\n",
      "2020-03-04 00:43:27,280 Validation result (greedy) at epoch   2, step      200: bleu:   0.00, loss: 10297.2920, ppl:   3.4312, duration: 2.9388s\n",
      "2020-03-04 00:43:27,280 Validation result (greedy) at epoch   2, step      200: bleu:   0.00, loss: 10297.2920, ppl:   3.4312, duration: 2.9388s\n",
      "2020-03-04 00:43:31,066 Validation result (greedy) at epoch   2, step      210: bleu:   0.00, loss: 10128.5439, ppl:   3.3626, duration: 2.6871s\n",
      "2020-03-04 00:43:31,066 Validation result (greedy) at epoch   2, step      210: bleu:   0.00, loss: 10128.5439, ppl:   3.3626, duration: 2.6871s\n",
      "2020-03-04 00:43:34,549 Validation result (greedy) at epoch   2, step      220: bleu:   0.00, loss: 10040.1699, ppl:   3.3272, duration: 2.3813s\n",
      "2020-03-04 00:43:34,549 Validation result (greedy) at epoch   2, step      220: bleu:   0.00, loss: 10040.1699, ppl:   3.3272, duration: 2.3813s\n",
      "2020-03-04 00:43:38,931 Validation result (greedy) at epoch   2, step      230: bleu:   0.00, loss: 9830.4375, ppl:   3.2447, duration: 3.3918s\n",
      "2020-03-04 00:43:38,931 Validation result (greedy) at epoch   2, step      230: bleu:   0.00, loss: 9830.4375, ppl:   3.2447, duration: 3.3918s\n",
      "2020-03-04 00:43:43,031 Validation result (greedy) at epoch   2, step      240: bleu:   0.00, loss: 9744.1104, ppl:   3.2113, duration: 3.0808s\n",
      "2020-03-04 00:43:43,031 Validation result (greedy) at epoch   2, step      240: bleu:   0.00, loss: 9744.1104, ppl:   3.2113, duration: 3.0808s\n",
      "2020-03-04 00:43:47,665 Validation result (greedy) at epoch   2, step      250: bleu:   0.00, loss: 9526.6006, ppl:   3.1288, duration: 3.3070s\n",
      "2020-03-04 00:43:47,665 Validation result (greedy) at epoch   2, step      250: bleu:   0.00, loss: 9526.6006, ppl:   3.1288, duration: 3.3070s\n",
      "2020-03-04 00:43:52,613 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:43:52,613 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:43:52,613 Saving new checkpoint.\n",
      "2020-03-04 00:43:52,613 Saving new checkpoint.\n",
      "2020-03-04 00:43:52,734 Validation result (greedy) at epoch   2, step      260: bleu:   2.98, loss: 9394.5469, ppl:   3.0797, duration: 3.8262s\n",
      "2020-03-04 00:43:52,734 Validation result (greedy) at epoch   2, step      260: bleu:   2.98, loss: 9394.5469, ppl:   3.0797, duration: 3.8262s\n",
      "2020-03-04 00:43:58,015 Validation result (greedy) at epoch   2, step      270: bleu:   0.00, loss: 9248.6738, ppl:   3.0264, duration: 4.0686s\n",
      "2020-03-04 00:43:58,015 Validation result (greedy) at epoch   2, step      270: bleu:   0.00, loss: 9248.6738, ppl:   3.0264, duration: 4.0686s\n",
      "2020-03-04 00:44:02,381 Validation result (greedy) at epoch   2, step      280: bleu:   0.00, loss: 9102.2910, ppl:   2.9738, duration: 3.1848s\n",
      "2020-03-04 00:44:02,381 Validation result (greedy) at epoch   2, step      280: bleu:   0.00, loss: 9102.2910, ppl:   2.9738, duration: 3.1848s\n",
      "2020-03-04 00:44:06,833 Validation result (greedy) at epoch   2, step      290: bleu:   2.63, loss: 8970.1035, ppl:   2.9271, duration: 3.1810s\n",
      "2020-03-04 00:44:06,833 Validation result (greedy) at epoch   2, step      290: bleu:   2.63, loss: 8970.1035, ppl:   2.9271, duration: 3.1810s\n",
      "2020-03-04 00:44:12,437 Validation result (greedy) at epoch   2, step      300: bleu:   2.89, loss: 8933.0645, ppl:   2.9141, duration: 4.2181s\n",
      "2020-03-04 00:44:12,437 Validation result (greedy) at epoch   2, step      300: bleu:   2.89, loss: 8933.0645, ppl:   2.9141, duration: 4.2181s\n",
      "2020-03-04 00:44:13,212 Epoch   2: total training loss 4167.07\n",
      "2020-03-04 00:44:13,212 Epoch   2: total training loss 4167.07\n",
      "2020-03-04 00:44:13,212 EPOCH 3\n",
      "2020-03-04 00:44:13,212 EPOCH 3\n",
      "2020-03-04 00:44:17,457 Validation result (greedy) at epoch   3, step      310: bleu:   0.00, loss: 8806.6885, ppl:   2.8704, duration: 3.6505s\n",
      "2020-03-04 00:44:17,457 Validation result (greedy) at epoch   3, step      310: bleu:   0.00, loss: 8806.6885, ppl:   2.8704, duration: 3.6505s\n",
      "2020-03-04 00:44:21,845 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:21,845 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:21,845 Saving new checkpoint.\n",
      "2020-03-04 00:44:21,845 Saving new checkpoint.\n",
      "2020-03-04 00:44:21,968 Validation result (greedy) at epoch   3, step      320: bleu:   3.32, loss: 8750.4727, ppl:   2.8511, duration: 3.4639s\n",
      "2020-03-04 00:44:21,968 Validation result (greedy) at epoch   3, step      320: bleu:   3.32, loss: 8750.4727, ppl:   2.8511, duration: 3.4639s\n",
      "2020-03-04 00:44:26,170 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:26,170 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:26,170 Saving new checkpoint.\n",
      "2020-03-04 00:44:26,170 Saving new checkpoint.\n",
      "2020-03-04 00:44:26,309 Validation result (greedy) at epoch   3, step      330: bleu:   3.36, loss: 8592.8672, ppl:   2.7978, duration: 2.9524s\n",
      "2020-03-04 00:44:26,309 Validation result (greedy) at epoch   3, step      330: bleu:   3.36, loss: 8592.8672, ppl:   2.7978, duration: 2.9524s\n",
      "2020-03-04 00:44:31,807 Validation result (greedy) at epoch   3, step      340: bleu:   3.05, loss: 8507.9141, ppl:   2.7695, duration: 4.1694s\n",
      "2020-03-04 00:44:31,807 Validation result (greedy) at epoch   3, step      340: bleu:   3.05, loss: 8507.9141, ppl:   2.7695, duration: 4.1694s\n",
      "2020-03-04 00:44:36,230 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:36,230 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:44:36,231 Saving new checkpoint.\n",
      "2020-03-04 00:44:36,231 Saving new checkpoint.\n",
      "2020-03-04 00:44:36,365 Validation result (greedy) at epoch   3, step      350: bleu:   3.90, loss: 8493.5020, ppl:   2.7647, duration: 3.2485s\n",
      "2020-03-04 00:44:36,365 Validation result (greedy) at epoch   3, step      350: bleu:   3.90, loss: 8493.5020, ppl:   2.7647, duration: 3.2485s\n",
      "2020-03-04 00:44:40,739 Validation result (greedy) at epoch   3, step      360: bleu:   0.00, loss: 8340.3506, ppl:   2.7145, duration: 3.0078s\n",
      "2020-03-04 00:44:40,739 Validation result (greedy) at epoch   3, step      360: bleu:   0.00, loss: 8340.3506, ppl:   2.7145, duration: 3.0078s\n",
      "2020-03-04 00:44:45,427 Validation result (greedy) at epoch   3, step      370: bleu:   3.83, loss: 8300.4541, ppl:   2.7016, duration: 3.3526s\n",
      "2020-03-04 00:44:45,427 Validation result (greedy) at epoch   3, step      370: bleu:   3.83, loss: 8300.4541, ppl:   2.7016, duration: 3.3526s\n",
      "2020-03-04 00:44:49,558 Validation result (greedy) at epoch   3, step      380: bleu:   3.01, loss: 8241.5977, ppl:   2.6826, duration: 2.8937s\n",
      "2020-03-04 00:44:49,558 Validation result (greedy) at epoch   3, step      380: bleu:   3.01, loss: 8241.5977, ppl:   2.6826, duration: 2.8937s\n",
      "2020-03-04 00:44:53,346 Validation result (greedy) at epoch   3, step      390: bleu:   3.82, loss: 8141.6543, ppl:   2.6507, duration: 2.6856s\n",
      "2020-03-04 00:44:53,346 Validation result (greedy) at epoch   3, step      390: bleu:   3.82, loss: 8141.6543, ppl:   2.6507, duration: 2.6856s\n",
      "2020-03-04 00:44:57,212 Validation result (greedy) at epoch   3, step      400: bleu:   0.00, loss: 8132.0967, ppl:   2.6476, duration: 2.7875s\n",
      "2020-03-04 00:44:57,212 Validation result (greedy) at epoch   3, step      400: bleu:   0.00, loss: 8132.0967, ppl:   2.6476, duration: 2.7875s\n",
      "2020-03-04 00:45:01,001 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:01,001 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:01,001 Saving new checkpoint.\n",
      "2020-03-04 00:45:01,001 Saving new checkpoint.\n",
      "2020-03-04 00:45:01,166 Validation result (greedy) at epoch   3, step      410: bleu:   4.87, loss: 8031.8374, ppl:   2.6161, duration: 2.7241s\n",
      "2020-03-04 00:45:01,166 Validation result (greedy) at epoch   3, step      410: bleu:   4.87, loss: 8031.8374, ppl:   2.6161, duration: 2.7241s\n",
      "2020-03-04 00:45:05,898 Validation result (greedy) at epoch   3, step      420: bleu:   0.00, loss: 7938.4360, ppl:   2.5870, duration: 3.5874s\n",
      "2020-03-04 00:45:05,898 Validation result (greedy) at epoch   3, step      420: bleu:   0.00, loss: 7938.4360, ppl:   2.5870, duration: 3.5874s\n",
      "2020-03-04 00:45:10,440 Validation result (greedy) at epoch   3, step      430: bleu:   4.22, loss: 7895.4219, ppl:   2.5737, duration: 3.4442s\n",
      "2020-03-04 00:45:10,440 Validation result (greedy) at epoch   3, step      430: bleu:   4.22, loss: 7895.4219, ppl:   2.5737, duration: 3.4442s\n",
      "2020-03-04 00:45:15,176 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:15,176 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:15,177 Saving new checkpoint.\n",
      "2020-03-04 00:45:15,177 Saving new checkpoint.\n",
      "2020-03-04 00:45:15,314 Validation result (greedy) at epoch   3, step      440: bleu:   5.20, loss: 7819.2480, ppl:   2.5503, duration: 3.6319s\n",
      "2020-03-04 00:45:15,314 Validation result (greedy) at epoch   3, step      440: bleu:   5.20, loss: 7819.2480, ppl:   2.5503, duration: 3.6319s\n",
      "2020-03-04 00:45:19,452 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:19,452 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:19,452 Saving new checkpoint.\n",
      "2020-03-04 00:45:19,452 Saving new checkpoint.\n",
      "2020-03-04 00:45:19,677 Validation result (greedy) at epoch   3, step      450: bleu:   5.37, loss: 7778.8340, ppl:   2.5380, duration: 3.3718s\n",
      "2020-03-04 00:45:19,677 Validation result (greedy) at epoch   3, step      450: bleu:   5.37, loss: 7778.8340, ppl:   2.5380, duration: 3.3718s\n",
      "2020-03-04 00:45:20,732 Epoch   3: total training loss 3460.38\n",
      "2020-03-04 00:45:20,732 Epoch   3: total training loss 3460.38\n",
      "2020-03-04 00:45:20,732 EPOCH 4\n",
      "2020-03-04 00:45:20,732 EPOCH 4\n",
      "2020-03-04 00:45:24,534 Validation result (greedy) at epoch   4, step      460: bleu:   5.08, loss: 7675.2842, ppl:   2.5067, duration: 3.5529s\n",
      "2020-03-04 00:45:24,534 Validation result (greedy) at epoch   4, step      460: bleu:   5.08, loss: 7675.2842, ppl:   2.5067, duration: 3.5529s\n",
      "2020-03-04 00:45:28,790 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:28,790 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:28,790 Saving new checkpoint.\n",
      "2020-03-04 00:45:28,790 Saving new checkpoint.\n",
      "2020-03-04 00:45:28,918 Validation result (greedy) at epoch   4, step      470: bleu:   5.56, loss: 7608.0059, ppl:   2.4866, duration: 3.2331s\n",
      "2020-03-04 00:45:28,918 Validation result (greedy) at epoch   4, step      470: bleu:   5.56, loss: 7608.0059, ppl:   2.4866, duration: 3.2331s\n",
      "2020-03-04 00:45:34,217 Validation result (greedy) at epoch   4, step      480: bleu:   5.22, loss: 7591.8755, ppl:   2.4818, duration: 4.0382s\n",
      "2020-03-04 00:45:34,217 Validation result (greedy) at epoch   4, step      480: bleu:   5.22, loss: 7591.8755, ppl:   2.4818, duration: 4.0382s\n",
      "2020-03-04 00:45:38,327 Validation result (greedy) at epoch   4, step      490: bleu:   4.88, loss: 7536.0137, ppl:   2.4653, duration: 2.8971s\n",
      "2020-03-04 00:45:38,327 Validation result (greedy) at epoch   4, step      490: bleu:   4.88, loss: 7536.0137, ppl:   2.4653, duration: 2.8971s\n",
      "2020-03-04 00:45:42,291 Validation result (greedy) at epoch   4, step      500: bleu:   5.34, loss: 7490.5718, ppl:   2.4519, duration: 2.8227s\n",
      "2020-03-04 00:45:42,291 Validation result (greedy) at epoch   4, step      500: bleu:   5.34, loss: 7490.5718, ppl:   2.4519, duration: 2.8227s\n",
      "2020-03-04 00:45:47,019 Validation result (greedy) at epoch   4, step      510: bleu:   4.78, loss: 7495.1099, ppl:   2.4532, duration: 3.4018s\n",
      "2020-03-04 00:45:47,019 Validation result (greedy) at epoch   4, step      510: bleu:   4.78, loss: 7495.1099, ppl:   2.4532, duration: 3.4018s\n",
      "2020-03-04 00:45:51,824 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:51,824 Hooray! New best validation result [eval_metric]!\n",
      "2020-03-04 00:45:51,824 Saving new checkpoint.\n",
      "2020-03-04 00:45:51,824 Saving new checkpoint.\n",
      "2020-03-04 00:45:51,954 Validation result (greedy) at epoch   4, step      520: bleu:   5.94, loss: 7422.3438, ppl:   2.4319, duration: 3.7385s\n",
      "2020-03-04 00:45:51,954 Validation result (greedy) at epoch   4, step      520: bleu:   5.94, loss: 7422.3438, ppl:   2.4319, duration: 3.7385s\n",
      "2020-03-04 00:45:56,243 Validation result (greedy) at epoch   4, step      530: bleu:   4.68, loss: 7340.7036, ppl:   2.4083, duration: 3.0013s\n",
      "2020-03-04 00:45:56,243 Validation result (greedy) at epoch   4, step      530: bleu:   4.68, loss: 7340.7036, ppl:   2.4083, duration: 3.0013s\n",
      "2020-03-04 00:46:00,021 Validation result (greedy) at epoch   4, step      540: bleu:   4.91, loss: 7273.1108, ppl:   2.3889, duration: 2.6493s\n",
      "2020-03-04 00:46:00,021 Validation result (greedy) at epoch   4, step      540: bleu:   4.91, loss: 7273.1108, ppl:   2.3889, duration: 2.6493s\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from joeynmt.training import train_transfer\n",
    "\n",
    "emb_size = 300\n",
    "hidden_size = 512\n",
    "base_dir = Path('data/transfer/preprocessed/')\n",
    "for base_lang in ['splits.en']:\n",
    "    #tr tk bn mr lt\n",
    "    base_lang_dir = base_dir / base_lang\n",
    "    for lang in os.listdir(base_lang_dir):\n",
    "        if 'shp' not in lang:\n",
    "            if 'tr' in lang\\\n",
    "                or 'tk' in lang\\\n",
    "                or 'bn' in lang\\\n",
    "                or 'mr' in lang\\\n",
    "                or 'lt' in lang:\n",
    "                lang_dir = base_lang_dir / lang\n",
    "                for segment in os.listdir(lang_dir):\n",
    "                    segment_dir = lang_dir / segment\n",
    "\n",
    "                    pretrained_lang_src, pretrained_lang_tgt = lang.split('-')\n",
    "                    lang_src = pretrained_lang_src\n",
    "                    lang_tgt = 'shp'\n",
    "\n",
    "                    training_dir = Path(str(segment_dir).replace(pretrained_lang_tgt, 'shp'))\n",
    "\n",
    "                    if 'bpe_drop' in segment:\n",
    "                        level = 'bpe'\n",
    "                    elif 'bpe' in segment:\n",
    "                        level = 'bpe'\n",
    "                    elif 'char' in segment:\n",
    "                        level = 'char'\n",
    "                    elif 'word' in segment:\n",
    "                        level = 'word'\n",
    "                    elif 'syl' in segment:\n",
    "                        level = 'syl'\n",
    "                    else:\n",
    "                        level = None         \n",
    "\n",
    "                    f_config = config.format(lang_src=lang_src, lang_tgt=lang_tgt, \\\n",
    "                        train_path=os.path.join(training_dir, 'train'),\\\n",
    "                        test_path=os.path.join(training_dir, 'test'),\\\n",
    "                        dev_path=os.path.join(training_dir, 'valid'),\\\n",
    "                        pretrained_lang_src=pretrained_lang_src,\\\n",
    "                        pretrained_lang_tgt=pretrained_lang_tgt,\\\n",
    "                        pretrained_train_path=os.path.join(segment_dir, 'train'),\\\n",
    "                        pretrained_test_path=os.path.join(segment_dir, 'test'),\\\n",
    "                        pretrained_dev_path=os.path.join(segment_dir, 'valid'),\\\n",
    "                        level=level,\\\n",
    "                        emb_size=emb_size,\\\n",
    "                        hidden_size=hidden_size,\\\n",
    "                        val_freq=10,\\\n",
    "                        model_dir=os.path.join('results/rnn/transfer_top', 'splits.en',\\\n",
    "                                            f'{pretrained_lang_src}-{pretrained_lang_tgt}_{emb_size}_{hidden_size}', segment))\n",
    "\n",
    "                    with open(\"joeynmt/configs/sample_{name}.yaml\".format(name=\"transfer\"),'w') as f:\n",
    "                        f.write(f_config)\n",
    "\n",
    "                    !python3 joeynmt/joeynmt train_transfer \"joeynmt/configs/sample_transfer.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from joeynmt.training import train_transfer\n",
    "\n",
    "emb_size = 300\n",
    "hidden_size = 512\n",
    "base_dir = Path('data/transfer/preprocessed/')\n",
    "for base_lang in ['splits.es']:\n",
    "    #tr tk bn mr lt\n",
    "    base_lang_dir = base_dir / base_lang\n",
    "    for lang in os.listdir(base_lang_dir):\n",
    "        if 'shp' not in lang:\n",
    "            if 'tr' in lang\\\n",
    "                or 'hu' in lang\\\n",
    "                or 'fi' in lang\\\n",
    "                or 'ru' in lang\\\n",
    "                or 'pl' in lang:\n",
    "                lang_dir = base_lang_dir / lang\n",
    "                for segment in os.listdir(lang_dir):\n",
    "                    segment_dir = lang_dir / segment\n",
    "\n",
    "                    pretrained_lang_src, pretrained_lang_tgt = lang.split('-')\n",
    "                    lang_src = pretrained_lang_src\n",
    "                    lang_tgt = 'shp'\n",
    "\n",
    "                    training_dir = Path(str(segment_dir).replace(pretrained_lang_tgt, 'shp'))\n",
    "\n",
    "                    if 'bpe_drop' in segment:\n",
    "                        level = 'bpe'\n",
    "                    elif 'bpe' in segment:\n",
    "                        level = 'bpe'\n",
    "                    elif 'char' in segment:\n",
    "                        level = 'char'\n",
    "                    elif 'word' in segment:\n",
    "                        level = 'word'\n",
    "                    elif 'syl' in segment:\n",
    "                        level = 'syl'\n",
    "                    else:\n",
    "                        level = None         \n",
    "\n",
    "                    f_config = config.format(lang_src=lang_src, lang_tgt=lang_tgt, \\\n",
    "                        train_path=os.path.join(training_dir, 'train'),\\\n",
    "                        test_path=os.path.join(training_dir, 'test'),\\\n",
    "                        dev_path=os.path.join(training_dir, 'valid'),\\\n",
    "                        pretrained_lang_src=pretrained_lang_src,\\\n",
    "                        pretrained_lang_tgt=pretrained_lang_tgt,\\\n",
    "                        pretrained_train_path=os.path.join(segment_dir, 'train'),\\\n",
    "                        pretrained_test_path=os.path.join(segment_dir, 'test'),\\\n",
    "                        pretrained_dev_path=os.path.join(segment_dir, 'valid'),\\\n",
    "                        level=level,\\\n",
    "                        emb_size=emb_size,\\\n",
    "                        hidden_size=hidden_size,\\\n",
    "                        val_freq=10,\\\n",
    "                        model_dir=os.path.join('results/rnn/transfer_top', 'splits.es',\\\n",
    "                                            f'{pretrained_lang_src}-{pretrained_lang_tgt}_{emb_size}_{hidden_size}', segment))\n",
    "\n",
    "                    with open(\"joeynmt/configs/sample_{name}_es.yaml\".format(name=\"transfer\"),'w') as f:\n",
    "                        f.write(f_config)\n",
    "\n",
    "                    !python3 joeynmt/joeynmt train_transfer \"joeynmt/configs/sample_transfer_es.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
