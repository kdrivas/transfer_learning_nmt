{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy\n",
    "\n",
    "def read_txt(path):\n",
    "    lines = []\n",
    "    with open(path) as f:\n",
    "        for line in f.read().split('\\n'):\n",
    "            if len(line):\n",
    "                line = line.replace('*', '')\n",
    "                line = line.replace('´', '\\\"')\n",
    "                line = re.sub(r'([.¡!¿?;,:\\\"])', r' \\1 ', line)\n",
    "                line = ' '.join([w for w in line.split(' ')])\n",
    "                line = re.sub(' +', ' ', line)\n",
    "                line = line.strip(' ')\n",
    "                line = line.strip(',')\n",
    "                line = line.strip(':')\n",
    "                line = line.replace('. .', '.')\n",
    "                line = line.replace('. ,', '.')\n",
    "                lines.append(line)\n",
    "            \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_accent(w):\n",
    "    chars = list(w)\n",
    "    replacement = []\n",
    "    for i,c in enumerate(chars):\n",
    "        if c == \"á\": \n",
    "            replacement.append((i,c))\n",
    "            chars[i] = \"a\"\n",
    "        elif c == \"é\": \n",
    "            replacement.append((i,c))\n",
    "            chars[i] = \"e\"\n",
    "        elif c == \"í\": \n",
    "            replacement.append((i,c))\n",
    "            chars[i] = \"i\"\n",
    "        elif c == \"ó\": \n",
    "            replacement.append((i,c))\n",
    "            chars[i] = \"o\"\n",
    "        elif c == \"ú\": \n",
    "            replacement.append((i,c))\n",
    "            chars[i] = \"u\"\n",
    "    w = \"\".join(chars)\n",
    "    return w, replacement\n",
    "\n",
    "def put_accent(syl, replacement):\n",
    "    lens = [len(s) for s in syl]\n",
    "    w = \"\".join(syl)\n",
    "    chars = list(w)\n",
    "    for (i,c) in replacement:\n",
    "        chars[i] = c\n",
    "    w = \"\".join(chars)\n",
    "    syllables = []\n",
    "    pos = 0\n",
    "    for l in lens:\n",
    "        syllables.append(w[pos:pos+l])\n",
    "        pos+=l\n",
    "    return syllables\n",
    "\n",
    "def silabificar(palabraVC):\n",
    "    sibilantes = ['m','n', 's', 'sh', 'x']\n",
    "    silabas = []\n",
    "    silaba = \"\"\n",
    "    posActual = len(palabraVC) - 1\n",
    "    if len(palabraVC) == 1:\n",
    "        silabas.append(palabraVC[0][0])\n",
    "        return silabas\n",
    "    while posActual >= 0 and palabraVC:\n",
    "        #Se revisa si es vocal\n",
    "        if palabraVC[posActual][1] == 'V':\n",
    "            silaba = palabraVC[posActual][0]\n",
    "            del palabraVC[-1]\n",
    "            #Se revisa las siguientes letras\n",
    "            posActual = posActual - 1\n",
    "            #Si es vocal alargada\n",
    "            if palabraVC and (palabraVC[posActual][0] == silaba or\n",
    "                              palabraVC[posActual][0] == tildar(silaba)):\n",
    "                if (len(palabraVC) > 1):\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "                    #Si es consonante\n",
    "                else:\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "            elif palabraVC and palabraVC[posActual][1] == 'C':          \n",
    "                if (palabraVC[posActual][0] == 'u' or\n",
    "                        palabraVC[posActual][0] == tildar('u') or palabraVC[posActual][0] == 'h'):                    \n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "                else:                   \n",
    "                    #Se agrega a la silaba CV\n",
    "                    silaba = palabraVC[posActual][0] + silaba  #C\n",
    "                    posActual = posActual - 1\n",
    "                    del palabraVC[-1]\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "            else:\n",
    "                if (len(palabraVC) < 2 and posActual != 0):  #es sílaba sóla\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "                    posActual = posActual - 1\n",
    "                    if (palabraVC):\n",
    "                        del palabraVC[-1]\n",
    "                else:\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "        else:  #Se revisa si es consonante           \n",
    "            if palabraVC[posActual][0] in sibilantes:\n",
    "                silaba = palabraVC[posActual][0] + silaba\n",
    "                posActual = posActual - 1\n",
    "                if (palabraVC):\n",
    "                    del palabraVC[-1]\n",
    "                # Se ve primero CVC \n",
    "                if palabraVC and palabraVC[posActual][1] == 'V':\n",
    "                    silaba = palabraVC[posActual][0] + silaba  #V\n",
    "                    posActual = posActual - 1\n",
    "                    del palabraVC[-1]\n",
    "                    #silaba = VC\n",
    "                    if len(palabraVC) and palabraVC[posActual][1] == 'C':\n",
    "                        if palabraVC[posActual][0] == 'u' or palabraVC[\n",
    "                                posActual][0] == tildar('u') or palabraVC[posActual][0] == 'h':\n",
    "                            silabas.insert(0, silaba)\n",
    "                            silaba = \"\"\n",
    "                        else:\n",
    "                            # es CVC\n",
    "                            silaba = palabraVC[posActual][0] + silaba  #V\n",
    "                            silabas.insert(0, silaba)\n",
    "                            silaba = \"\"\n",
    "                            posActual = posActual - 1\n",
    "                            del palabraVC[-1]\n",
    "                    else:  #es VC\n",
    "                        silabas.insert(0, silaba)\n",
    "                        silaba = \"\"\n",
    "                else:\n",
    "                    if palabraVC and (palabraVC[posActual][0] == 'u' or\n",
    "                                      palabraVC[posActual][0] == tildar('u')):\n",
    "                        silabas.insert(0, silaba)\n",
    "                        silaba = \"\"\n",
    "                        posActual = posActual - 1\n",
    "                        del palabraVC[-1]\n",
    "            else:\n",
    "                if (palabraVC[posActual][0] == 'h'):\n",
    "                    silaba = palabraVC[posActual][0]\n",
    "                    posActual = posActual - 1\n",
    "                    del palabraVC[-1]\n",
    "                elif (palabraVC[posActual][0] == 'u' or\n",
    "                        palabraVC[posActual][0] == tildar('u')):                   \n",
    "                    silaba = palabraVC[posActual][0]\n",
    "                    silabas.insert(0, silaba)\n",
    "                    silaba = \"\"\n",
    "                    posActual = posActual - 1\n",
    "                    if (palabraVC):\n",
    "                        del palabraVC[-1]\n",
    "                else:\n",
    "                    if len(silabas):\n",
    "                        if palabraVC[posActual][0] == 't' and silabas[0][0] == 's':\n",
    "                            silabas[0] = palabraVC[posActual][0] + silabas[0]\n",
    "                        if palabraVC[posActual][0] == 'c' and silabas[0][0] == 'h':\n",
    "                            silabas[0] = palabraVC[posActual][0] + silabas[0]\n",
    "                        if palabraVC[posActual][0] == 's' and silabas[0][0] == 'h':                        \n",
    "                            silabas[0] = palabraVC[posActual][0] + silabas[0]\n",
    "                    posActual = posActual - 1\n",
    "                    if (palabraVC):\n",
    "                        del palabraVC[-1]\n",
    "    return silabas\n",
    "\n",
    "#Función que recibe una palabra y devuelve una lista con [letra: V o C]\n",
    "def convertir_a_VC(palabra):\n",
    "    estructura = []\n",
    "    vocales = ['a', 'e', 'i', 'o']\n",
    "    acentuado = [\"á\", \"é\", \"í\", \"ó\"]\n",
    "    #acentuado = ['á', 'é', 'í', 'ó']\n",
    "    especiales = ['ch', 'hu', 'sh', 'ts', 'qu']  #,'bu']\n",
    "    posConsonanteEspecial = -1\n",
    "    transformacion = {\n",
    "        \"ch\": \"1\",\n",
    "        \"hu\": \"2\",\n",
    "        \"sh\": \"3\",\n",
    "        \"ts\": \"4\",\n",
    "        \"qu\": \"5\"\n",
    "    }  #,\"bu\":\"6\"}\n",
    "    for especial in especiales:\n",
    "        if especial in palabra:\n",
    "            palabra = palabra.replace(especial, transformacion[especial])\n",
    "    for pos in range(0, len(palabra)):\n",
    "        #Se pone +1 para que se pueda juntar los consonantes especiales\n",
    "        if (posConsonanteEspecial != -1):\n",
    "            if pos != posConsonanteEspecial + 1:\n",
    "                if palabra[pos] in vocales or palabra[pos] in acentuado:\n",
    "                    estructura.append([palabra[pos], \"V\"])\n",
    "                else:\n",
    "                    if palabra[pos] == \" \":\n",
    "                        estructura.append([palabra[pos], \" \"])\n",
    "                    else:\n",
    "                        if palabra[pos] == \"-\":\n",
    "                            estructura.append([palabra[pos], \"-\"])\n",
    "                        else:\n",
    "                            estructura.append([palabra[pos], \"C\"])\n",
    "            else:  #Aquí se escribe el consonante especial\n",
    "                estructura[pos - 1] = [palabra[pos - 1] + palabra[pos], \"C\"]\n",
    "        else:\n",
    "            if palabra[pos] in vocales or palabra[pos] in acentuado:\n",
    "                estructura.append([palabra[pos], \"V\"])\n",
    "            else:\n",
    "                if palabra[pos] == \" \":\n",
    "                    estructura.append([palabra[pos], \" \"])\n",
    "                else:\n",
    "                    if palabra[pos] == \"-\":\n",
    "                        estructura.append([palabra[pos], \"-\"])\n",
    "                    else:\n",
    "                        estructura.append([palabra[pos], \"C\"])\n",
    "    for silaba in estructura:\n",
    "        silaba[0] = cambiar(silaba[0])\n",
    "    #print(estructura)\n",
    "    return estructura\n",
    "\n",
    "def cambiar(silaba):\n",
    "    if \"1\" in silaba:\n",
    "        silaba = silaba.replace(\"1\", \"ch\")\n",
    "    elif \"2\" in silaba:\n",
    "        silaba = silaba.replace(\"2\", \"hu\")\n",
    "    elif \"3\" in silaba:\n",
    "        silaba = silaba.replace(\"3\", \"sh\")\n",
    "    elif \"4\" in silaba:\n",
    "        silaba = silaba.replace(\"4\", \"ts\")\n",
    "    elif \"5\" in silaba:\n",
    "        silaba = silaba.replace(\"5\", \"qu\")\n",
    "    else:\n",
    "        silaba = silaba.replace(\"6\", \"bu\")\n",
    "    return silaba\n",
    "\n",
    "def tildar(letra): #    acentuado = [\"á\", \"é\", \"í\", \"ó\"]\n",
    "    if letra == \"a\":\n",
    "        letra = \"á\"\n",
    "    if letra == \"e\":\n",
    "        letra = \"é\"\n",
    "    if letra == \"i\":\n",
    "        letra = \"í\"\n",
    "    if letra == \"o\":\n",
    "        letra = \"ó\"\n",
    "    if letra == \"u\":\n",
    "        letra = \"ú\"\n",
    "    return letra\n",
    "\n",
    "def syllabification(w):\n",
    "    w, replacement = clean_accent(w)\n",
    "    #print(w,replacement)\n",
    "    syl = silabificar(convertir_a_VC(w))\n",
    "    #print(syl)\n",
    "    syl = put_accent(syl, replacement)\n",
    "    return syl, w\n",
    "\n",
    "def syllabification_pairs(pairs, path_out=None, path_word_to_syl_out=None):\n",
    "    sentences = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        line = pair[1]\n",
    "        flag_error = False\n",
    "        for w in line.strip().split():\n",
    "            w, replacement = clean_accent(w)\n",
    "            syl = silabificar(convertir_a_VC(w))\n",
    "            if len(\"\".join(syl)) < len(w):\n",
    "                flag_error = True\n",
    "\n",
    "        if not flag_error:\n",
    "            sentences.append(pair)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_txt(df, path, file):\n",
    "    with open(path / (file + '.es'), 'w') as f:\n",
    "        for line in df.iloc[:, 0]:\n",
    "            print(line, file=f)\n",
    "            \n",
    "    with open(path / (file + '.shp'), 'w') as f:\n",
    "        for line in df.iloc[:, 1]:\n",
    "            print(line, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/krivas/projects/transfer_learning_nmt/nb/Religioso\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/krivas/projects/transfer_learning_nmt/nb/Religioso/train.original.es'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-7eb0ae6d4de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mshi_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mpartition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.original.es'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mshi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpartition\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.original.shi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mes_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b57b78fe9bd4>\u001b[0m in \u001b[0;36mread_txt\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_txt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/krivas/projects/transfer_learning_nmt/nb/Religioso/train.original.es'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "filter_pairs= True\n",
    "base = Path('../data/translate/raw')\n",
    "\n",
    "for folder in ['Religioso', 'Educativo']:\n",
    "    folder_path = base / folder\n",
    "    print(folder_path)\n",
    "    es_all = []\n",
    "    shi_all = []\n",
    "    for partition in ['train', 'test', 'dev']:\n",
    "        es = read_txt(folder_path / (partition + '.original.es'))\n",
    "        shi = read_txt(folder_path / (partition + '.original.shi'))\n",
    "        es_all.extend(es)\n",
    "        shi_all.extend(shi)\n",
    "    print(len(es_all), len(shi_all))\n",
    "        \n",
    "    sentences = list(zip(es_all, shi_all))\n",
    "    if filter_pairs:\n",
    "        sentences = syllabification_pairs(sentences)\n",
    "    else:\n",
    "        sentences = sentences    \n",
    "    \n",
    "    sentences = np.array(sentences)\n",
    "    df = pd.DataFrame(sentences, columns=['es', 'shi'])\n",
    "    print('Tamaño df:', df.shape)\n",
    "    #df['es'] = sentences[:, 0]\n",
    "    #df['shi'] = sentences[:, 1]\n",
    "    df = df.drop_duplicates()\n",
    "    df.to_csv(folder_path / 'all.txt', index=False, sep='\\t', header=None)\n",
    "    #train, temp = train_test_split(df, test_size=0.1, random_state=0)\n",
    "    #test, dev = train_test_split(temp, test_size=0.5, random_state=0)\n",
    "    #train.to_csv(folder_path / 'train.txt', index=False, sep='\\t', header=None)\n",
    "    #test.to_csv(folder_path / 'test.txt', index=False, sep='\\t', header=None)\n",
    "    #dev.to_csv(folder_path / 'dev.txt', index=False, sep='\\t', header=None)\n",
    "    \n",
    "    #csv_to_txt(train, folder_path, 'train')\n",
    "    #csv_to_txt(test, folder_path, 'test')\n",
    "    #csv_to_txt(dev, folder_path, 'dev')\n",
    "    \n",
    "    #train, temp = train_test_split(df, test_size=0.3)\n",
    "    print(len(train), len(dev), len(test), df.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 2), (2, 2), (2, 2))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5982* 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5982, 5982)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(es_all), len(shi_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5982, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5982, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop_duplicates().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
